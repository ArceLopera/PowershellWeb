{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"This guide is designed to introduce you to PowerShell, a powerful command-line interface and scripting language built by Microsoft. Whether you are new to PowerShell or are looking to expand your skills, this guide will provide you with the necessary information to get started. Windows Powershell PowerShell is an automation solution that consists of a command-line shell, a scripting language, and a configuration-management framework. Installation PowerShell is pre-installed on Windows 10 and Windows Server 2016 and later, but you may need to update it to the latest version. To install PowerShell on older versions of Windows, visit the PowerShell GitHub repository and follow the installation instructions. Getting Started with PowerShell Before we dive into the commands, let's first open PowerShell. There are a few ways to do this: Click on the Start menu, search for PowerShell , and click on the Windows PowerShell option. Press the Windows key + R to open the Run dialog box, type in powershell , and press Enter . If you are using Windows 10, you can also right-click on the Start menu and select Windows PowerShell or Windows PowerShell (Admin) . Once you have PowerShell open, you can start entering commands. Command-line Shell Windows PowerShell superseded the Windows command-line interface (cmd.exe) and the limited functionality of its batch file scripting language. PowerShell accepts and returns .NET objects and includes: A command-line history. Tab completion and prediction. Support for command and parameter aliases . Chaining commands that use the Pipeline feature . A robust in-console help system . Initially, Windows PowerShell was a platform built on the .NET Framework and only worked on Windows operating systems. However, with its recent releases, PowerShell uses the .NET Core and can run on Windows, macOS, and Linux platforms. Due to their multi-platform support, these recent releases are referred to as PowerShell (rather than Windows PowerShell). PowerShell Basics PowerShell commands are called cmdlets, and they follow a simple verb-noun syntax. For example, the command to get a list of files in a directory is Get-ChildItem. Here are some basic PowerShell commands to get you started: Get-Help : Get help for a cmdlet Get-Member : Essential tool for exploring objects and their properties, methods, and events Get-Process : Get information about running processes Get-Service : Get information about running services Get-ChildItem : Get a list of files and folders in a directory Set-Location : Change the current working directory Get-Content : Get the contents of a file Set-Content : Set the contents of a file Clear-Host : Clear the PowerShell console screen Exit : Exit PowerShell Commands provide PowerShell\u2019s main functionality. There are many varieties of commands, including cmdlets (pronounced command-lets), functions, filters, scripts, applications, configurations, and workflows. Commands are building blocks that you piece together by using the Windows PowerShell scripting language. Using commands enables you to create custom solutions to complex administrative problems. Alternatively, you can run commands directly within the PowerShell console to complete a single task. The console is the CLI for PowerShell and is the primary way in which you'll interact with PowerShell. Cmdlets use a Verb-Noun naming convention. For example, you can use the Get-Command cmdlet to list all cmdlets and functions that are registered in the command shell. The verb identifies the action for the cmdlet to perform, and the noun identifies the resource on which the cmdlet will perform its action. A Scripting Language PowerShell scripts are saved as .ps1 files and can be run from the command line or by double-clicking on the file. Here are some tips for writing PowerShell scripts: Use comments to explain your code Use variables to store data Use loops and conditional statements to control the flow of your script Use functions to reuse code Advanced PowerShell PowerShell is a very powerful tool, and there are many advanced features that you can use to make your scripts even more powerful. Here are some advanced topics to explore: Remoting : Run PowerShell commands on remote computers Modules : Extend PowerShell with additional functionality Active Directory : Stores information about the objects of the network environment Error Handling : Handle errors in your scripts Conclusion PowerShell is a powerful tool that can help you automate repetitive tasks and manage your environment. By learning the basics of PowerShell, you can greatly improve your productivity and efficiency as an IT professional. With PowerShell, you can: Automate administrative tasks and eliminate manual work Manage and configure Windows operating systems and applications Integrate with other technologies and tools, such as Azure and Visual Studio Code Analyze and transform data using PowerShell commands and scripts In addition, PowerShell has a strong and supportive community of users and developers who are constantly creating new scripts, modules, and tools to extend its functionality. Whether you are a sysadmin, a developer, or just someone who wants to learn a powerful scripting language, PowerShell is a valuable tool to add to your skillset. With its robust features and wide range of applications, PowerShell can help you become more efficient and effective in your work. So why not give it a try and see what you can accomplish with PowerShell!","title":"Home"},{"location":"#windows-powershell","text":"PowerShell is an automation solution that consists of a command-line shell, a scripting language, and a configuration-management framework.","title":"Windows Powershell"},{"location":"#installation","text":"PowerShell is pre-installed on Windows 10 and Windows Server 2016 and later, but you may need to update it to the latest version. To install PowerShell on older versions of Windows, visit the PowerShell GitHub repository and follow the installation instructions.","title":"Installation"},{"location":"#getting-started-with-powershell","text":"Before we dive into the commands, let's first open PowerShell. There are a few ways to do this: Click on the Start menu, search for PowerShell , and click on the Windows PowerShell option. Press the Windows key + R to open the Run dialog box, type in powershell , and press Enter . If you are using Windows 10, you can also right-click on the Start menu and select Windows PowerShell or Windows PowerShell (Admin) . Once you have PowerShell open, you can start entering commands.","title":"Getting Started with PowerShell"},{"location":"#command-line-shell","text":"Windows PowerShell superseded the Windows command-line interface (cmd.exe) and the limited functionality of its batch file scripting language. PowerShell accepts and returns .NET objects and includes: A command-line history. Tab completion and prediction. Support for command and parameter aliases . Chaining commands that use the Pipeline feature . A robust in-console help system . Initially, Windows PowerShell was a platform built on the .NET Framework and only worked on Windows operating systems. However, with its recent releases, PowerShell uses the .NET Core and can run on Windows, macOS, and Linux platforms. Due to their multi-platform support, these recent releases are referred to as PowerShell (rather than Windows PowerShell).","title":"Command-line Shell"},{"location":"#powershell-basics","text":"PowerShell commands are called cmdlets, and they follow a simple verb-noun syntax. For example, the command to get a list of files in a directory is Get-ChildItem. Here are some basic PowerShell commands to get you started: Get-Help : Get help for a cmdlet Get-Member : Essential tool for exploring objects and their properties, methods, and events Get-Process : Get information about running processes Get-Service : Get information about running services Get-ChildItem : Get a list of files and folders in a directory Set-Location : Change the current working directory Get-Content : Get the contents of a file Set-Content : Set the contents of a file Clear-Host : Clear the PowerShell console screen Exit : Exit PowerShell Commands provide PowerShell\u2019s main functionality. There are many varieties of commands, including cmdlets (pronounced command-lets), functions, filters, scripts, applications, configurations, and workflows. Commands are building blocks that you piece together by using the Windows PowerShell scripting language. Using commands enables you to create custom solutions to complex administrative problems. Alternatively, you can run commands directly within the PowerShell console to complete a single task. The console is the CLI for PowerShell and is the primary way in which you'll interact with PowerShell. Cmdlets use a Verb-Noun naming convention. For example, you can use the Get-Command cmdlet to list all cmdlets and functions that are registered in the command shell. The verb identifies the action for the cmdlet to perform, and the noun identifies the resource on which the cmdlet will perform its action.","title":"PowerShell Basics"},{"location":"#a-scripting-language","text":"PowerShell scripts are saved as .ps1 files and can be run from the command line or by double-clicking on the file. Here are some tips for writing PowerShell scripts: Use comments to explain your code Use variables to store data Use loops and conditional statements to control the flow of your script Use functions to reuse code","title":"A Scripting Language"},{"location":"#advanced-powershell","text":"PowerShell is a very powerful tool, and there are many advanced features that you can use to make your scripts even more powerful. Here are some advanced topics to explore: Remoting : Run PowerShell commands on remote computers Modules : Extend PowerShell with additional functionality Active Directory : Stores information about the objects of the network environment Error Handling : Handle errors in your scripts","title":"Advanced PowerShell"},{"location":"#conclusion","text":"PowerShell is a powerful tool that can help you automate repetitive tasks and manage your environment. By learning the basics of PowerShell, you can greatly improve your productivity and efficiency as an IT professional. With PowerShell, you can: Automate administrative tasks and eliminate manual work Manage and configure Windows operating systems and applications Integrate with other technologies and tools, such as Azure and Visual Studio Code Analyze and transform data using PowerShell commands and scripts In addition, PowerShell has a strong and supportive community of users and developers who are constantly creating new scripts, modules, and tools to extend its functionality. Whether you are a sysadmin, a developer, or just someone who wants to learn a powerful scripting language, PowerShell is a valuable tool to add to your skillset. With its robust features and wide range of applications, PowerShell can help you become more efficient and effective in your work. So why not give it a try and see what you can accomplish with PowerShell!","title":"Conclusion"},{"location":"GetStart/","text":"Getting started with PowerShell is easy, and here are the steps to help you: Find and run PowerShell PowerShell is pre-installed on most modern Windows operating systems. To find it, click on the \"Start\" menu, type \"PowerShell\" in the search box, and select the \"Windows PowerShell\" or \"PowerShell 7\" option depending on which version you want to use. Alternatively, you can press the \"Windows Key + X\" key combination and select \"Windows PowerShell\" from the Power User menu. Check the PowerShell version To check which version of PowerShell you have installed, open a PowerShell session and run the following command: $PSVersionTable This will display the PowerShell version number and other version-related information, such as the CLR version, the .NET Framework version, and the OS version. Update PowerShell If you have an older version of PowerShell, you can update it to the latest version. Winget, the Windows Package Manager, is a command-line tool enables users to discover, install, upgrade, remove, and configure applications on Windows client computers. This tool is the client interface to the Windows Package Manager service. The following commands can be used to install PowerShell using the published winget packages: Search for the latest version of PowerShell winget search Microsoft . PowerShell Then, install PowerShell or PowerShell Preview using the id parameter winget install - -id Microsoft . Powershell - -source winget winget install - -id Microsoft . Powershell . Preview - -source winget Use PowerShell help PowerShell includes a comprehensive help system that you can use to learn about PowerShell cmdlets, functions, and modules. To use the help system, open a PowerShell session and run the following command: Get-Help < cmdlet or topic > Replace with the name of the cmdlet or topic you want to learn about. For example, to learn about the Get-ChildItem cmdlet, you would run the following command: Get-Help Get-ChildItem This will display the help information for the Get-ChildItem cmdlet, including a description, syntax, parameters, examples, and related topics. By following these steps, you can get started with PowerShell, check for its version, update it to the latest version, and use the built-in help system to learn more about PowerShell and its various features. More on the use of Get-Help The Get-Help cmdlet is a powerful feature of PowerShell that provides help information for cmdlets, functions, modules, and other PowerShell components. Here are some examples of how to use the Get-Help cmdlet: Get help for a specific cmdlet: To get help for a specific cmdlet, run the following command: Get-Help < cmdlet name > Replace with the name of the cmdlet you want to learn about. For example, to get help for the Get-ChildItem cmdlet, you would run the following command: Get-Help Get-ChildItem This will display the help information for the Get-ChildItem cmdlet, including a description, syntax, parameters, examples, and related topics. Get help for a specific parameter: To get help for a specific parameter of a cmdlet, run the following command: Get-Help < cmdlet name > -Parameter < parameter name > Replace with the name of the cmdlet and with the name of the parameter you want to learn about. For example, to get help for the Path parameter of the Get-ChildItem cmdlet, you would run the following command: Get-Help Get-ChildItem -Parameter Path This will display the help information for the Path parameter of the Get-ChildItem cmdlet. Get help for a specific topic: To get help for a specific topic, such as operators or variables, run the following command: Get-Help < topic > Replace with the name of the topic you want to learn about. For example, to get help for operators, you would run the following command: Get-Help about_operators This will display the help information for operators in PowerShell. Use wildcard with Get-Help: You can use wildcard characters to search for cmdlets or topics that match a certain pattern. For example, to search for all cmdlets that start with \"Get\", you would run the following command: Get-Help Get -* This will display help information for all cmdlets that start with \"Get\", including Get-ChildItem, Get-Item, Get-Process, and others. In summary, the Get-Help cmdlet is a valuable tool for learning about PowerShell and its various components. By using Get-Help with different parameters and wildcard characters, you can quickly find the information you need and improve your PowerShell skills.","title":"Getting Started"},{"location":"GetStart/#find-and-run-powershell","text":"PowerShell is pre-installed on most modern Windows operating systems. To find it, click on the \"Start\" menu, type \"PowerShell\" in the search box, and select the \"Windows PowerShell\" or \"PowerShell 7\" option depending on which version you want to use. Alternatively, you can press the \"Windows Key + X\" key combination and select \"Windows PowerShell\" from the Power User menu.","title":"Find and run PowerShell"},{"location":"GetStart/#check-the-powershell-version","text":"To check which version of PowerShell you have installed, open a PowerShell session and run the following command: $PSVersionTable This will display the PowerShell version number and other version-related information, such as the CLR version, the .NET Framework version, and the OS version.","title":"Check the PowerShell version"},{"location":"GetStart/#update-powershell","text":"If you have an older version of PowerShell, you can update it to the latest version. Winget, the Windows Package Manager, is a command-line tool enables users to discover, install, upgrade, remove, and configure applications on Windows client computers. This tool is the client interface to the Windows Package Manager service. The following commands can be used to install PowerShell using the published winget packages: Search for the latest version of PowerShell winget search Microsoft . PowerShell Then, install PowerShell or PowerShell Preview using the id parameter winget install - -id Microsoft . Powershell - -source winget winget install - -id Microsoft . Powershell . Preview - -source winget","title":"Update PowerShell"},{"location":"GetStart/#use-powershell-help","text":"PowerShell includes a comprehensive help system that you can use to learn about PowerShell cmdlets, functions, and modules. To use the help system, open a PowerShell session and run the following command: Get-Help < cmdlet or topic > Replace with the name of the cmdlet or topic you want to learn about. For example, to learn about the Get-ChildItem cmdlet, you would run the following command: Get-Help Get-ChildItem This will display the help information for the Get-ChildItem cmdlet, including a description, syntax, parameters, examples, and related topics. By following these steps, you can get started with PowerShell, check for its version, update it to the latest version, and use the built-in help system to learn more about PowerShell and its various features.","title":"Use PowerShell help"},{"location":"GetStart/#more-on-the-use-of-get-help","text":"The Get-Help cmdlet is a powerful feature of PowerShell that provides help information for cmdlets, functions, modules, and other PowerShell components. Here are some examples of how to use the Get-Help cmdlet: Get help for a specific cmdlet: To get help for a specific cmdlet, run the following command: Get-Help < cmdlet name > Replace with the name of the cmdlet you want to learn about. For example, to get help for the Get-ChildItem cmdlet, you would run the following command: Get-Help Get-ChildItem This will display the help information for the Get-ChildItem cmdlet, including a description, syntax, parameters, examples, and related topics. Get help for a specific parameter: To get help for a specific parameter of a cmdlet, run the following command: Get-Help < cmdlet name > -Parameter < parameter name > Replace with the name of the cmdlet and with the name of the parameter you want to learn about. For example, to get help for the Path parameter of the Get-ChildItem cmdlet, you would run the following command: Get-Help Get-ChildItem -Parameter Path This will display the help information for the Path parameter of the Get-ChildItem cmdlet. Get help for a specific topic: To get help for a specific topic, such as operators or variables, run the following command: Get-Help < topic > Replace with the name of the topic you want to learn about. For example, to get help for operators, you would run the following command: Get-Help about_operators This will display the help information for operators in PowerShell. Use wildcard with Get-Help: You can use wildcard characters to search for cmdlets or topics that match a certain pattern. For example, to search for all cmdlets that start with \"Get\", you would run the following command: Get-Help Get -* This will display help information for all cmdlets that start with \"Get\", including Get-ChildItem, Get-Item, Get-Process, and others. In summary, the Get-Help cmdlet is a valuable tool for learning about PowerShell and its various components. By using Get-Help with different parameters and wildcard characters, you can quickly find the information you need and improve your PowerShell skills.","title":"More on the use of Get-Help"},{"location":"comparison/","text":"The Compare-Object cmdlet (which has the alias diff) allows you to compare two objects and display the differences between them. In this sense, it allows you to compare a snapshot of processes (or services, or anything else) from a system with a more current snapshot. For example, you can generate a snapshot of the system's processes: get-process | export-clixml processes . xml ... and later, compare it with the processes that are running at that time: diff -Ref ( Import-Clixml .\\ processes . xml ) -Diff ( get-process ) -Property name The previous command is interpreted as follows: Parentheses are interpreted the same as in algebra: the commands that are inside parentheses are executed first, and their results are passed to the outermost command. The -Ref parameter (-ReferenceObject in full) indicates the object that will be used as the basis for the comparison (in this case, the snapshot that was previously saved). The -Diff parameter (-DifferenceObject in full) indicates the object that will be compared against the base (in this case, the current list of processes). The -Property parameter indicates the property that is being compared, in this case, the names of the processes. The output of the command is similar to this: name SideIndicator ---- ------------- WindowsInternal.ComposableShell.Experiences.TextInput.InputApp => YourPhone => LockApp <= Microsoft.Photos <= notepad <= The names of the processes appear, with an arrow pointing to the left or right: \u2022 If the arrow points to the right, it indicates a name that is in the new snapshot but not in the original. \u2022 If the arrow points to the left, it indicates a name that is in the original snapshot but not in the new one.","title":"Object Comparison"},{"location":"config_profile/","text":"Configuring your PowerShell profile is an essential step to personalize your PowerShell environment and make your work more efficient. Your profile is a PowerShell script file that executes every time you start a PowerShell session. You can use it to customize your environment by adding aliases, functions, variables, and modules. Here's an example of how to configure your profile in PowerShell: Open PowerShell and run the following command to create a new profile file if it doesn't exist: if ( ! ( Test-Path -Path $PROFILE )) { New-Item -Type File -Path $PROFILE -Force } Open your profile file with your preferred text editor or IDE. You can find the location of your profile file by running the following command: notepad $PROFILE This will open your profile file in Notepad. Add any customizations you want to your profile file. For example, you can add an alias to simplify a frequently used command. To create an alias for the Get-ChildItem cmdlet, add the following line to your profile: Set-Alias -Name ls -Value Get-ChildItem This creates an alias named ls that runs the Get-ChildItem cmdlet. Save and close your profile file. Restart PowerShell to apply your changes. Your customizations should now be available in your PowerShell session. In addition to aliases, you can also use your profile to configure your PowerShell prompt, set default parameters for cmdlets, load modules automatically, and define functions that you frequently use. By taking advantage of the customization options available in your profile, you can make your PowerShell experience more efficient and tailored to your needs. Here is an example of a common $profile script for PowerShell: # Add custom PowerShell functions function Get-Weather { param ([ string ] $location = \"New York\" ) Invoke-RestMethod -Uri \"https://wttr.in/ $location ?format=%C+%t\" -UseBasicParsing } # Load useful PowerShell modules Import-Module Pester Import-Module PSReadline Import-Module Microsoft.PowerShell.Management # Set default parameters for cmdlets $PSDefaultParameterValues = @ { \"Get-ChildItem:Recurse\" = $true \"Out-File:Encoding\" = \"utf8\" } # Add custom aliases Set-Alias -Name l -Value Get-ChildItem Set-Alias -Name gac -Value Get-ChildItem -ParameterName FullName -ArgumentList \"C:\\Windows\\Microsoft.NET\\assembly\\GAC*\" # Configure PowerShell prompt $host .UI.RawUI.WindowTitle = \" $env :USERNAME@ $env :COMPUTERNAME\" $host .UI.RawUI.ForegroundColor = \"Green\" $host .UI.RawUI.BackgroundColor = \"Black\" $host .UI.RawUI.WindowSize = New-Object System.Management.Automation.Host.Size ( 120 ,50 ) This $profile script defines several customizations for the PowerShell environment, including: A custom function named Get-Weather that uses the Invoke-RestMethod cmdlet to retrieve weather information for a specified location. The loading of several useful PowerShell modules, including Pester, PSReadline, and Microsoft.PowerShell.Management. Default parameter values for the Get-ChildItem and Out-File cmdlets. Custom aliases for the Get-ChildItem cmdlet and a common path for the Get-ChildItem cmdlet. Configuration of the PowerShell prompt, including the window title, foreground and background colors, and window size. By using a $profile script like this one, you can customize your PowerShell environment to suit your needs and make your work more efficient.","title":"Config Profile"},{"location":"enum/","text":"Enumeration is the process of performing a task on each object, one at a time, in a collection. Frequently, PowerShell doesn't require you to explicitly enumerate objects. For example, if you need to stop every running Notepad process on your computer, you can run either of these two commands: Get-Process \u2013 Name Notepad | Stop-Process Stop-Process \u2013 Name Notepad The ForEach-Object command performs enumeration. It has two common aliases: ForEach and %. Like Where-Object, ForEach-Object has a basic syntax and an advanced syntax. Basic Syntax In the basic syntax, you can run a single method or access a single property of the objects that were piped into the command. Get-ChildItem \u2013 Path C :\\ Encrypted \\ File | ForEach Object MemberName Encrypt With this syntax, you don't include the parentheses after the member name if the member is a method. Because this basic syntax is meant to be short, you'll frequently notice it without the -MemberName parameter name, and you might notice it with an alias instead of the full command name. For example, both of the following commands perform the same action: Get-ChildItem \u2013 Path C :\\ Encrypted \\ -File | ForEach Encrypt Get-ChildItem \u2013 Path C :\\ Encrypted \\ -File | % Encrypt You might not run into many scenarios that require enumeration. Each new operating system and version of PowerShell introduces new PowerShell commands. Newer operating systems typically introduce new commands which perform actions that previously required enumeration. Limitations of the basic syntax The basic syntax can access only a single property or method. It can't perform logical comparisons that use -and or -or; it can't make decisions; and it can't run any other commands or code. For example, the following command doesn't run, and it produces an error: Get-Service | ForEach -MemberName Stop -and -MemberName Close Advanced Syntax The advanced syntax for enumeration provides more flexibility and functionality than the basic syntax. Instead of letting you access a single object member, you can run a whole script. That script can include one command, or it can include many commands in sequence. Get-ChildItem \u2013 Path C :\\ ToEncrypt \\ -File | ForEach -Object \u2013 Process { $PSItem . Encrypt () } The ForEach-Object command can accept any number of objects from the pipeline. It has the -Process parameter that accepts a script block. This script block runs one time for each object that was piped in. Every time that the script block runs, the built-in variable $PSItem (or $_) can be used to refer to the current object. In the preceding example command, the Encrypt() method of each file object runs. When used with the advanced syntax, method names are always followed by opening and closing parentheses, even when the method doesn't have any input arguments. For methods that do need input arguments, provide them as a comma-separated list inside the parentheses. Don't include a space or other characters between the method name and the opening parenthesis. Advanced techniques In some situations, you might need to repeat a particular task a specified number of times. You can use ForEach-Object for that purpose when you pass it an input that uses the range operator. The range operator is two periods (..) with no space between them. For example, run the following command: 1 .. 100 | ForEach -Object { Get-Random } In the preceding command, the range operator produces integer objects from 1 through 100. Those 100 objects are piped to ForEach-Object, forcing the script block to run 100 times. However, because neither $_ nor $_PSItem display in the script block, the actual integers aren't used. Instead, the Get-Random command runs 100 times. The integer objects are used only to set the number of times the script block runs.","title":"Enumeration"},{"location":"enum/#basic-syntax","text":"In the basic syntax, you can run a single method or access a single property of the objects that were piped into the command. Get-ChildItem \u2013 Path C :\\ Encrypted \\ File | ForEach Object MemberName Encrypt With this syntax, you don't include the parentheses after the member name if the member is a method. Because this basic syntax is meant to be short, you'll frequently notice it without the -MemberName parameter name, and you might notice it with an alias instead of the full command name. For example, both of the following commands perform the same action: Get-ChildItem \u2013 Path C :\\ Encrypted \\ -File | ForEach Encrypt Get-ChildItem \u2013 Path C :\\ Encrypted \\ -File | % Encrypt You might not run into many scenarios that require enumeration. Each new operating system and version of PowerShell introduces new PowerShell commands. Newer operating systems typically introduce new commands which perform actions that previously required enumeration.","title":"Basic Syntax"},{"location":"enum/#limitations-of-the-basic-syntax","text":"The basic syntax can access only a single property or method. It can't perform logical comparisons that use -and or -or; it can't make decisions; and it can't run any other commands or code. For example, the following command doesn't run, and it produces an error: Get-Service | ForEach -MemberName Stop -and -MemberName Close","title":"Limitations of the basic syntax"},{"location":"enum/#advanced-syntax","text":"The advanced syntax for enumeration provides more flexibility and functionality than the basic syntax. Instead of letting you access a single object member, you can run a whole script. That script can include one command, or it can include many commands in sequence. Get-ChildItem \u2013 Path C :\\ ToEncrypt \\ -File | ForEach -Object \u2013 Process { $PSItem . Encrypt () } The ForEach-Object command can accept any number of objects from the pipeline. It has the -Process parameter that accepts a script block. This script block runs one time for each object that was piped in. Every time that the script block runs, the built-in variable $PSItem (or $_) can be used to refer to the current object. In the preceding example command, the Encrypt() method of each file object runs. When used with the advanced syntax, method names are always followed by opening and closing parentheses, even when the method doesn't have any input arguments. For methods that do need input arguments, provide them as a comma-separated list inside the parentheses. Don't include a space or other characters between the method name and the opening parenthesis.","title":"Advanced Syntax"},{"location":"enum/#advanced-techniques","text":"In some situations, you might need to repeat a particular task a specified number of times. You can use ForEach-Object for that purpose when you pass it an input that uses the range operator. The range operator is two periods (..) with no space between them. For example, run the following command: 1 .. 100 | ForEach -Object { Get-Random } In the preceding command, the range operator produces integer objects from 1 through 100. Those 100 objects are piped to ForEach-Object, forcing the script block to run 100 times. However, because neither $_ nor $_PSItem display in the script block, the actual integers aren't used. Instead, the Get-Random command runs 100 times. The integer objects are used only to set the number of times the script block runs.","title":"Advanced techniques"},{"location":"files_folders/","text":"PowerShell provides a variety of cmdlets for working with files and folders. In PowerShell, an \"item\" is a generic term used to refer to a file, folder, registry key, or other object that can be manipulated by cmdlets in the PowerShell environment. The term \"item\" is used in cmdlet names such as Get-Item, Set-Item, and Remove-Item, which can be used to manipulate different types of items in PowerShell. Items Here are some examples of how to use these cmdlets: Cmdlet Description Alias Get-ChildItem Gets the items and child items in one or more specified locations gci, dir, ls Set-Location Sets the working location to a specified location cd, sl, chdir Copy-Item Copies an item from one location to another location cp, copy Move-Item Moves an item from one location to another location mv, move Remove-Item Deletes the specified items ri, rmdir, rd, del, erase New-Item Creates a new item at the specified location ni Rename-Item Renames an item at the specified location rni Note that some of these cmdlets have additional parameters that can be used to control their behavior. For example, you can use the -Recurse parameter with Remove-Item to delete a directory and all its contents. You can also use wildcards with many of these cmdlets to perform operations on multiple files or directories at once. Get-ChildItem This cmdlet lists the contents of a directory. By default, it displays both files and directories. Example: Get-ChildItem C :\\ Users Set-Location This cmdlet changes the current working directory. Example: Set-Location C :\\ Users \\ UserName \\ Desktop Copy-Item This cmdlet copies a file or directory to a new location. Example: Copy-Item C :\\ Users \\ UserName \\ Desktop \\ MyFile . txt C :\\ Temp \\ Move-Item This cmdlet moves a file or directory to a new location. Example: Move-Item C :\\ Users \\ UserName \\ Desktop \\ MyFile . txt C :\\ Temp \\ Rename-Item This cmdlet renames a file or directory. Example: Rename-Item C :\\ Temp \\ MyFile . txt MyNewFile . txt New-Item This cmdlet creates a new file or directory. Example: New-Item -ItemType File -Path C :\\ Temp \\ NewFile . txt Remove-Item This cmdlet deletes a file or directory. Example: Remove-Item C :\\ Temp \\ MyFile . txt Properties In PowerShell, cmdlets whose names end with \"Property\" are used to retrieve or manipulate the properties of objects. Properties are attributes or characteristics of an object, such as its name, size, or creation date. The most common cmdlet that ends with \"Property\" is the Get-ItemProperty cmdlet, which is used to retrieve the properties of a file, folder, or registry key. For example, you can use the Get-ItemProperty cmdlet to retrieve the version number of a file or the registry key value for a particular setting. Other examples of cmdlets that end with \"Property\" include the Get-ServiceProperty cmdlet, which is used to retrieve the properties of a Windows service, and the Get-ADUserProperty cmdlet, which is used to retrieve the properties of an Active Directory user. In general, cmdlets that end with \"Property\" are useful for retrieving specific information about an object, which can be used in scripts or further manipulated using other PowerShell cmdlets. Cmdlet Description New-ItemProperty Creates a new property for an item at the specified location Get-ItemProperty Gets the properties of the specified items Set-ItemProperty Sets the value of a property for the specified item Remove-ItemProperty Removes a property from an item at the specified location Some interesting properties are: CreationTime, FullName, LastAccessTime, LastWriteTime, Attributes. For example, to check the creation time of a file: get-itemproperty -path filename -name CreationTime To check the attributes (permissions) of the file: get-itemproperty -path file -name Attributes To set the attributes, the Set-Itemproperty command is used, for example: set-itemproperty -path file -name Attributes -value \"ReadOnly\" Some permission values are ReadOnly, Hidden, System. If you want to set multiple permissions at once, separate their names with commas, and enclose the entire set in quotation marks (as in the example). Paths In PowerShell, cmdlets whose names end with \"Path\" are used to work with file and directory paths. These cmdlets are commonly used to manipulate or retrieve information about file and directory paths, such as their locations, names, or extensions. One of the most commonly used cmdlets that ends with \"Path\" is the Split-Path cmdlet, which is used to split a file or directory path into its individual components, such as the directory, filename, and extension. For example, the command \"Split-Path C:\\Temp\\test.txt -Leaf\" would return \"test.txt\", while \"Split-Path C:\\Temp\\test.txt -Parent\" would return \"C:\\Temp\". Another example is the Join-Path cmdlet, which is used to combine two or more path strings into a single path. For example, the command \"Join-Path C:\\Temp test.txt\" would return \"C:\\Temp\\test.txt\". Other examples of cmdlets that end with \"Path\" include the Resolve-Path cmdlet, which is used to resolve a path to its full, absolute form, and the Test-Path cmdlet, which is used to test whether a file or directory path exists. In general, cmdlets that end with \"Path\" are useful for manipulating file and directory paths, which can be useful for scripting or automating tasks that involve working with files and directories. Cmdlet Description Test-Path Determines whether all elements of a path exist Join-Path Joins two or more parts of a path into a single path Split-Path Returns specific parts of a path Convert-Path Converts a path from a relative path to a full path or from a full path to a relative path Directories or Folders Operation Command Creation new-item -itemtype directory -name directory_name Deletion remove-item -path directory_name -Recurse Rename rename-item -path directory_name -newname new_directory_name -Recurse Move move-item -path directory_name -destination new_location Enter cd directory_name Show current directory Get-Location or pwd (same as Linux) Note .(dot) indicates the current directory and ..(dot dot) indicates the parent of the current directory. Files Operation Command Creation new-item -itemtype file -name file_name [-value content] Deletion remove-item -path file_name Renaming rename-item -path file_name -newname new_name Moving move-item -path file_name -destination new_location Text files can be displayed on the console using the Get-Content command, which has the alias \"type\".","title":"Files & Folders"},{"location":"files_folders/#items","text":"Here are some examples of how to use these cmdlets: Cmdlet Description Alias Get-ChildItem Gets the items and child items in one or more specified locations gci, dir, ls Set-Location Sets the working location to a specified location cd, sl, chdir Copy-Item Copies an item from one location to another location cp, copy Move-Item Moves an item from one location to another location mv, move Remove-Item Deletes the specified items ri, rmdir, rd, del, erase New-Item Creates a new item at the specified location ni Rename-Item Renames an item at the specified location rni Note that some of these cmdlets have additional parameters that can be used to control their behavior. For example, you can use the -Recurse parameter with Remove-Item to delete a directory and all its contents. You can also use wildcards with many of these cmdlets to perform operations on multiple files or directories at once.","title":"Items"},{"location":"files_folders/#get-childitem","text":"This cmdlet lists the contents of a directory. By default, it displays both files and directories. Example: Get-ChildItem C :\\ Users","title":"Get-ChildItem"},{"location":"files_folders/#set-location","text":"This cmdlet changes the current working directory. Example: Set-Location C :\\ Users \\ UserName \\ Desktop","title":"Set-Location"},{"location":"files_folders/#copy-item","text":"This cmdlet copies a file or directory to a new location. Example: Copy-Item C :\\ Users \\ UserName \\ Desktop \\ MyFile . txt C :\\ Temp \\","title":"Copy-Item"},{"location":"files_folders/#move-item","text":"This cmdlet moves a file or directory to a new location. Example: Move-Item C :\\ Users \\ UserName \\ Desktop \\ MyFile . txt C :\\ Temp \\","title":"Move-Item"},{"location":"files_folders/#rename-item","text":"This cmdlet renames a file or directory. Example: Rename-Item C :\\ Temp \\ MyFile . txt MyNewFile . txt","title":"Rename-Item"},{"location":"files_folders/#new-item","text":"This cmdlet creates a new file or directory. Example: New-Item -ItemType File -Path C :\\ Temp \\ NewFile . txt","title":"New-Item"},{"location":"files_folders/#remove-item","text":"This cmdlet deletes a file or directory. Example: Remove-Item C :\\ Temp \\ MyFile . txt","title":"Remove-Item"},{"location":"files_folders/#properties","text":"In PowerShell, cmdlets whose names end with \"Property\" are used to retrieve or manipulate the properties of objects. Properties are attributes or characteristics of an object, such as its name, size, or creation date. The most common cmdlet that ends with \"Property\" is the Get-ItemProperty cmdlet, which is used to retrieve the properties of a file, folder, or registry key. For example, you can use the Get-ItemProperty cmdlet to retrieve the version number of a file or the registry key value for a particular setting. Other examples of cmdlets that end with \"Property\" include the Get-ServiceProperty cmdlet, which is used to retrieve the properties of a Windows service, and the Get-ADUserProperty cmdlet, which is used to retrieve the properties of an Active Directory user. In general, cmdlets that end with \"Property\" are useful for retrieving specific information about an object, which can be used in scripts or further manipulated using other PowerShell cmdlets. Cmdlet Description New-ItemProperty Creates a new property for an item at the specified location Get-ItemProperty Gets the properties of the specified items Set-ItemProperty Sets the value of a property for the specified item Remove-ItemProperty Removes a property from an item at the specified location Some interesting properties are: CreationTime, FullName, LastAccessTime, LastWriteTime, Attributes. For example, to check the creation time of a file: get-itemproperty -path filename -name CreationTime To check the attributes (permissions) of the file: get-itemproperty -path file -name Attributes To set the attributes, the Set-Itemproperty command is used, for example: set-itemproperty -path file -name Attributes -value \"ReadOnly\" Some permission values are ReadOnly, Hidden, System. If you want to set multiple permissions at once, separate their names with commas, and enclose the entire set in quotation marks (as in the example).","title":"Properties"},{"location":"files_folders/#paths","text":"In PowerShell, cmdlets whose names end with \"Path\" are used to work with file and directory paths. These cmdlets are commonly used to manipulate or retrieve information about file and directory paths, such as their locations, names, or extensions. One of the most commonly used cmdlets that ends with \"Path\" is the Split-Path cmdlet, which is used to split a file or directory path into its individual components, such as the directory, filename, and extension. For example, the command \"Split-Path C:\\Temp\\test.txt -Leaf\" would return \"test.txt\", while \"Split-Path C:\\Temp\\test.txt -Parent\" would return \"C:\\Temp\". Another example is the Join-Path cmdlet, which is used to combine two or more path strings into a single path. For example, the command \"Join-Path C:\\Temp test.txt\" would return \"C:\\Temp\\test.txt\". Other examples of cmdlets that end with \"Path\" include the Resolve-Path cmdlet, which is used to resolve a path to its full, absolute form, and the Test-Path cmdlet, which is used to test whether a file or directory path exists. In general, cmdlets that end with \"Path\" are useful for manipulating file and directory paths, which can be useful for scripting or automating tasks that involve working with files and directories. Cmdlet Description Test-Path Determines whether all elements of a path exist Join-Path Joins two or more parts of a path into a single path Split-Path Returns specific parts of a path Convert-Path Converts a path from a relative path to a full path or from a full path to a relative path","title":"Paths"},{"location":"files_folders/#directories-or-folders","text":"Operation Command Creation new-item -itemtype directory -name directory_name Deletion remove-item -path directory_name -Recurse Rename rename-item -path directory_name -newname new_directory_name -Recurse Move move-item -path directory_name -destination new_location Enter cd directory_name Show current directory Get-Location or pwd (same as Linux) Note .(dot) indicates the current directory and ..(dot dot) indicates the parent of the current directory.","title":"Directories or Folders"},{"location":"files_folders/#files","text":"Operation Command Creation new-item -itemtype file -name file_name [-value content] Deletion remove-item -path file_name Renaming rename-item -path file_name -newname new_name Moving move-item -path file_name -destination new_location Text files can be displayed on the console using the Get-Content command, which has the alias \"type\".","title":"Files"},{"location":"filtering/","text":"Command output can be filtered in several ways: Using wildcards in the parameters that support it. For example: get-service -name s * ...displays a list of services whose name starts with S. If the parameter does not support wildcards, the Where-Object (abbreviated Where) cmdlet can be used in the pipeline. For example: Get-Service | where -filter { $_ . Status -like \"Run*\" } ...displays a list of services whose status starts with \"Run\" Some of the comparison operators that can be used are: Operator Meaning -eq Equal -ne not equal -gt Greater than -ge Greater than or equal -lt Less Than -le Less than or equal -like Matches the expression with wildcards -notlike Does not match the expression with wildcards For example: Get-Service | where -filter { $_ . Status -eq \"Running\" } String comparisons are normally not case sensitive. If it is required to do so, a c is placed before the operators (-ceq, -cne, -cgt, -cge...). You can also use the connectives -and and -or. PowerShell also contains the -like operator and its case-sensitive companion, -clike. The -like operator resembles -eq but supports the use of the question mark (?) and asterisk (*) wildcard characters in string comparisons. Other, more advanced operators exist that are beyond the scope of this course. These operators include: The -in and -contains operators, which test whether an object exists in a collection. The -as operator, which tests whether an object is of a specified type. The -match and -cmatch operators, which compare a string to a regular expression. PowerShell also contains many operators that reverse the logic of the comparison, such as -notlike and -notin. For more information, see the help topic about_comparison_operators. Advanced Filtering The advanced syntax of Where-Object uses a filter script. A filter script is a script block that contains the comparison and that you pass by using the -FilterScript parameter. Within that script block, you can use the built-in $PSItem variable (or $_, which is also valid in versions of Windows PowerShell older than 3.0) to reference whatever object was piped into the command. Your filter script runs one time for each object that's piped into the command. When the filter script returns True, that object is passed down the pipeline as output. When the filter script returns False, that object is removed from the pipeline. The following two commands are functionally identical. The first uses the basic syntax, and the second uses the advanced syntax to do the same thing: ## basic syntax Get-Service | Where Status \u2013 eq Running ## advanced syntax Get-Service | Where-Object \u2013 FilterScript { $PSItem . Status \u2013 eq 'Running' } The -FilterScript parameter is positional, and most users omit it. Most users also use the Where alias or the ? alias, which is even shorter. Experienced Windows PowerShell users also use the $ variable instead of $PSItem, because only $ is allowed in Windows PowerShell 1.0 and Windows PowerShell 2.0. The following commands perform the same task as the previous two commands: Get-Service | Where { $PSItem . Status \u2013 eq 'Running' } Get-Service | ? { $_ . Status \u2013 eq 'Running' } Combining multiple criteria The advanced syntax allows you to combine multiple criteria by using the -and and -or Boolean, or logical, operators. Here's an example: Get-EventLog \u2013 LogName Security \u2013 Newest 100 | Where { $PSItem . EventID \u2013 eq 4672 \u2013 and $PSItem . EntryType \u2013 eq 'SuccessAudit' } Accessing properties without limitations Although the basic filtering syntax can access only the direct properties of the object being evaluated, the advanced syntax doesn't have that limitation. For example, to display a list of all the services that have names longer than eight characters, use this command: Get-Service | Where { $PSItem . Name . Length \u2013 gt 8 } Example It is required to draw a list that includes the 10 processes that are consuming the most virtual memory, not including Powershell. At the end, the total virtual memory that these 10 processes are consuming should be presented. The listing should only include the Name and VM columns. The first step (filtering Powershell processes) can be done like this: Get Process | where -filter { $_ . Name -notlike \"Powershell*\" } Then it is organized by the VM column, in descending order, and the columns that you want to show are specified: Get Process | where -filter { $_ . Name -notlike \"Powershell*\" } | sort VM -desc | select name , vm Finally, the Measure-Object cmdlet is used to find the total virtual memory usage: Get Process | where -filter { $_ . Name -notlike \"Powershell*\" } | sort VM | select name , vm -first 10 | Measure-Object -Property vm -sum Other Example Get-Process | Select-Object Name , ID , @{ n = 'VirtualMemory(MB)' ; e ={ '{0:N2}' \u2013 f ( $PSItem . VM / 1MB ) -as [Double] }}, @{ n = 'PagedMemory(MB)' ; e ={ '{0:N2}' \u2013 f ( $PSItem . PM / 1MB ) -as [Double] }} This example uses the Windows PowerShell -f formatting operator. When used with a string, the -f formatting operator instructs Windows PowerShell to replace one or more placeholders in the string with the specified values that follow the operator. In this example, the string that precedes the -f operator instructs Windows PowerShell what data to display. The string '{0:N2}' signifies displaying the first data item as a number with two decimal places. The original mathematical expression comes after the operator. It's in parentheses to make sure that it runs as a single unit. Best Practice is to always filter left , any filtering should occur as far to the left, or as close to the beginning of the command line, as possible. This will have a significant effect on performance.","title":"Filtering"},{"location":"filtering/#advanced-filtering","text":"The advanced syntax of Where-Object uses a filter script. A filter script is a script block that contains the comparison and that you pass by using the -FilterScript parameter. Within that script block, you can use the built-in $PSItem variable (or $_, which is also valid in versions of Windows PowerShell older than 3.0) to reference whatever object was piped into the command. Your filter script runs one time for each object that's piped into the command. When the filter script returns True, that object is passed down the pipeline as output. When the filter script returns False, that object is removed from the pipeline. The following two commands are functionally identical. The first uses the basic syntax, and the second uses the advanced syntax to do the same thing: ## basic syntax Get-Service | Where Status \u2013 eq Running ## advanced syntax Get-Service | Where-Object \u2013 FilterScript { $PSItem . Status \u2013 eq 'Running' } The -FilterScript parameter is positional, and most users omit it. Most users also use the Where alias or the ? alias, which is even shorter. Experienced Windows PowerShell users also use the $ variable instead of $PSItem, because only $ is allowed in Windows PowerShell 1.0 and Windows PowerShell 2.0. The following commands perform the same task as the previous two commands: Get-Service | Where { $PSItem . Status \u2013 eq 'Running' } Get-Service | ? { $_ . Status \u2013 eq 'Running' }","title":"Advanced Filtering"},{"location":"filtering/#combining-multiple-criteria","text":"The advanced syntax allows you to combine multiple criteria by using the -and and -or Boolean, or logical, operators. Here's an example: Get-EventLog \u2013 LogName Security \u2013 Newest 100 | Where { $PSItem . EventID \u2013 eq 4672 \u2013 and $PSItem . EntryType \u2013 eq 'SuccessAudit' }","title":"Combining multiple criteria"},{"location":"filtering/#accessing-properties-without-limitations","text":"Although the basic filtering syntax can access only the direct properties of the object being evaluated, the advanced syntax doesn't have that limitation. For example, to display a list of all the services that have names longer than eight characters, use this command: Get-Service | Where { $PSItem . Name . Length \u2013 gt 8 }","title":"Accessing properties without limitations"},{"location":"filtering/#example","text":"It is required to draw a list that includes the 10 processes that are consuming the most virtual memory, not including Powershell. At the end, the total virtual memory that these 10 processes are consuming should be presented. The listing should only include the Name and VM columns. The first step (filtering Powershell processes) can be done like this: Get Process | where -filter { $_ . Name -notlike \"Powershell*\" } Then it is organized by the VM column, in descending order, and the columns that you want to show are specified: Get Process | where -filter { $_ . Name -notlike \"Powershell*\" } | sort VM -desc | select name , vm Finally, the Measure-Object cmdlet is used to find the total virtual memory usage: Get Process | where -filter { $_ . Name -notlike \"Powershell*\" } | sort VM | select name , vm -first 10 | Measure-Object -Property vm -sum","title":"Example"},{"location":"filtering/#other-example","text":"Get-Process | Select-Object Name , ID , @{ n = 'VirtualMemory(MB)' ; e ={ '{0:N2}' \u2013 f ( $PSItem . VM / 1MB ) -as [Double] }}, @{ n = 'PagedMemory(MB)' ; e ={ '{0:N2}' \u2013 f ( $PSItem . PM / 1MB ) -as [Double] }} This example uses the Windows PowerShell -f formatting operator. When used with a string, the -f formatting operator instructs Windows PowerShell to replace one or more placeholders in the string with the specified values that follow the operator. In this example, the string that precedes the -f operator instructs Windows PowerShell what data to display. The string '{0:N2}' signifies displaying the first data item as a number with two decimal places. The original mathematical expression comes after the operator. It's in parentheses to make sure that it runs as a single unit. Best Practice is to always filter left , any filtering should occur as far to the left, or as close to the beginning of the command line, as possible. This will have a significant effect on performance.","title":"Other Example"},{"location":"get_member/","text":"The Get-Member cmdlet in PowerShell is an essential tool for exploring objects and their properties, methods, and events. It retrieves the members (properties, methods, and events) of an object and displays their definitions and syntax, which can help users understand the object and how to interact with it. Syntax The syntax for using Get-Member is as follows: Get-Member [ -InputObject ] < PSObject > [ -MemberType { Property | Method | Event | NoteProperty | AliasProperty | ScriptProperty | PropertySet | All }] [ -Force ] [ -Static ] Here's an explanation of the parameters: InputObject: specifies the object for which to retrieve the members. It can be piped to Get-Member or specified as an argument. MemberType: specifies the type of members to retrieve. It can be one of the following: Property (instance properties), Method (instance methods), Event (instance events), NoteProperty (extended properties), AliasProperty (aliases), ScriptProperty (script properties), PropertySet (property sets), or All (all members). Force: forces Get-Member to retrieve hidden or non-public members. Static: retrieves static members of a class. Examples View the properties of an object: Get-Process | Get-Member -MemberType Property This command retrieves the list of properties associated with the Get-Process cmdlet. View the methods of an object: Get-ChildItem | Get-Member -MemberType Method This command retrieves the list of methods associated with the Get-ChildItem cmdlet. Filter the results by name or type: Get-Process | Get-Member -Name \"<Name>\" This command retrieves only the properties with the name \" \" from the Get-Process cmdlet. View the static properties of a .NET class: [System.Math] | Get-Member -Static -MemberType Property This command retrieves the static properties of the .NET class System.Math.","title":"GetMember"},{"location":"get_member/#syntax","text":"The syntax for using Get-Member is as follows: Get-Member [ -InputObject ] < PSObject > [ -MemberType { Property | Method | Event | NoteProperty | AliasProperty | ScriptProperty | PropertySet | All }] [ -Force ] [ -Static ] Here's an explanation of the parameters: InputObject: specifies the object for which to retrieve the members. It can be piped to Get-Member or specified as an argument. MemberType: specifies the type of members to retrieve. It can be one of the following: Property (instance properties), Method (instance methods), Event (instance events), NoteProperty (extended properties), AliasProperty (aliases), ScriptProperty (script properties), PropertySet (property sets), or All (all members). Force: forces Get-Member to retrieve hidden or non-public members. Static: retrieves static members of a class.","title":"Syntax"},{"location":"get_member/#examples","text":"View the properties of an object: Get-Process | Get-Member -MemberType Property This command retrieves the list of properties associated with the Get-Process cmdlet. View the methods of an object: Get-ChildItem | Get-Member -MemberType Method This command retrieves the list of methods associated with the Get-ChildItem cmdlet. Filter the results by name or type: Get-Process | Get-Member -Name \"<Name>\" This command retrieves only the properties with the name \" \" from the Get-Process cmdlet. View the static properties of a .NET class: [System.Math] | Get-Member -Static -MemberType Property This command retrieves the static properties of the .NET class System.Math.","title":"Examples"},{"location":"getalias/","text":"In PowerShell, an alias is an alternate name or shortcut that you can use to refer to a cmdlet, function, executable, or script. Aliases can be used to save time and typing effort, and they can also be customized to match your preferences and habits. For example, instead of typing Get-ChildItem every time you want to list the contents of a directory, you can use the alias ls instead. Similarly, instead of typing Set-Location to change the current directory, you can use the alias cd instead. PowerShell comes with a set of built-in aliases that map common commands to shorter names, such as ls for Get-ChildItem, cd for Set-Location, and dir for Get-ChildItem -Directory. You can use the Get-Alias cmdlet to view the list of built-in aliases. In addition to the built-in aliases, you can create your own aliases or modify existing ones using the New-Alias and Set-Alias cmdlets. For example, you could create an alias wd for Set-Location -Path C:\\Windows, or you could modify the ls alias to include the -Force parameter by using Set-Alias. ls Get-ChildItem -Force While aliases can be useful in PowerShell for saving time and reducing typing, there are also some limitations and potential issues to be aware of: Clarity: Aliases can make code harder to understand, especially for other users who may not be familiar with the specific aliases you're using. It's generally recommended to use the full cmdlet names in scripts and functions to make the code more clear and self-explanatory. Conflicts: Multiple aliases can be defined for the same cmdlet, and aliases can also be defined for other aliases. This can lead to confusion and potential conflicts, especially when using modules or scripts that define their own aliases. Portability: Aliases are specific to the PowerShell session in which they are defined. If you use a script or module that relies on specific aliases, you may run into issues if those aliases are not defined on the system where the script is being run. Autocomplete: PowerShell's autocomplete feature may not work with aliases, depending on the specific environment and tools you're using. Overall, while aliases can be useful in certain situations, it's important to use them judiciously and be aware of their limitations and potential issues. It's generally best to use the full cmdlet names in scripts and functions to ensure clarity and portability, and to avoid potential conflicts with other aliases or scripts. Get-Alias Get-Alias is a PowerShell cmdlet that is used to display the aliases for cmdlets, functions, and scripts. It allows you to see the built-in aliases that are available in PowerShell, as well as any custom aliases that you or other users have created. Here are some common ways to use Get-Alias: List all aliases You can use the Get-Alias cmdlet without any parameters to list all the aliases available in your PowerShell session. Get-Alias List aliases for a specific command You can use the -Definition parameter followed by the name of the command to list all the aliases for that command. Get-Alias -Definition Get-ChildItem Search for a specific alias You can use the -Name parameter followed by a search pattern to find a specific alias or a group of aliases that match the pattern. Get-Alias -Name * s * Export aliases to a file You can use the Export-Alias cmdlet with the -Path parameter followed by the name and location of the file to export the aliases to a file. Get-Alias | Export-Alias -Path C :\\ Aliases . txt Import aliases from a file You can use the Import-Alias cmdlet with the -Path parameter followed by the name and location of the file to import the aliases from a file. Import-Alias -Path C :\\ Aliases . txt Overall, the Get-Alias cmdlet is a powerful tool for managing and customizing your PowerShell experience. It can help you save time and increase your productivity by allowing you to use shorthand commands and aliases that are easier to remember and type. New-Alias In PowerShell, the New-Alias cmdlet is used to create a new alias for a cmdlet, function, or script. The most common usage of New-Alias is to create a shorter, more convenient name for a longer, more complex command that you use frequently. For example, if you use the Get-ChildItem cmdlet frequently to list the contents of a directory, you could create an alias ls that maps to Get-ChildItem. Then, instead of typing Get-ChildItem, you could simply type ls to achieve the same result. This can save you time and typing effort, especially when working with long or complex commands. Here is an example of how to use New-Alias to create an alias: New-Alias -Name ls -Value Get-ChildItem This creates a new alias named ls that maps to the Get-ChildItem cmdlet. You can then use ls to list the contents of a directory, like this: ls C :\\ Windows This will list the contents of the C:\\Windows directory using the Get-ChildItem cmdlet, but you can use the shorter ls alias instead. Another example: new-alias -Name np -Value Notepad Another common use case for New-Alias is to create an alias for a function or script that you use frequently. For example, if you have a script named MyScript.ps1 that you want to run frequently, you could create an alias like this: New-Alias -Name myscript -Value C :\\ Scripts \\ MyScript . ps1 This creates a new alias named myscript that maps to the MyScript.ps1 script located at C:\\Scripts\\MyScript.ps1. You can then use myscript to run the script, like this: myscript This will run the MyScript.ps1 script, but you can use the shorter myscript alias instead. Overall, New-Alias is a useful cmdlet for creating custom aliases that can save you time and typing effort, especially when working with long or complex commands. Set-Alias In PowerShell, the Set-Alias cmdlet is used to change the definition of an existing alias. The most common usage of Set-Alias is to update an existing alias to map to a different cmdlet, function, or script. For example, if you have an alias named ls that currently maps to the Get-ChildItem cmdlet, but you want to change it to map to the Set-Location cmdlet instead, you can use Set-Alias like this: Set-Alias -Name ls -Value Set-Location This changes the definition of the ls alias to map to the Set-Location cmdlet instead of Get-ChildItem. You can then use ls to change to a different directory, like this: ls C :\\ Windows This will change to the C:\\Windows directory using the Set-Location cmdlet, which is now mapped to the ls alias. Another common use case for Set-Alias is to update an alias that was created by a module or script that you are using. For example, if a module that you are using creates an alias named gci that maps to the Get-ChildItem cmdlet, but you want to change it to map to a different cmdlet or function, you can use Set-Alias to update it. Set-Alias -Name gci -Value Get-Content This changes the definition of the gci alias to map to the Get-Content cmdlet instead of Get-ChildItem. You can then use gci to read the contents of a file, like this: gci C :\\ MyFile . txt This will read the contents of the C:\\MyFile.txt file using the Get-Content cmdlet, which is now mapped to the gci alias. Overall, Set-Alias is a useful cmdlet for updating existing aliases to map to different cmdlets, functions, or scripts. This can help you customize your PowerShell environment to better suit your needs and preferences. Other cmdlets In PowerShell, the Import-Alias, Export-Alias, and Remove-Alias cmdlets are used for managing aliases. Here's a brief explanation of each: Import-Alias This cmdlet is used to import a list of aliases from a file or another PowerShell session. It can be useful for setting up a consistent set of aliases across multiple systems or sessions. For example, you could use Import-Alias to load a set of aliases defined in a PowerShell profile or script. Example: Import-Alias -Path C :\\ Aliases \\ MyAliases . txt Export-Alias This cmdlet is used to export a list of aliases to a file or another PowerShell session. It can be useful for backing up or sharing sets of aliases. For example, you could use Export-Alias to save a set of aliases defined on your system and then import them on another system. Example: Export-Alias -Path C :\\ Aliases \\ MyAliases . txt Remove-Alias This cmdlet is used to remove an existing alias. It can be useful for cleaning up aliases that are no longer needed or that are causing conflicts with other aliases or cmdlets. Example: Remove-Alias -Name myAlias Note that when using Remove-Alias, you need to specify the name of the alias you want to remove. If the alias is defined in a PowerShell module or script, you may also need to remove it from those locations in order to fully clean up the alias.","title":"GetAlias"},{"location":"getalias/#get-alias","text":"Get-Alias is a PowerShell cmdlet that is used to display the aliases for cmdlets, functions, and scripts. It allows you to see the built-in aliases that are available in PowerShell, as well as any custom aliases that you or other users have created. Here are some common ways to use Get-Alias: List all aliases You can use the Get-Alias cmdlet without any parameters to list all the aliases available in your PowerShell session. Get-Alias List aliases for a specific command You can use the -Definition parameter followed by the name of the command to list all the aliases for that command. Get-Alias -Definition Get-ChildItem Search for a specific alias You can use the -Name parameter followed by a search pattern to find a specific alias or a group of aliases that match the pattern. Get-Alias -Name * s * Export aliases to a file You can use the Export-Alias cmdlet with the -Path parameter followed by the name and location of the file to export the aliases to a file. Get-Alias | Export-Alias -Path C :\\ Aliases . txt Import aliases from a file You can use the Import-Alias cmdlet with the -Path parameter followed by the name and location of the file to import the aliases from a file. Import-Alias -Path C :\\ Aliases . txt Overall, the Get-Alias cmdlet is a powerful tool for managing and customizing your PowerShell experience. It can help you save time and increase your productivity by allowing you to use shorthand commands and aliases that are easier to remember and type.","title":"Get-Alias"},{"location":"getalias/#new-alias","text":"In PowerShell, the New-Alias cmdlet is used to create a new alias for a cmdlet, function, or script. The most common usage of New-Alias is to create a shorter, more convenient name for a longer, more complex command that you use frequently. For example, if you use the Get-ChildItem cmdlet frequently to list the contents of a directory, you could create an alias ls that maps to Get-ChildItem. Then, instead of typing Get-ChildItem, you could simply type ls to achieve the same result. This can save you time and typing effort, especially when working with long or complex commands. Here is an example of how to use New-Alias to create an alias: New-Alias -Name ls -Value Get-ChildItem This creates a new alias named ls that maps to the Get-ChildItem cmdlet. You can then use ls to list the contents of a directory, like this: ls C :\\ Windows This will list the contents of the C:\\Windows directory using the Get-ChildItem cmdlet, but you can use the shorter ls alias instead. Another example: new-alias -Name np -Value Notepad Another common use case for New-Alias is to create an alias for a function or script that you use frequently. For example, if you have a script named MyScript.ps1 that you want to run frequently, you could create an alias like this: New-Alias -Name myscript -Value C :\\ Scripts \\ MyScript . ps1 This creates a new alias named myscript that maps to the MyScript.ps1 script located at C:\\Scripts\\MyScript.ps1. You can then use myscript to run the script, like this: myscript This will run the MyScript.ps1 script, but you can use the shorter myscript alias instead. Overall, New-Alias is a useful cmdlet for creating custom aliases that can save you time and typing effort, especially when working with long or complex commands.","title":"New-Alias"},{"location":"getalias/#set-alias","text":"In PowerShell, the Set-Alias cmdlet is used to change the definition of an existing alias. The most common usage of Set-Alias is to update an existing alias to map to a different cmdlet, function, or script. For example, if you have an alias named ls that currently maps to the Get-ChildItem cmdlet, but you want to change it to map to the Set-Location cmdlet instead, you can use Set-Alias like this: Set-Alias -Name ls -Value Set-Location This changes the definition of the ls alias to map to the Set-Location cmdlet instead of Get-ChildItem. You can then use ls to change to a different directory, like this: ls C :\\ Windows This will change to the C:\\Windows directory using the Set-Location cmdlet, which is now mapped to the ls alias. Another common use case for Set-Alias is to update an alias that was created by a module or script that you are using. For example, if a module that you are using creates an alias named gci that maps to the Get-ChildItem cmdlet, but you want to change it to map to a different cmdlet or function, you can use Set-Alias to update it. Set-Alias -Name gci -Value Get-Content This changes the definition of the gci alias to map to the Get-Content cmdlet instead of Get-ChildItem. You can then use gci to read the contents of a file, like this: gci C :\\ MyFile . txt This will read the contents of the C:\\MyFile.txt file using the Get-Content cmdlet, which is now mapped to the gci alias. Overall, Set-Alias is a useful cmdlet for updating existing aliases to map to different cmdlets, functions, or scripts. This can help you customize your PowerShell environment to better suit your needs and preferences.","title":"Set-Alias"},{"location":"getalias/#other-cmdlets","text":"In PowerShell, the Import-Alias, Export-Alias, and Remove-Alias cmdlets are used for managing aliases. Here's a brief explanation of each:","title":"Other cmdlets"},{"location":"getalias/#import-alias","text":"This cmdlet is used to import a list of aliases from a file or another PowerShell session. It can be useful for setting up a consistent set of aliases across multiple systems or sessions. For example, you could use Import-Alias to load a set of aliases defined in a PowerShell profile or script. Example: Import-Alias -Path C :\\ Aliases \\ MyAliases . txt","title":"Import-Alias"},{"location":"getalias/#export-alias","text":"This cmdlet is used to export a list of aliases to a file or another PowerShell session. It can be useful for backing up or sharing sets of aliases. For example, you could use Export-Alias to save a set of aliases defined on your system and then import them on another system. Example: Export-Alias -Path C :\\ Aliases \\ MyAliases . txt","title":"Export-Alias"},{"location":"getalias/#remove-alias","text":"This cmdlet is used to remove an existing alias. It can be useful for cleaning up aliases that are no longer needed or that are causing conflicts with other aliases or cmdlets. Example: Remove-Alias -Name myAlias Note that when using Remove-Alias, you need to specify the name of the alias you want to remove. If the alias is defined in a PowerShell module or script, you may also need to remove it from those locations in order to fully clean up the alias.","title":"Remove-Alias"},{"location":"gethelp/","text":"The Get-Help cmdlet is a powerful tool in PowerShell that provides information about commands, cmdlets, and modules. It has several parameters that allow you to customize the help output to suit your needs. Here are some of the most common parameters for the Get-Help cmdlet with examples: 1. -Name This parameter specifies the name of the command or cmdlet that you want help with. For example: Get-Help -Name Get-ChildItem This command will display help for the Get-ChildItem cmdlet, which is used to list the contents of a directory. 2. -Category This parameter specifies the category of help that you want to display. For example: Get-Help -Category Navigation This command will display all cmdlets related to navigation. 3. -Detailed This parameter displays detailed help information, including examples and parameter descriptions. For example: Get-Help -Name Get-ChildItem -Detailed This command will display detailed help information for the Get-ChildItem cmdlet. 4. -Examples This parameter displays examples of how to use the command or cmdlet. For example: Get-Help -Name Get-ChildItem -Examples This command will display examples of how to use the Get-ChildItem cmdlet. 5. -Full This parameter displays the full help information, including syntax and parameter descriptions. For example: Get-Help -Name Get-ChildItem -Full This command will display the full help information for the Get-ChildItem cmdlet. 6. -Parameter This parameter displays help information for a specific parameter of a command or cmdlet. For example: Get-Help -Name Get-ChildItem -Parameter Path This command will display help information for the Path parameter of the Get-ChildItem cmdlet. 7. -Online This parameter opens the online version of the help file for the command or cmdlet. For example: ``` Get-Help -Name Get-ChildItem -Online ``` This command will open the online version of the help file for the Get-ChildItem cmdlet. In summary, the Get-Help cmdlet is a versatile tool that can provide a lot of information about commands, cmdlets, and modules in PowerShell. By using the appropriate parameters, you can customize the help output to suit your needs and become more proficient in PowerShell.","title":"GetHelp"},{"location":"gethelp/#1-name","text":"This parameter specifies the name of the command or cmdlet that you want help with. For example: Get-Help -Name Get-ChildItem This command will display help for the Get-ChildItem cmdlet, which is used to list the contents of a directory.","title":"1. -Name"},{"location":"gethelp/#2-category","text":"This parameter specifies the category of help that you want to display. For example: Get-Help -Category Navigation This command will display all cmdlets related to navigation.","title":"2. -Category"},{"location":"gethelp/#3-detailed","text":"This parameter displays detailed help information, including examples and parameter descriptions. For example: Get-Help -Name Get-ChildItem -Detailed This command will display detailed help information for the Get-ChildItem cmdlet.","title":"3. -Detailed"},{"location":"gethelp/#4-examples","text":"This parameter displays examples of how to use the command or cmdlet. For example: Get-Help -Name Get-ChildItem -Examples This command will display examples of how to use the Get-ChildItem cmdlet.","title":"4. -Examples"},{"location":"gethelp/#5-full","text":"This parameter displays the full help information, including syntax and parameter descriptions. For example: Get-Help -Name Get-ChildItem -Full This command will display the full help information for the Get-ChildItem cmdlet.","title":"5. -Full"},{"location":"gethelp/#6-parameter","text":"This parameter displays help information for a specific parameter of a command or cmdlet. For example: Get-Help -Name Get-ChildItem -Parameter Path This command will display help information for the Path parameter of the Get-ChildItem cmdlet.","title":"6. -Parameter"},{"location":"gethelp/#7-online","text":"This parameter opens the online version of the help file for the command or cmdlet. For example: ``` Get-Help -Name Get-ChildItem -Online ``` This command will open the online version of the help file for the Get-ChildItem cmdlet. In summary, the Get-Help cmdlet is a versatile tool that can provide a lot of information about commands, cmdlets, and modules in PowerShell. By using the appropriate parameters, you can customize the help output to suit your needs and become more proficient in PowerShell.","title":"7. -Online"},{"location":"out_format/","text":"Here is a detailed table of the most common cmdlets available for reading and writing files in different formats in PowerShell: File Format Cmdlet for Reading Cmdlet for Writing Text Files (.txt) Get-Content Set-Content CSV Files (.csv) Import-Csv Export-Csv JSON Files (.json) ConvertFrom-Json ConvertTo-Json XML Files (.xml) Select-Xml Export-Clixml HTML Files Get-Content ConvertTo-Html Here are some examples of how to use these cmdlets: Text Get-Content The Get-Content cmdlet gets the content of the item at the location specified by the path, such as the text in a file or the content of a function. For files, the content is read one line at a time and returns a collection of objects, each of which represents a line of content. Beginning in PowerShell 3.0, Get-Content can also get a specified number of lines from the beginning or end of an item. $computers = Get-Content C :\\ Scripts \\ computers . txt You can use wildcards in the path for Get-Content to obtain data from multiple files at a time. When you use wildcards for the path, you can modify the files selected by using the -Include and -Exclude parameters. When you use -Include, only the specified patterns are included. When you use -Exclude, all files are included except the patterns specified. Using wildcards can be useful when you want to scan all text files for specific content such as an error in log files. Get-Content -Path \"C:\\Scripts\\*\" -Include \"*.txt\" , \"*.log\" You can limit the amount of data that you retrieve with Get-Content by using the -TotalCount and -Tail parameters. The -TotalCount parameter specifies how many lines should be retrieved from the beginning of a file. The -Tail parameter specifies how many lines to retrieve from the end of a file. Get-Content C :\\ Scripts \\ computers . txt -TotalCount 10 Set-Content Set-Content is a string-processing cmdlet that writes new content or replaces the content in a file. Set-Content replaces the existing content and differs from the Add-Content cmdlet that appends content to a file. To send content to Set-Content you can use the Value parameter on the command line or send content through the pipeline. If you need to create files or directories for the following examples, see New-Item. Set-Content C :\\ example . txt \"This is some text.\" This command will write the text \"This is some text\" to the file file.txt located in the C:\\ directory. If the file already exists, its content will be overwritten. If the file does not exist, it will be created. Add-Content The Add-Content cmdlet appends content to a specified item or file. You can specify the content by typing the content in the command or by specifying an object that contains the content. If you need to create files or directories for the following examples, see New-Item. Add-Content -Path .\\*. txt -Exclude help * -Value 'End of file' The Path parameter specifies all .txt files in the current directory, but the Exclude parameter ignores file names that match the specified pattern. The Value parameter specifies the text string that is written to the files. Use Get-Content to display the contents of these files. Clear-Content The Clear-Content cmdlet deletes the contents of an item, such as deleting the text from a file, but it does not delete the item. As a result, the item exists, but it is empty. Clear-Content is similar to Clear-Item, but it works on items with contents, instead of items with values. Clear-Content \"..\\SmpUsers\\*\\init.txt\" This command deletes all of the content from the init.txt files in all subdirectories of the SmpUsers directory. The files are not deleted, but they are empty. CSV A CSV (Comma Separated Values) file is a plain text file format that stores tabular data in a simple, structured way, where each line represents a row, and the data within each row is separated by commas. The first line of the file usually contains the headers, which specify the column names. When working with CSV files in PowerShell, it's important to keep in mind that the file format is very simple and flexible, but can also be prone to errors if the data is not well-formed. It's important to validate and clean the data before working with it, and to always specify the correct headers and data types when importing or exporting CSV files. I/O Import-Csv C :\\ example . csv Import-CSV This cmdlet reads a CSV file and creates custom objects for each row, using the headers as the property names. You can then work with these objects as you would with any other PowerShell object. Here's an example: $csv = Import-CSV C :\\ data \\ users . csv foreach ( $user in $csv ) { Write-Output $user . Name } This code imports a CSV file containing user data, and then outputs the Name property of each user object. Export-CSV $data = @{ \"Name\" = \"John\" ; \"Age\" = 30 } $data | Export-Csv C :\\ example . csv -NoTypeInformation This cmdlet writes a collection of objects to a CSV file, using the object properties as the column names. Here's an example: $users = Get-ADUser -Filter * $users | Select-Object Name , EmailAddress | Export-CSV C :\\ data \\ users . csv -NoTypeInformation This code retrieves all users from Active Directory, selects the Name and EmailAddress properties, and then exports them to a CSV file. Conversion To/From ConvertTo-CSV This cmdlet converts a collection of objects to a CSV format, but does not write it to a file. You can then use other cmdlets (like Out-File or Set-Content) to write the CSV to a file. Here's an example: $processes = Get-Process $processes | Select-Object Name , ID , CPU | ConvertTo-CSV | Out-File C :\\ data \\ processes . csv This code retrieves information about running processes, selects the Name, ID, and CPU properties, converts it to CSV format, and then writes it to a file. Here's another example of how to use ConvertTo-CSV: # Create an array of objects $people = @( [PSCustomObject] @{ Name = \"John\" Age = 35 Occupation = \"Software Engineer\" }, [PSCustomObject] @{ Name = \"Jane\" Age = 28 Occupation = \"Project Manager\" } ) # Convert the objects to CSV format $csv = $people | ConvertTo-CSV # Output the CSV data $csv In this example, we first create an array of custom objects representing people with different attributes like name, age, and occupation. We then pipe this array to the ConvertTo-CSV cmdlet to convert it to CSV format and store the output in a variable called $csv. Finally, we output the CSV data using the $csv variable. ConvertFrom-CSV ConvertFrom-CSV is a cmdlet that allows you to convert CSV data back into PowerShell objects. This cmdlet takes the input CSV data, converts it into PowerShell objects, and outputs the objects. Here's an example of how to use ConvertFrom-CSV: # Convert CSV data to PowerShell objects $csvData = @\" Name,Age,Occupation John,35,Software Engineer Jane,28,Project Manager \"@ | ConvertFrom-CSV # Output the objects $csvData In this example, we first define a CSV string containing data about people, with each person represented as a row with columns for name, age, and occupation. We then pipe this CSV string to the ConvertFrom-CSV cmdlet to convert it into PowerShell objects and store the output in a variable called $csvData. Finally, we output the objects using the $csvData variable. JSON JavaScript Object Notation (JSON) is a lightweight data format that's similar to XML, because it can represent multiple layers of data. JSON is a lightweight data-interchange format compared to XML because of its simpler syntax. Windows PowerShell doesn't include cmdlets that import or export JSON data directly from a file. Instead, if you have JSON data stored in a file, you can retrieve the data by using Get-Content and then convert the data by using the ConvertFrom-Json cmdlet. Reading a JSON file $json = Get-Content .\\ example . json | ConvertFrom-Json Writing to a JSON file $data = @{ \"Name\" = \"John\" ; \"Age\" = 30 } $data | ConvertTo-Json | Out-File .\\ example . json Testing a JSON file \"{'name': 'Ashley', 'age': 25}\" | Test-Json XML XML is a more complex data storage format than CSV files. The main advantage of using XML for Windows PowerShell is that it can hold multiple levels of data. A CSV file works with a table of information in which the columns are the object properties. In a CSV file, it's difficult to work with multivalued attributes, whereas XML can easily represent multivalued attributes or even objects that have other objects as a property. Reading an XML file The use of Import-Clixml to retrieve data from an XML file creates an array of objects. Because XML can be complex, you might not easily be able to understand the object properties by reviewing the contents of the XML file directly. You can use Get-Member to identify the properties of the data that you import. $users = Import-Clixml C :\\ Scripts \\ Users . xml You can limit the data retrieved by Import-Clixml by using the -First and -Skip parameters. The -First parameter specifies to retrieve only the specified number of objects from the beginning of the XML file. The -Skip parameter specifies to ignore the specified number of objects from the beginning of the XML file and to retrieve all the remaining objects. $xml = Select-Xml -Path C :\\ example . xml -XPath \"//book\" Writing to an XML file $data = @{ \"Name\" = \"John\" ; \"Age\" = 30 } $data | Export-Clixml C :\\ example . xml HTML PowerShell provides a variety of cmdlets that can be used to manipulate HTML files, such as Invoke-WebRequest, Invoke-RestMethod, and ConvertTo-Html. Here are some examples of how to use these cmdlets to manipulate HTML files in PowerShell: Downloading an HTML file using Invoke-WebRequest: Invoke-WebRequest -Uri https :// example . com -OutFile example . html Extracting data from an HTML file using Invoke-RestMethod: $response = Invoke-RestMethod -Uri https :// example . com $response . Tables [ 0 ] | ConvertTo-Html -Fragment Converting a PowerShell object to an HTML table using ConvertTo-Html: Get-Process | Select-Object Name , CPU , WorkingSet | ConvertTo-Html -Head \"Process Report\" -PreContent \"<h1>Current Processes</h1>\" These are just a few examples of how to manipulate HTML files in PowerShell. The possibilities are endless, and these cmdlets can be combined with other PowerShell commands to perform more complex tasks. ConvertTo-Html creates a simple list or table that's coded as HTML. You can control the HTML format in a limited way through a variety of parameters, such as: \u2011Head. Specifies the content of an HTML head section. \u2011Title. Sets the value of the HTML title tag. \u2011PreContent. Defines any content that should display before the table or list output. \u2011PostContent. Defines any content that should display after the table or list output. OUTPUT TO FILE OR PRINTER If you want to save the output of a command to an unformatted plain text file, you can use either of these methods (using the get-process command as an example): get-process > processes.txt (using redirection) get-process | out-file processes.txt (using the pipeline) Both versions are functionally equivalent, but the out-file command can receive parameters to change the line width and to avoid overwriting an existing file. To read a plain text file as text strings, you use the Get-Content cmdlet (with aliases cat or type): Get-Content processes . txt PowerShell also supports the text redirection operators (> and >>) that cmd.exe uses. These operators act as an alias for Out-File. The greater than sign (>) at the end of a pipeline directs output to a file, overwriting the content. Two consecutive greater than signs (>>) direct output to a file, appending the output to any text already in the file. Out-File is the easiest way to move data from PowerShell to external storage. However, the text files that Out-File creates are usually intended for reviewing by a person. Therefore, reading the data back into Windows PowerShell in a way that enables data manipulation, sorting, selection, and measurement is frequently difficult or impractical. Out-File doesn't produce any output of its own, which means that the command doesn't put objects into the pipeline. After you run the command, you should expect no output on the screen. If you want to send the output of a command to the printer, you use the out-printer cmdlet: get-process | out-printer","title":"Output Format"},{"location":"out_format/#text","text":"","title":"Text"},{"location":"out_format/#get-content","text":"The Get-Content cmdlet gets the content of the item at the location specified by the path, such as the text in a file or the content of a function. For files, the content is read one line at a time and returns a collection of objects, each of which represents a line of content. Beginning in PowerShell 3.0, Get-Content can also get a specified number of lines from the beginning or end of an item. $computers = Get-Content C :\\ Scripts \\ computers . txt You can use wildcards in the path for Get-Content to obtain data from multiple files at a time. When you use wildcards for the path, you can modify the files selected by using the -Include and -Exclude parameters. When you use -Include, only the specified patterns are included. When you use -Exclude, all files are included except the patterns specified. Using wildcards can be useful when you want to scan all text files for specific content such as an error in log files. Get-Content -Path \"C:\\Scripts\\*\" -Include \"*.txt\" , \"*.log\" You can limit the amount of data that you retrieve with Get-Content by using the -TotalCount and -Tail parameters. The -TotalCount parameter specifies how many lines should be retrieved from the beginning of a file. The -Tail parameter specifies how many lines to retrieve from the end of a file. Get-Content C :\\ Scripts \\ computers . txt -TotalCount 10","title":"Get-Content"},{"location":"out_format/#set-content","text":"Set-Content is a string-processing cmdlet that writes new content or replaces the content in a file. Set-Content replaces the existing content and differs from the Add-Content cmdlet that appends content to a file. To send content to Set-Content you can use the Value parameter on the command line or send content through the pipeline. If you need to create files or directories for the following examples, see New-Item. Set-Content C :\\ example . txt \"This is some text.\" This command will write the text \"This is some text\" to the file file.txt located in the C:\\ directory. If the file already exists, its content will be overwritten. If the file does not exist, it will be created.","title":"Set-Content"},{"location":"out_format/#add-content","text":"The Add-Content cmdlet appends content to a specified item or file. You can specify the content by typing the content in the command or by specifying an object that contains the content. If you need to create files or directories for the following examples, see New-Item. Add-Content -Path .\\*. txt -Exclude help * -Value 'End of file' The Path parameter specifies all .txt files in the current directory, but the Exclude parameter ignores file names that match the specified pattern. The Value parameter specifies the text string that is written to the files. Use Get-Content to display the contents of these files.","title":"Add-Content"},{"location":"out_format/#clear-content","text":"The Clear-Content cmdlet deletes the contents of an item, such as deleting the text from a file, but it does not delete the item. As a result, the item exists, but it is empty. Clear-Content is similar to Clear-Item, but it works on items with contents, instead of items with values. Clear-Content \"..\\SmpUsers\\*\\init.txt\" This command deletes all of the content from the init.txt files in all subdirectories of the SmpUsers directory. The files are not deleted, but they are empty.","title":"Clear-Content"},{"location":"out_format/#csv","text":"A CSV (Comma Separated Values) file is a plain text file format that stores tabular data in a simple, structured way, where each line represents a row, and the data within each row is separated by commas. The first line of the file usually contains the headers, which specify the column names. When working with CSV files in PowerShell, it's important to keep in mind that the file format is very simple and flexible, but can also be prone to errors if the data is not well-formed. It's important to validate and clean the data before working with it, and to always specify the correct headers and data types when importing or exporting CSV files.","title":"CSV"},{"location":"out_format/#io","text":"Import-Csv C :\\ example . csv","title":"I/O"},{"location":"out_format/#import-csv","text":"This cmdlet reads a CSV file and creates custom objects for each row, using the headers as the property names. You can then work with these objects as you would with any other PowerShell object. Here's an example: $csv = Import-CSV C :\\ data \\ users . csv foreach ( $user in $csv ) { Write-Output $user . Name } This code imports a CSV file containing user data, and then outputs the Name property of each user object.","title":"Import-CSV"},{"location":"out_format/#export-csv","text":"$data = @{ \"Name\" = \"John\" ; \"Age\" = 30 } $data | Export-Csv C :\\ example . csv -NoTypeInformation This cmdlet writes a collection of objects to a CSV file, using the object properties as the column names. Here's an example: $users = Get-ADUser -Filter * $users | Select-Object Name , EmailAddress | Export-CSV C :\\ data \\ users . csv -NoTypeInformation This code retrieves all users from Active Directory, selects the Name and EmailAddress properties, and then exports them to a CSV file.","title":"Export-CSV"},{"location":"out_format/#conversion-tofrom","text":"","title":"Conversion To/From"},{"location":"out_format/#convertto-csv","text":"This cmdlet converts a collection of objects to a CSV format, but does not write it to a file. You can then use other cmdlets (like Out-File or Set-Content) to write the CSV to a file. Here's an example: $processes = Get-Process $processes | Select-Object Name , ID , CPU | ConvertTo-CSV | Out-File C :\\ data \\ processes . csv This code retrieves information about running processes, selects the Name, ID, and CPU properties, converts it to CSV format, and then writes it to a file. Here's another example of how to use ConvertTo-CSV: # Create an array of objects $people = @( [PSCustomObject] @{ Name = \"John\" Age = 35 Occupation = \"Software Engineer\" }, [PSCustomObject] @{ Name = \"Jane\" Age = 28 Occupation = \"Project Manager\" } ) # Convert the objects to CSV format $csv = $people | ConvertTo-CSV # Output the CSV data $csv In this example, we first create an array of custom objects representing people with different attributes like name, age, and occupation. We then pipe this array to the ConvertTo-CSV cmdlet to convert it to CSV format and store the output in a variable called $csv. Finally, we output the CSV data using the $csv variable.","title":"ConvertTo-CSV"},{"location":"out_format/#convertfrom-csv","text":"ConvertFrom-CSV is a cmdlet that allows you to convert CSV data back into PowerShell objects. This cmdlet takes the input CSV data, converts it into PowerShell objects, and outputs the objects. Here's an example of how to use ConvertFrom-CSV: # Convert CSV data to PowerShell objects $csvData = @\" Name,Age,Occupation John,35,Software Engineer Jane,28,Project Manager \"@ | ConvertFrom-CSV # Output the objects $csvData In this example, we first define a CSV string containing data about people, with each person represented as a row with columns for name, age, and occupation. We then pipe this CSV string to the ConvertFrom-CSV cmdlet to convert it into PowerShell objects and store the output in a variable called $csvData. Finally, we output the objects using the $csvData variable.","title":"ConvertFrom-CSV"},{"location":"out_format/#json","text":"JavaScript Object Notation (JSON) is a lightweight data format that's similar to XML, because it can represent multiple layers of data. JSON is a lightweight data-interchange format compared to XML because of its simpler syntax. Windows PowerShell doesn't include cmdlets that import or export JSON data directly from a file. Instead, if you have JSON data stored in a file, you can retrieve the data by using Get-Content and then convert the data by using the ConvertFrom-Json cmdlet.","title":"JSON"},{"location":"out_format/#reading-a-json-file","text":"$json = Get-Content .\\ example . json | ConvertFrom-Json","title":"Reading a JSON file"},{"location":"out_format/#writing-to-a-json-file","text":"$data = @{ \"Name\" = \"John\" ; \"Age\" = 30 } $data | ConvertTo-Json | Out-File .\\ example . json","title":"Writing to a JSON file"},{"location":"out_format/#testing-a-json-file","text":"\"{'name': 'Ashley', 'age': 25}\" | Test-Json","title":"Testing a JSON file"},{"location":"out_format/#xml","text":"XML is a more complex data storage format than CSV files. The main advantage of using XML for Windows PowerShell is that it can hold multiple levels of data. A CSV file works with a table of information in which the columns are the object properties. In a CSV file, it's difficult to work with multivalued attributes, whereas XML can easily represent multivalued attributes or even objects that have other objects as a property.","title":"XML"},{"location":"out_format/#reading-an-xml-file","text":"The use of Import-Clixml to retrieve data from an XML file creates an array of objects. Because XML can be complex, you might not easily be able to understand the object properties by reviewing the contents of the XML file directly. You can use Get-Member to identify the properties of the data that you import. $users = Import-Clixml C :\\ Scripts \\ Users . xml You can limit the data retrieved by Import-Clixml by using the -First and -Skip parameters. The -First parameter specifies to retrieve only the specified number of objects from the beginning of the XML file. The -Skip parameter specifies to ignore the specified number of objects from the beginning of the XML file and to retrieve all the remaining objects. $xml = Select-Xml -Path C :\\ example . xml -XPath \"//book\"","title":"Reading an XML file"},{"location":"out_format/#writing-to-an-xml-file","text":"$data = @{ \"Name\" = \"John\" ; \"Age\" = 30 } $data | Export-Clixml C :\\ example . xml","title":"Writing to an XML file"},{"location":"out_format/#html","text":"PowerShell provides a variety of cmdlets that can be used to manipulate HTML files, such as Invoke-WebRequest, Invoke-RestMethod, and ConvertTo-Html. Here are some examples of how to use these cmdlets to manipulate HTML files in PowerShell: Downloading an HTML file using Invoke-WebRequest: Invoke-WebRequest -Uri https :// example . com -OutFile example . html Extracting data from an HTML file using Invoke-RestMethod: $response = Invoke-RestMethod -Uri https :// example . com $response . Tables [ 0 ] | ConvertTo-Html -Fragment Converting a PowerShell object to an HTML table using ConvertTo-Html: Get-Process | Select-Object Name , CPU , WorkingSet | ConvertTo-Html -Head \"Process Report\" -PreContent \"<h1>Current Processes</h1>\" These are just a few examples of how to manipulate HTML files in PowerShell. The possibilities are endless, and these cmdlets can be combined with other PowerShell commands to perform more complex tasks. ConvertTo-Html creates a simple list or table that's coded as HTML. You can control the HTML format in a limited way through a variety of parameters, such as: \u2011Head. Specifies the content of an HTML head section. \u2011Title. Sets the value of the HTML title tag. \u2011PreContent. Defines any content that should display before the table or list output. \u2011PostContent. Defines any content that should display after the table or list output.","title":"HTML"},{"location":"out_format/#output-to-file-or-printer","text":"If you want to save the output of a command to an unformatted plain text file, you can use either of these methods (using the get-process command as an example): get-process > processes.txt (using redirection) get-process | out-file processes.txt (using the pipeline) Both versions are functionally equivalent, but the out-file command can receive parameters to change the line width and to avoid overwriting an existing file. To read a plain text file as text strings, you use the Get-Content cmdlet (with aliases cat or type): Get-Content processes . txt PowerShell also supports the text redirection operators (> and >>) that cmd.exe uses. These operators act as an alias for Out-File. The greater than sign (>) at the end of a pipeline directs output to a file, overwriting the content. Two consecutive greater than signs (>>) direct output to a file, appending the output to any text already in the file. Out-File is the easiest way to move data from PowerShell to external storage. However, the text files that Out-File creates are usually intended for reviewing by a person. Therefore, reading the data back into Windows PowerShell in a way that enables data manipulation, sorting, selection, and measurement is frequently difficult or impractical. Out-File doesn't produce any output of its own, which means that the command doesn't put objects into the pipeline. After you run the command, you should expect no output on the screen. If you want to send the output of a command to the printer, you use the out-printer cmdlet: get-process | out-printer","title":"OUTPUT TO FILE OR PRINTER"},{"location":"pipeline/","text":"The pipeline in PowerShell is a feature that allows you to take the output of one command and pass it as input to another command. This makes it possible to create more complex commands by chaining simple commands together. The pipeline operator, represented by the \"|\" character, is used to connect commands together. When using the Windows PowerShell pipeline, you can pass data through the pipeline and perform operations on it. This capability lets you perform many bulk operations such as: Querying a list of objects. Filtering the objects. Modifying the objects. Displaying the data. Here are some examples of how to use the pipeline in PowerShell: Example 1: Get-ChildItem and Select-Object The Get-ChildItem command is used to list the files and folders in a specified directory. The Select-Object command is used to select specific properties of the objects returned by Get-ChildItem. By using the pipeline, you can pass the output of Get-ChildItem to Select-Object to filter the results. Get-ChildItem | Select-Object Name , Length , LastWriteTime This command lists the files and folders in the current directory and then selects the Name, Length, and LastWriteTime properties of each item. Example 2: Get-Process and Sort-Object The Get-Process command is used to list the running processes on a system. The Sort-Object command is used to sort the results based on a specific property. By using the pipeline, you can pass the output of Get-Process to Sort-Object to sort the results by CPU usage. Get-Process | Sort-Object CPU -Descending This command lists the running processes and then sorts them in descending order based on their CPU usage. Example 3: Get-Service and Where-Object The Get-Service command is used to list the services on a system. The Where-Object command is used to filter the results based on a specific condition. By using the pipeline, you can pass the output of Get-Service to Where-Object to filter the results to only show services that are currently running. Get-Service | Where-Object Status -eq \"Running\" This command lists all of the services on the system and then filters the results to only show services that have a Status property equal to \"Running\". In each of these examples, the pipeline is used to pass the output of one command to another command. This allows you to create more powerful commands by combining simple commands together. Order & Selection The pipeline can be used to select properties of objects that are not displayed by default when using a cmdlet. It can also be used to filter results (using search criteria). To sort, the Sort-Object cmdlet (abbreviated sort) is used, and to select properties, Select-Object (abbreviated select) is used. For example, the process list is normally displayed in alphabetical order by process name. To sort it by Process ID, the command is: get-process | sort id To sort it by virtual memory usage in descending order: get-process | sort vm -desc Note that in this last example, it is sorting by a field that is not normally displayed on the screen. To change the fields that are displayed, select is used: get-process | select -property id , name , vm | sort vm -desc This example shows a table with the identifier, name, and virtual memory usage of the machine's processes, ordered in descending order by virtual memory usage. Remember that to view the properties of an object (the fields that can be displayed), the Get-Member cmdlet (abbreviated gm) is used: Get-Process | gm Best Practice : Always review the property names in the output of Get-Member before you use those property names in another command. By doing this, you can help to ensure that you use the actual property names and not ones created for display purposes. Passing parameters In a pipeline of the type: Command_A | Command_B ...parameters can be passed in two ways: By value (ByValue) In this case, PowerShell analyzes the output type of Command_A and determines which parameter of Command_B can receive this output. Example: Analyzing the command Get-Process | Stop-Process In this case, Get-Process produces Process type objects. Examining the help for Stop-Process, the following parameter is found: -InputObject <Process[]> Specifies the process objects to stop. Enter a variable that contains the objects, or type a command or expression that gets the objects. Required? true Position? 0 Default value None Accept pipeline input? True (ByValue) Accept wildcard characters? false As you can see, this parameter can receive values from the pipeline, using the ByValue method. For this reason, the command works. If you try to connect two commands to the pipeline that do not have compatible output and parameter types, an error occurs. It can also happen that data is passed through the wrong parameter. For example, suppose the file computers.txt contains the names of several computers, and you want to display the list of services on each of these computers. You could use the command: Get-Content computers . txt | get-service This command produces an error because the required parameter (ComputerName) does not accept input through the pipeline using the ByValue method. The command can then be executed using parentheses: get-service -computername ( get-content computers . txt ) When data is passed using ByValue, a parameter can accept complete objects from the pipeline when those objects are of the type that the parameter accepts. A single command can have more than one parameter accepting pipeline input ByValue, but each parameter must accept a different kind of object. For example, Get-Service can accept pipeline input ByValue on both its \u2013InputObject and \u2013Name parameters. Each of those parameters accepts a different kind of object. \u2013InputObject accepts objects of the type ServiceController, and \u2013Name accepts objects of the type String. Consider the following example: 'BITS' , 'WinRM' | Get-Service Here, two string objects are piped into Get-Service. They attach to the \u2013Name parameter because that parameter accepts that kind of object, ByValue, from the pipeline. Generic object types Windows PowerShell recognizes two generic kinds of object, Object and PSObject. Parameters that accept these kinds of objects can accept any kind of object. When you perform ByValue pipeline parameter binding, Windows PowerShell first looks for the most specific object type possible. If the pipeline contains a String, and a parameter can accept String, that parameter will receive the objects. If there's no match for a specific data type, Windows PowerShell will try to match generic data types. That behavior is why commands like Sort-Object and Select-Object work. Each of those commands has a parameter named \u2013InputObject that accepts objects of the type PSObject from the pipeline ByValue. This is why you can pipe any type of object to those commands. Their \u2013InputObject parameter will receive any object from the pipeline because it accepts objects of any kind. By parameter name (ByPropertyName) If Windows PowerShell is unable to bind pipeline input by using the ByValue technique, it tries to use the ByPropertyName technique. When Windows PowerShell uses the ByPropertyName technique, it attempts to match a property of the object passed to a parameter of the command to which the object was passed. This match occurs in a simple manner. If the input object has a Name property, it will be matched with the parameter Name because they're spelled the same. However, it will only pass the property if the parameter is programmed to accept a value by property name. This means that you can pass output from one command to another when they don't logically go together. In this method, you must specify the parameter names. For example, consider a file called alias.txt with the following content: Name,Value np,notepad sel,Select-Object go,Invoke-Command The idea is to use the contents of this file to input it to the new-alias command and create the aliases listed in the file. Note that the first line of the file corresponds to the column headers. If this file is imported with Import-Csv, the following is obtained: PS C :\\ Users \\ Usuario \\ powershell > Import-Csv .\\ alias . txt Name Value ---- ----- np notepad sel Select-Object go Invoke-Command If you use Get-Member to analyze this output, you get: TypeName: System.Management.Automation.PSCustomObject Name MemberType Definition ---- ---------- ---------- Equals Method bool Equals(System.Object obj) GetHashCode Method int GetHashCode() GetType Method type GetType() ToString Method string ToString() Name NoteProperty string Name=np Value NoteProperty string Value=notepad It can be seen that the last two properties are of type String. Let's now analyze the parameters of the New-Alias command: New-Alias [-Name] <String> [-Value] <String> [-Confirm] [-Description <String>] [-Force] [-Option {None | ReadOnly | Constant | Private | AllScope | Unspecified}] [-PassThru] [-Scope <String>] [-WhatIf] [<CommonParameters>] The Name and Value parameters receive String inputs. And if you review the complete help, you can verify that both parameters receive values through the pipeline using the ByPropertyName mode: -Name <String> Specifies the new alias. You can use any alphanumeric characters in an alias, but the first character cannot be a number. Required? true Position? 0 Default value None Accept pipeline input? True (ByPropertyName) Accept wildcard characters? false -Value <String> Specifies the name of the cmdlet or command element that is being aliased. Required? true Position? 1 Default value None Accept pipeline input? True (ByPropertyName) Accept wildcard characters? false Therefore, information can be passed from one command to another in the following way: import-csv alias . txt | new-alias Renaming properties Most often, a property name from an output object doesn't match the name of an input parameter exactly. You can change the name of the property by using Select-Object and create a calculated property. For example, to view the processes running on all computers in your Windows Server Active Directory, try running the following command: Get-ADComputer -Filter * | Get-Process However, this command doesn't work. No parameter for Get-Process matches a property name for the output of Get-ADComputer. View the output of Get-ADComputer | Get-Member and Get-Help Get-Process and you'll see that what you want is to match the Name property of Get-ADComputer with the -ComputerName parameter of Get-Process. You can do that by using Select-Object and changing the property name for the Get-ADComputer command\u2019s Name property to ComputerName, and then passing the results to Get-Process. The following command will work: Get-ADComputer -Filter * | Select-Object @{ n = 'ComputerName' ; e ={ $PSItem . Name }} | Get-Process Remember: Windows PowerShell will always try ByValue first and will use ByPropertyName only if ByValue fails. Parenthetical Commands Another option for passing the results of one command to the parameters of another is by using parenthetical commands. A parenthetical command is a command that is enclosed in parentheses. Just as in math, parentheses tell Windows PowerShell to execute the enclosed command first. The parenthetical command runs, and the results of the command are inserted in its place. You can use parenthetical commands to pass values to parameters that do not accept pipeline input. This means you can have a pipeline that includes data inputs from multiple sources. Consider the following command: Get-ADGroup \"London Users\" | Add-ADGroupMember -Members ( Get-ADUser -Filter { City -eq 'London' }) In this example, output of Get-ADGroup passes to Add-ADGroupMember, telling it which group to modify. However, that is only part of the information needed. We also need to tell Add-ADGroupMember what users to add to the group. The -Members parameter does not accept piped input, and even if it did, we have already piped data to the command. Therefore, we need to use a parenthetical command to provide a list of users that we want added to the group. Parenthetical commands do not rely on pipeline parameter binding. They work with any parameter if the parenthetical command produces the kind of object that the parameter expects. Expand Property Values You can use parenthetical commands to provide parameter input without using the pipeline. In some cases, however, you might have to manipulate the objects produced by a parenthetical command so that the command\u2019s output is of the type that the parameter requires. For example, you might want to list all the processes that are running on every computer in the domain. In this example, imagine that you have a very small lab domain that contains just a few computers. You can get a list of every computer in the domain by running the following command: Get-ADComputer \u2013 Filter * However, this command produces objects of the type ADComputer. You couldn't use those objects directly in a parenthetical command such as in the following command: Get-Process \u2013 ComputerName ( Get-ADComputer \u2013 Filter *) The \u2013ComputerName parameter expects objects of the type String. However, the parenthetical command doesn't produce String type objects. The \u2013ComputerName parameter only wants a computer name. However, the command provides it an object that contains a name, an operating system version, and several other properties. You could try the following command: Get-Process \u2013 ComputerName ( Get-ADComputer \u2013 Filter * | Select-Object \u2013 Property Name ) This command selects only the Name property. This property is still a member of a whole ADComputer object. It's the Name property of an object. Although the Name property contains a string, it isn't itself a string. The \u2013ComputerName parameter expects a string, not an object with a property. Therefore, that command doesn't work either. The following command achieves the goal of passing the computer name as a string to the -ComputerName parameter: Get-Process \u2013 ComputerName ( Get-ADComputer \u2013 Filter * | Select-Object \u2013 ExpandProperty Name ) The \u2013ExpandProperty parameter accepts one, and only one, property name. When you use that parameter, only the contents of the specified property are produced by Select-Object. Some people refer to this feature as extracting the property contents. The official description of the feature is expanding the property contents. In the preceding command, the result of the parenthetical command is a collection of strings that are passed as individual strings, not an array, and that is what the \u2013ComputerName parameter expects. The command will work correctly; however, it might produce an error if one or more of the computers can't be reached on the network. Expanding property values also works when piping output. Consider the following example: Get-ADUser Ty -Properties MemberOf | Get-ADGroup This command returns an error because Windows PowerShell can't match the MemberOf property to any property of Get-ADGroup. However, if you expand the value of the MemberOf property, as in the following example, Windows PowerShell can match the resulting output to a value that Get-ADGroup understands as valid input: Get-ADUser Ty -Properties MemberOf | Select-Object -ExpandProperty MemberOf | Get-ADGroup","title":"Pipeline"},{"location":"pipeline/#order-selection","text":"The pipeline can be used to select properties of objects that are not displayed by default when using a cmdlet. It can also be used to filter results (using search criteria). To sort, the Sort-Object cmdlet (abbreviated sort) is used, and to select properties, Select-Object (abbreviated select) is used. For example, the process list is normally displayed in alphabetical order by process name. To sort it by Process ID, the command is: get-process | sort id To sort it by virtual memory usage in descending order: get-process | sort vm -desc Note that in this last example, it is sorting by a field that is not normally displayed on the screen. To change the fields that are displayed, select is used: get-process | select -property id , name , vm | sort vm -desc This example shows a table with the identifier, name, and virtual memory usage of the machine's processes, ordered in descending order by virtual memory usage. Remember that to view the properties of an object (the fields that can be displayed), the Get-Member cmdlet (abbreviated gm) is used: Get-Process | gm Best Practice : Always review the property names in the output of Get-Member before you use those property names in another command. By doing this, you can help to ensure that you use the actual property names and not ones created for display purposes.","title":"Order &amp; Selection"},{"location":"pipeline/#passing-parameters","text":"In a pipeline of the type: Command_A | Command_B ...parameters can be passed in two ways:","title":"Passing parameters"},{"location":"pipeline/#by-value-byvalue","text":"In this case, PowerShell analyzes the output type of Command_A and determines which parameter of Command_B can receive this output. Example: Analyzing the command Get-Process | Stop-Process In this case, Get-Process produces Process type objects. Examining the help for Stop-Process, the following parameter is found: -InputObject <Process[]> Specifies the process objects to stop. Enter a variable that contains the objects, or type a command or expression that gets the objects. Required? true Position? 0 Default value None Accept pipeline input? True (ByValue) Accept wildcard characters? false As you can see, this parameter can receive values from the pipeline, using the ByValue method. For this reason, the command works. If you try to connect two commands to the pipeline that do not have compatible output and parameter types, an error occurs. It can also happen that data is passed through the wrong parameter. For example, suppose the file computers.txt contains the names of several computers, and you want to display the list of services on each of these computers. You could use the command: Get-Content computers . txt | get-service This command produces an error because the required parameter (ComputerName) does not accept input through the pipeline using the ByValue method. The command can then be executed using parentheses: get-service -computername ( get-content computers . txt ) When data is passed using ByValue, a parameter can accept complete objects from the pipeline when those objects are of the type that the parameter accepts. A single command can have more than one parameter accepting pipeline input ByValue, but each parameter must accept a different kind of object. For example, Get-Service can accept pipeline input ByValue on both its \u2013InputObject and \u2013Name parameters. Each of those parameters accepts a different kind of object. \u2013InputObject accepts objects of the type ServiceController, and \u2013Name accepts objects of the type String. Consider the following example: 'BITS' , 'WinRM' | Get-Service Here, two string objects are piped into Get-Service. They attach to the \u2013Name parameter because that parameter accepts that kind of object, ByValue, from the pipeline.","title":"By value (ByValue)"},{"location":"pipeline/#generic-object-types","text":"Windows PowerShell recognizes two generic kinds of object, Object and PSObject. Parameters that accept these kinds of objects can accept any kind of object. When you perform ByValue pipeline parameter binding, Windows PowerShell first looks for the most specific object type possible. If the pipeline contains a String, and a parameter can accept String, that parameter will receive the objects. If there's no match for a specific data type, Windows PowerShell will try to match generic data types. That behavior is why commands like Sort-Object and Select-Object work. Each of those commands has a parameter named \u2013InputObject that accepts objects of the type PSObject from the pipeline ByValue. This is why you can pipe any type of object to those commands. Their \u2013InputObject parameter will receive any object from the pipeline because it accepts objects of any kind.","title":"Generic object types"},{"location":"pipeline/#by-parameter-name-bypropertyname","text":"If Windows PowerShell is unable to bind pipeline input by using the ByValue technique, it tries to use the ByPropertyName technique. When Windows PowerShell uses the ByPropertyName technique, it attempts to match a property of the object passed to a parameter of the command to which the object was passed. This match occurs in a simple manner. If the input object has a Name property, it will be matched with the parameter Name because they're spelled the same. However, it will only pass the property if the parameter is programmed to accept a value by property name. This means that you can pass output from one command to another when they don't logically go together. In this method, you must specify the parameter names. For example, consider a file called alias.txt with the following content: Name,Value np,notepad sel,Select-Object go,Invoke-Command The idea is to use the contents of this file to input it to the new-alias command and create the aliases listed in the file. Note that the first line of the file corresponds to the column headers. If this file is imported with Import-Csv, the following is obtained: PS C :\\ Users \\ Usuario \\ powershell > Import-Csv .\\ alias . txt Name Value ---- ----- np notepad sel Select-Object go Invoke-Command If you use Get-Member to analyze this output, you get: TypeName: System.Management.Automation.PSCustomObject Name MemberType Definition ---- ---------- ---------- Equals Method bool Equals(System.Object obj) GetHashCode Method int GetHashCode() GetType Method type GetType() ToString Method string ToString() Name NoteProperty string Name=np Value NoteProperty string Value=notepad It can be seen that the last two properties are of type String. Let's now analyze the parameters of the New-Alias command: New-Alias [-Name] <String> [-Value] <String> [-Confirm] [-Description <String>] [-Force] [-Option {None | ReadOnly | Constant | Private | AllScope | Unspecified}] [-PassThru] [-Scope <String>] [-WhatIf] [<CommonParameters>] The Name and Value parameters receive String inputs. And if you review the complete help, you can verify that both parameters receive values through the pipeline using the ByPropertyName mode: -Name <String> Specifies the new alias. You can use any alphanumeric characters in an alias, but the first character cannot be a number. Required? true Position? 0 Default value None Accept pipeline input? True (ByPropertyName) Accept wildcard characters? false -Value <String> Specifies the name of the cmdlet or command element that is being aliased. Required? true Position? 1 Default value None Accept pipeline input? True (ByPropertyName) Accept wildcard characters? false Therefore, information can be passed from one command to another in the following way: import-csv alias . txt | new-alias","title":"By parameter name (ByPropertyName)"},{"location":"pipeline/#renaming-properties","text":"Most often, a property name from an output object doesn't match the name of an input parameter exactly. You can change the name of the property by using Select-Object and create a calculated property. For example, to view the processes running on all computers in your Windows Server Active Directory, try running the following command: Get-ADComputer -Filter * | Get-Process However, this command doesn't work. No parameter for Get-Process matches a property name for the output of Get-ADComputer. View the output of Get-ADComputer | Get-Member and Get-Help Get-Process and you'll see that what you want is to match the Name property of Get-ADComputer with the -ComputerName parameter of Get-Process. You can do that by using Select-Object and changing the property name for the Get-ADComputer command\u2019s Name property to ComputerName, and then passing the results to Get-Process. The following command will work: Get-ADComputer -Filter * | Select-Object @{ n = 'ComputerName' ; e ={ $PSItem . Name }} | Get-Process Remember: Windows PowerShell will always try ByValue first and will use ByPropertyName only if ByValue fails.","title":"Renaming properties"},{"location":"pipeline/#parenthetical-commands","text":"Another option for passing the results of one command to the parameters of another is by using parenthetical commands. A parenthetical command is a command that is enclosed in parentheses. Just as in math, parentheses tell Windows PowerShell to execute the enclosed command first. The parenthetical command runs, and the results of the command are inserted in its place. You can use parenthetical commands to pass values to parameters that do not accept pipeline input. This means you can have a pipeline that includes data inputs from multiple sources. Consider the following command: Get-ADGroup \"London Users\" | Add-ADGroupMember -Members ( Get-ADUser -Filter { City -eq 'London' }) In this example, output of Get-ADGroup passes to Add-ADGroupMember, telling it which group to modify. However, that is only part of the information needed. We also need to tell Add-ADGroupMember what users to add to the group. The -Members parameter does not accept piped input, and even if it did, we have already piped data to the command. Therefore, we need to use a parenthetical command to provide a list of users that we want added to the group. Parenthetical commands do not rely on pipeline parameter binding. They work with any parameter if the parenthetical command produces the kind of object that the parameter expects.","title":"Parenthetical Commands"},{"location":"pipeline/#expand-property-values","text":"You can use parenthetical commands to provide parameter input without using the pipeline. In some cases, however, you might have to manipulate the objects produced by a parenthetical command so that the command\u2019s output is of the type that the parameter requires. For example, you might want to list all the processes that are running on every computer in the domain. In this example, imagine that you have a very small lab domain that contains just a few computers. You can get a list of every computer in the domain by running the following command: Get-ADComputer \u2013 Filter * However, this command produces objects of the type ADComputer. You couldn't use those objects directly in a parenthetical command such as in the following command: Get-Process \u2013 ComputerName ( Get-ADComputer \u2013 Filter *) The \u2013ComputerName parameter expects objects of the type String. However, the parenthetical command doesn't produce String type objects. The \u2013ComputerName parameter only wants a computer name. However, the command provides it an object that contains a name, an operating system version, and several other properties. You could try the following command: Get-Process \u2013 ComputerName ( Get-ADComputer \u2013 Filter * | Select-Object \u2013 Property Name ) This command selects only the Name property. This property is still a member of a whole ADComputer object. It's the Name property of an object. Although the Name property contains a string, it isn't itself a string. The \u2013ComputerName parameter expects a string, not an object with a property. Therefore, that command doesn't work either. The following command achieves the goal of passing the computer name as a string to the -ComputerName parameter: Get-Process \u2013 ComputerName ( Get-ADComputer \u2013 Filter * | Select-Object \u2013 ExpandProperty Name ) The \u2013ExpandProperty parameter accepts one, and only one, property name. When you use that parameter, only the contents of the specified property are produced by Select-Object. Some people refer to this feature as extracting the property contents. The official description of the feature is expanding the property contents. In the preceding command, the result of the parenthetical command is a collection of strings that are passed as individual strings, not an array, and that is what the \u2013ComputerName parameter expects. The command will work correctly; however, it might produce an error if one or more of the computers can't be reached on the network. Expanding property values also works when piping output. Consider the following example: Get-ADUser Ty -Properties MemberOf | Get-ADGroup This command returns an error because Windows PowerShell can't match the MemberOf property to any property of Get-ADGroup. However, if you expand the value of the MemberOf property, as in the following example, Windows PowerShell can match the resulting output to a value that Get-ADGroup understands as valid input: Get-ADUser Ty -Properties MemberOf | Select-Object -ExpandProperty MemberOf | Get-ADGroup","title":"Expand Property Values"},{"location":"tables_lists/","text":"Powershell commands present their output in tables or lists, depending on the command being used and the attributes it is asked to display. The Select-Object command (abbreviated as Select) can be used to determine the attributes that are displayed. However, the display is limited to the attributes related to the invoked command. For example: Get Process | select name , vm ...displays a list of processes, made up only of the name of each process and the amount of virtual memory it uses. The formatting commands allow, in addition to printing the standard attributes, to display attributes calculated from the basic attributes. The display can be done in table, list or wide format mode. Table Format The Format-Table cmdlet (abbreviated as ft) allows you to display the output of a command in table format. The parameters received by this command are the following: Parameters Meaning -Property Allows you to specify the attributes (native or calculated) that you want to display. The wildcard * can be used to specify all of them. -Autosize Allows the command to accommodate the width of the columns in the best possible way. Normally this width is fixed, but this parameter adjusts the width of the columns to the longest value of each attribute. -Groupby This parameter specifies one of the fields. Each time there is a change in the value of this field, a new set of headers is printed. It is recommended to use Sort-Object before doing a Format-Table with Groupby, to avoid unnecessary repetition of headers. -Wrap When a field's value is excessively long, Powershell wraps it, indicating this with an ellipsis (...). The Wrap parameter causes long values to span one or more additional lines, depending on the length of the value. Examples: get-process | ft-Property * ... tries to print all the attributes of the processes. Powershell reviews all lines of the output, and does its best to accommodate all possible fields. Due to this hotfix, the command takes a relatively long time to execute. get-process | ft -Property ID , Name , Responding -AutoSize ...gets a list of processes with ID, Name, and Responding attributes. The width of the columns is optimized. get-process | ft -Property * -autosize ... tries to print all the attributes of the processes. However, this command runs faster, since the width of the columns is optimized. Get-Service | sortStatus | ft Name , Status , DisplayName -groupby Status ... prints a list of services divided into two sections: One of stopped services (Stopped) and another of running services (Running). Get-Service | ft Name , Status , DisplayName -autosize -wrap ...prints a list of services with the attributes Name, Status and DisplayName. The DisplayName attribute (which is the longest) will span multiple lines if necessary. List Format The Format-List cmdlet (abbreviated fl) allows you to display attributes as a series of name-value pairs, for example: Get-Service -name bits | fl -Property * Name : bits RequiredServices : { RpcSs } CanPauseAndContinue : False CanShutdown : False CanStop : False DisplayName : Background Intelligent Transfer Service DependentServices : {} MachineName : . ServiceName : bits ServicesDependedOn : { RpcSs } ServiceHandle : Status : Stopped ServiceType : Win32ShareProcess StartType : Manual Site : Container : Note that the output of the Get-Service command was filtered here, to get only the information for the BITS service (otherwise, Format-List would have returned a similar set of lines for each service). Here Format-List was asked to display all attributes of the service (the -Property parameter with wildcard). Wide Format The wide format allows you to display two or more columns of a particular object property, much like the Linux ls command. The Format-Wide (abbreviated fw) cmdlet is used for this purpose. Examples: get-process | format-wide ... displays two columns of process names (Format-wide defaults to the Name property). get-process | format-wide name -col 4 ...shows 4 columns of process names. Change Of Names Of Attributes An example of renaming an attribute is the following: get service | ft @{ name = 'Service' ; expression ={ $_ . Name }}, Status , DisplayName In this case, a new column is defined, using the expression between the @{ } symbols. Name indicates the name that the column will have. It can be abbreviated as n. Expression defines the content of the column. It can be abbreviated as e. $ is a special variable that holds the object that is currently being processed. For this example, $ .Name means: \"Of the current object, take the Name property.\" The above command could be abbreviated like this: get service | ft @{ n = 'Service' ; e ={ $_ . Name }}, Status , DisplayName The following command: get-process | ft Name ,@{ n = 'VM (MB)' ; e ={ $_ . VM / 1MB }} ...displays a process table with two columns: Name (native property) and VM (MB), which shows the amount of virtual memory used by the process, in megabytes. The command: get-process | ft Name ,@{ n = 'VM (MB)' ; e ={ $_ . VM / 1MB -as [int] }} -AutoSize ...displays a table similar to the one in the previous example, but rounds the virtual memory to an integer value. Using The Format Commands The formatting command to be used (ft, fl or fw) must be the last one in the pipeline before printing to the screen. The output of a format command can only be redirected to a TEXT file. If you try to convert the output to another format (CSV, HTML, XML) the results will be inconsistent.","title":"Formatting"},{"location":"tables_lists/#table-format","text":"The Format-Table cmdlet (abbreviated as ft) allows you to display the output of a command in table format. The parameters received by this command are the following: Parameters Meaning -Property Allows you to specify the attributes (native or calculated) that you want to display. The wildcard * can be used to specify all of them. -Autosize Allows the command to accommodate the width of the columns in the best possible way. Normally this width is fixed, but this parameter adjusts the width of the columns to the longest value of each attribute. -Groupby This parameter specifies one of the fields. Each time there is a change in the value of this field, a new set of headers is printed. It is recommended to use Sort-Object before doing a Format-Table with Groupby, to avoid unnecessary repetition of headers. -Wrap When a field's value is excessively long, Powershell wraps it, indicating this with an ellipsis (...). The Wrap parameter causes long values to span one or more additional lines, depending on the length of the value. Examples: get-process | ft-Property * ... tries to print all the attributes of the processes. Powershell reviews all lines of the output, and does its best to accommodate all possible fields. Due to this hotfix, the command takes a relatively long time to execute. get-process | ft -Property ID , Name , Responding -AutoSize ...gets a list of processes with ID, Name, and Responding attributes. The width of the columns is optimized. get-process | ft -Property * -autosize ... tries to print all the attributes of the processes. However, this command runs faster, since the width of the columns is optimized. Get-Service | sortStatus | ft Name , Status , DisplayName -groupby Status ... prints a list of services divided into two sections: One of stopped services (Stopped) and another of running services (Running). Get-Service | ft Name , Status , DisplayName -autosize -wrap ...prints a list of services with the attributes Name, Status and DisplayName. The DisplayName attribute (which is the longest) will span multiple lines if necessary.","title":"Table Format"},{"location":"tables_lists/#list-format","text":"The Format-List cmdlet (abbreviated fl) allows you to display attributes as a series of name-value pairs, for example: Get-Service -name bits | fl -Property * Name : bits RequiredServices : { RpcSs } CanPauseAndContinue : False CanShutdown : False CanStop : False DisplayName : Background Intelligent Transfer Service DependentServices : {} MachineName : . ServiceName : bits ServicesDependedOn : { RpcSs } ServiceHandle : Status : Stopped ServiceType : Win32ShareProcess StartType : Manual Site : Container : Note that the output of the Get-Service command was filtered here, to get only the information for the BITS service (otherwise, Format-List would have returned a similar set of lines for each service). Here Format-List was asked to display all attributes of the service (the -Property parameter with wildcard).","title":"List Format"},{"location":"tables_lists/#wide-format","text":"The wide format allows you to display two or more columns of a particular object property, much like the Linux ls command. The Format-Wide (abbreviated fw) cmdlet is used for this purpose. Examples: get-process | format-wide ... displays two columns of process names (Format-wide defaults to the Name property). get-process | format-wide name -col 4 ...shows 4 columns of process names.","title":"Wide Format"},{"location":"tables_lists/#change-of-names-of-attributes","text":"An example of renaming an attribute is the following: get service | ft @{ name = 'Service' ; expression ={ $_ . Name }}, Status , DisplayName In this case, a new column is defined, using the expression between the @{ } symbols. Name indicates the name that the column will have. It can be abbreviated as n. Expression defines the content of the column. It can be abbreviated as e. $ is a special variable that holds the object that is currently being processed. For this example, $ .Name means: \"Of the current object, take the Name property.\" The above command could be abbreviated like this: get service | ft @{ n = 'Service' ; e ={ $_ . Name }}, Status , DisplayName The following command: get-process | ft Name ,@{ n = 'VM (MB)' ; e ={ $_ . VM / 1MB }} ...displays a process table with two columns: Name (native property) and VM (MB), which shows the amount of virtual memory used by the process, in megabytes. The command: get-process | ft Name ,@{ n = 'VM (MB)' ; e ={ $_ . VM / 1MB -as [int] }} -AutoSize ...displays a table similar to the one in the previous example, but rounds the virtual memory to an integer value.","title":"Change Of Names Of Attributes"},{"location":"tables_lists/#using-the-format-commands","text":"The formatting command to be used (ft, fl or fw) must be the last one in the pipeline before printing to the screen. The output of a format command can only be redirected to a TEXT file. If you try to convert the output to another format (CSV, HTML, XML) the results will be inconsistent.","title":"Using The Format Commands"},{"location":"wmi_cim/","text":"WMI and CMI basics A Windows computer contains thousands of items of management information. The WMI (Windows Management Instrumentation) and CIM (Common Information Model) frameworks seek to facilitate and organize these elements. WMI, which is the Microsoft implementation of the Web-Based Enterprise Management (WBEM) standard, is an older technology that's based on preliminary standards and proprietary technology. CIM is a newer technology that's based on open, cross-platform standards. Both technologies provide a way to connect to a common information repository (also known as the WMI repository). This repository contains management information that you can query and manipulate. There are two parallel sets of cmdlets that you can use to perform tasks by using WMI or CIM. WMI cmdlets WMI cmdlets use the same repository as CIM cmdlets. The only difference is how the WMI cmdlets connect to a remote computer. WMI cmdlets don't support session-based connections. These commands support only ad-hoc remote connections over DCOM. Whether used by WMI or CIM commands, DCOM might be difficult to use on some networks. DCOM uses the remote procedure call (RPC) protocol, which connects by using randomly selected port numbers. Special firewall exceptions are required for DCOM to work correctly. The Windows Management Instrumentation service provides the connectivity for WMI. WMI cmdlets don't require any version of the Windows Management Framework on a remote computer. They also don't require Windows PowerShell remoting to be enabled. If the remote computer has the Windows Firewall feature enabled, you need to ensure that the remote administration exceptions are enabled on the remote computer. If the remote computer has a different local firewall enabled, equivalent exceptions must be created and enabled. There are different tools designed to explore the different classes of WMI. One of them is WMI Explorer Get-WmiObject You can use the Get-WmiObject cmdlet to explore WMI namespaces. For example, if you wanted to query the classes related to disks, you could use the following command: Get-WmiObject -Namespace root \\ CIMv2 -list | where name -like '*disk*' The following command displays a complete list of classes within the root\\CIMv2 namespace: Get-WmiObject -Namespace root \\ CIMv2 -list To interrogate a specific class, use the -class parameter: Get-WmiObject -Namespace root \\ CIMv2 -class win32_desktop The above command can be abbreviated, since the default namespace is root\\CIMv2 , and the -class parameter are both positional: Get-WmiObject win32_desktop CIM Cmdlets You can use CIM cmdlets to access the repository on local or remote computers. Multiple protocols for connectivity are supported and the protocol varies, depending on how the connection is created. Component Object Model (COM) is a protocol for local communication between software components. Distributed COM (DCOM) is an older proprietary Microsoft protocol for connectivity which uses dynamic ports. Web Services for Management (WS-MAN) is a web-based protocol defined by the DMTF for connectivity. A WS-MAN listener is configured automatically on port 5985. Also, a secure listener is created on port 5986 if a certificate is available. CIM cmdlets can create connections in three ways: Local connections. When you don't specify a remote computer, the CIM cmdlets use a local COM session to access and communicate with the repository. Ad-hoc connections. When you specify a remote computer by using the -ComputerName parameter with a CIM cmdlet, the remote connection uses WS-MAN. CIM sessions. You can precreate a CIM session with specific options for connectivity to remote computers. When you create a CIM session, you can specify whether to use WS-MAN or DCOM. To use the CIM cmdlets on a remote computer, the remote computer doesn't need to have PowerShell installed. The remote computer needs to support WS-MAN to connect to it with CIM cmdlets. You can use CIM cmdlets with Linux computers. In Windows, WS-MAN connectivity is provided by the Windows Remote Management (WinRM) service. This service also provides support for Windows PowerShell remoting, but PowerShell remoting is not required for the CIM cmdlets. Get-CimInstance The Get-CimInstance command was introduced in Powershell version 3, and works much like Get-WmiObject , except for the following: The -ClassName parameter is used instead of -Class . There is no -list parameter to list all classes in a namespace. The Get-CimClass cmdlet must be used with the -Namespace parameter. Examples: List the instances of the Win32_LogicalDisk class: Get-CimInstance -ClassName win32_logicaldisk Get the list of classes from root\\CIMv2 , filtering out those that have to do with disks: Get-CimClass -Namespace root \\ CIMv2 | where cimclassname -Like '*disk*' CIM or WMI? In general, you should use CIM cmdlets instead of the older WMI cmdlets. Microsoft considers the WMI commands within Windows PowerShell to be deprecated, although the underlying WMI repository is still a current technology. You should rely primarily on CIM commands and use WMI commands only when CIM commands aren't practical. CIM cmdlets also provide easier network connectivity. Because CIM cmdlets use WS-MAN for remote connectivity, the firewall rules for known ports are easier to create than the randomly generated ports used by DCOM. If remote computers don't support using WS-MAN, you can specify the use of DCOM for connectivity by using a CIM session. Using cmdlets instead of classes The repository is not well-documented, so discovering the classes that you need to perform a specific task might be difficult and impractical. If there is a PowerShell cmdlet for managing a specific item such as networking, then it's typically easier to use that cmdlet instead of the equivalent class methods exposed through CIM cmdlets. These purpose-built cmdlets often use CIM or WMI but hide their complexity from you. This approach gives you the advantages of Windows PowerShell cmdlets, such as discoverability and built-in documentation, while also giving you the existing functionality of the repository. Repositories WMI and CIM The repository that Common Information Model (CIM) and Windows Management Instrumentation (WMI) use is organized into namespaces. A namespace is a folder that groups related items for organizational purposes. Namespaces contain classes. A class represents a manageable software or hardware component. For example, the Windows operating system provides classes for processors, disk drives, services, user accounts, and so on. Each computer on the network might have slightly different namespaces and classes. For example, a domain controller might have a class named ActiveDirectory that doesn't exist on other computers. To find the top-level namespaces, run the following command: Get-CimInstance -Namespace root -ClassName __Namespace In the previous command, there are two underscores (_) in the class name of __Namespace. Some of the namespaces returned might include: subscription DEFAULT CIMV2 msdtc Cli Intel_ME SECURITY HyperVCluster SecurityCenter2 RSOP Intel PEH StandardCimv2 WMI directory Policy virtualization Interop Hardware ServiceModel SecurityCenter Microsoft Appv dcim When you work with the repository, you typically work with instances. An instance is an actual occurrence of a class. For example, if your computer has two processor sockets, you'll have two instances of the class that represents processors. If your computer doesn't have an attached tape drive, you'll have zero instances of the tape drive class. Instances are objects, similar to the objects that you've already used in Windows PowerShell. Instances have properties, and some instances have methods. Properties describe the attributes of an instance. For example, a network adapter instance might have properties that describe its speed, power state, and so on. Methods tell an instance to do something. For example, the instance that represents the operating system might have a method to restart the operating system. The root\\CIMv2 namespace contains all information about the Windows operating system and the underlying hardware. On client computers, the namespace root\\SecurityCenter2 ( root\\SecurityCenter in earlier versions of the operating system) contains information about firewall, antivirus, and antispyware software installed on the computer. Within each namespace, WMI includes a series of classes. Each class represents a type of management component that WMI knows how to query. For example, the Win32_LogicalDisk class in the root\\CIMv2 namespace contains information about logical disks, while the AntiSpywareProduct class in the root\\SecurityCenterv2 namespace contains information about antispyware products. . If manageable components exist for a certain class, they will appear as instances of that class. Class names in the root\\CIMv2 namespace usually start with Win32_ (even on 64-bit machines) or CIM_ . Typically, the properties of such instances are read-only (that is, you cannot make changes to the parameter values). Listing classes Most of the time, when you use Common Information Model (CIM) and Windows Management Instrumentation (WMI) you're trying to accomplish a specific task. To identify how to accomplish that task, you typically do an internet search to identify if anyone has provided sample code that accomplishes a similar task. Then you can modify that code for your purposes and identify the CIM or WMI classes that they're using. When you don't find useful sample code, you might want to browse the available classes to check if anything is suitable. To explore the classes available to you by using CIM and WMI, you can list the classes available in a namespace. For example, to list all the classes in the root\\CIMv2 namespace, run either of these commands: Get-WmiObject -Namespace root \\ CIMv2 -List #or Get-CimClass -Namespace root \\ CIMv2 In the root\\CIMv2 namespace, you'll notice some class names that start with Win32_ and others that start with CIM_. This namespace is the only one that uses these prefixes. Classes that start with CIM_ are typically abstract classes. Classes that start with Win32_ are typically more specific versions of the abstract classes, and they contain information that's specific to the Windows operating system. Many administrators feel that the repository is difficult to work with. Finding the class that you need to perform a particular task is a guessing game. You have to guess what the class might be named and then review the class list to figure out whether you're correct. Then you must query the class to determine whether it contains the information that you need. Because many classes outside the root\\CIMv2 namespace are not well-documented, this is your best approach. No central directory of repository classes exists. The repository doesn't include a search system. You can use Windows PowerShell to perform a basic keyword search of repository class names. For example, to find all the classes in the root\\CIMv2 namespace having network in the class name, use the following command: Get-CimClass * network * | Sort CimClassName However, this technique does not provide the ability to search class descriptions because that information isn't stored in the repository. An internet search engine provides more viable alternative to search for possible class names. There's one specific WMI class object that can cause problems for system administrators. This is the Win32_Product class. You can use this class to query installed software, but be aware that returning the results takes a long time and has negative performance implications. When you query this class, the provider performs a Windows Installer (MSI) reconfiguration on every MSI package on the system as the query is being performed. Microsoft recommends using the Win32reg_AddRemovePrograms class as an alternative, but this class is only available on systems with the Microsoft Endpoint Configuration Manager client installed. Query instances Once you've identified the class you want to query, you can use Windows PowerShell to retrieve the specific instances of that class. For example, if you want to retrieve all instances of the Win32_LogicalDisk class from the root\\CIMv2 namespace, run either of the following commands: Get-WmiObject -Class Win32_LogicalDisk # or Get-CimInstance -ClassName Win32_LogicalDisk The output from these commands is formatted differently, but they contain the same information. When using Get-CimInstance, you can use tab completion for the class name. This isn't possible with Get-WmiObject. Both the -Class parameter of Get-WmiObject and the -ClassName parameter of Get-CimInstance are positional. The names of positional parameters don't need to be specified. Filtering instances By default, both commands retrieve all available instances of the specified class. You can specify filter criteria to retrieve a smaller set of instances. The filter languages used by these commands don't use Windows PowerShell comparison operators. Instead, they use traditional programming operators, as listed in the following table. Comparison WMI and CIM operator Windows PowerShell operator Equal to = -eq Not equal to <> -ne Greater than > -gt Less than < -lt Less than or equal to <= -le Greater than or equal to >= -ge Wildcard string match LIKE (with % as the wildcard) -like (with * as the wildcard) Require two or more conditions to be true AND -and Require one of two or more conditions to be true OR -or For example, to retrieve only the instances of Win32_LogicalDisk for which the DriveType property is 3, run either of the following commands: Get-WmiObject -Class Win32_LogicalDisk -Filter \"DriveType=3\" #or Get-CimInstance -ClassName Win32_LogicalDisk -Filter \"DriveType=3\" Many class properties use integers to represent different kinds of things. For example, in the Win32_LogicalDisk class, a DriveType property of 3 represents a local fixed disk. A value of 5 represents an optical disk, such as a DVD drive. You have to examine the class documentation to learn what each value represents. Querying by using WQL Both WMI and CIM accept query statements written in WMI Query Language (WQL) . WQL is a subset of Structured Query Language (SQL) that is specific to querying WMI. Their format is fairly intuitive so it's relatively straightforward to author them. For example, the following queries are equivalent to the previously described commands that retrieve the specific instance of the Win32_LogicalDisk class: Get-WmiObject -Query \"SELECT * FROM Win32_LogicalDisk WHERE DriveType = 3\" #or Get-CimInstance -Query \"SELECT * FROM Win32_LogicalDisk WHERE DriveType = 3\" Discover Methods A method is an action that you can perform on an object. Repository objects that you query by using Common Information Model (CIM) or Windows Management Instrumentation (WMI) have methods that reconfigure the manageable components that the objects represent. For example, the Win32_Service class instances represent background services. The class has a Change method that reconfigures many of a service\u2019s settings, including the sign-in password, name, and start mode. When you query instances of a class, you can use the Get-Member cmdlet to discover the methods available for that type of object. The following examples depict how to use Get-Member to review the properties and methods for instances of Win32_Service: Get-WmiObject -Class Win32_Service | Get-Member -MemberType Method # or Get-CimInstance -ClassName Win32_Service | Get-Member -MemberType Method You can also use Get-CimClass to review the methods available for a specific class: Get-CimClass -Class Win32_Service | Select-Object -ExpandProperty CimClassMethods The methods available to managing object instances vary, depending on the type of object. The output of the commands doesn't explain how to use the methods, so unless you already know how to use them, you will need to find the relevant documentation by relying on other sources of information, such as results of an internet search. If any method documentation exists, the documentation webpage for the repository class will include it. Remember that repository classes aren't typically well-documented, especially the classes that aren't in the root\\CIMv2 namespace. An internet search engine provides the fastest way to find the documentation for a class. When you enter the class name into a search engine, one of the first few search results is typically the class documentation page. Generally, the documentation page includes a section named Methods that lists the class methods. Select any method name to display the instructions for using that method. The documentation allows you to determine the arguments that each method requires. For example, the Win32Shutdown method of the Win32_OperatingSystem class accepts a single argument. This argument is an integer, and it tells the method to either shut down, restart, or sign out. To use a method on an object, you invoke it. You can accomplish this by using direct invocation, which includes a reference to the object that supports the method, followed by the method name. Alternatively, you can use the Invoke-WmiMethod or Invoke-CimMethod cmdlets. If you use the cmdlets, the cmdlet you use needs to match the type of object you're working with. Direct invocation Direct invocation is typically used when you've loaded Windows Management Instrumentation (WMI) objects into a variable. Then, you can invoke methods available for that object type by specifying the variable name, a dot (.), and then the method. This is similar to how you display property values for an object contained in a variable. The following example queries the spooler service as a WMI object and then invokes the StopService method. $WmiSpoolerService = Get-WmiObject -Class Win32_Service -Filter \"Name='Spooler'\" $WmiSpoolerService . StopService () The StopService method in the previous example doesn't require any parameters to be passed to it, so there's no value within the parentheses. If you invoke a method that requires parameters, their values are placed within the parentheses. The following example sets the value of the start mode parameter to Manual: $WmiSpoolerService . ChangeStartMode ( \"Manual\" ) To identify the parameters required for a method, you should review the documentation for its class. Be aware that parameters for WMI method parameters need to be passed in a specific order. To identify the order, you can use the GetMethodParameters() method. The following example queries the parameters for the Change method: $WmiSpoolerService . GetMethodParameters ( \"Change\" ) If the method requires multiple parameters and you don't want to change some of them, you can pass a $null value for the parameters you don't want to change. Additionally, you don't need to specify parameters that are positioned after the one you want to change. In the following example, the Change method has 11 parameters, but only the second parameter (display name) is being configured. $WimSpoolerService . Change ( $null , \"Printer Service\" ) Because $null is treated as a parameter value to skip when calling a method, you can't set a value to $null by invoking a method on a WMI object. Objects retrieved by Get-CimInstance are static and don't have methods. Therefore, you can't use them by relying on direct invocation. Using the Invoke-WmiMethod Cmdlet The Invoke-WmiMethod cmdlet is another way to invoke a method for a WMI object with different syntax. The -Name parameter is used to specify the method to invoke and the -Argument parameter is used to specify the parameter values that are passed to the method. If required, multiple parameters are passed as a comma-separated list or array. The parameter values need to be in a specific order just as they were for direct invocation. You can use the Invoke-WmiMethod cmdlet by itself, or you can use the pipeline to send it a WMI object. Here are two examples that work the same way: Get-WmiObject -Class Win32_OperatingSystem | Invoke-WmiMethod -Name Win32Shutdown -Argument 0 # or Invoke-WmiMethod -Class Win32_OperatingSystem -Name Win32Shutdown -Argument 0 The Get-WmiObject and Invoke-Method cmdlets both have the -ComputerName parameter that lets you run the cmdlet on a remote computer. Using the Invoke-CimMethod cmdlet The Invoke-CimMethod cmdlets provide similar functionality to the Invoke-WmiMethod cmdlet, but argument list for Invoke-CimMethod is a dictionary object. Such an object consists of one or more key-value pairs. The key for each pair is the parameter name, and the value for each pair is the corresponding parameter value. In the following example, Path is the name of the parameter and Notepad.exe is the value: Invoke-CimMethod -ComputerName LON-DC1 -ClassName Win32_Process -MethodName Create -Arguments @{ CommandLine = 'Notepad.exe' } To include multiple parameters in the dictionary, use a semicolon to separate each key-value pair. Because the parameters are named, the key-value pairs can be in any order. To invoke a method on a specific instance of an object, you retrieve the object first by using the Get-CimInstance cmdlet. You can pipe the object directly to the Invoke-CimMethod cmdlet or store it in a variable first. If the object provides all of the necessary information, then you don't need to specify any arguments. The following example retrieves any running instances of Notepad.exe and terminates them: Get-CimInstance -ClassName Win32_Process -Filter \"Name='notepad.exe'\" | Invoke-CimMethod -MethodName Terminate If you use the -ComputerName or -CIMSession parameters with the Get-CimInstance cmdlet and pipe the resulting object to the Invoke-CimMethod cmdlet, the method is invoked on whatever computer or session the object came from. For example, to terminate a process on a remote computer, you can run the following command: Get-CimInstance -ClassName Win32_Process -Filter \"Name='notepad.exe'\" -Computername LON-DC1 | Invoke-CimMethod -MethodName Terminate","title":"Windows Management"},{"location":"wmi_cim/#wmi-and-cmi-basics","text":"A Windows computer contains thousands of items of management information. The WMI (Windows Management Instrumentation) and CIM (Common Information Model) frameworks seek to facilitate and organize these elements. WMI, which is the Microsoft implementation of the Web-Based Enterprise Management (WBEM) standard, is an older technology that's based on preliminary standards and proprietary technology. CIM is a newer technology that's based on open, cross-platform standards. Both technologies provide a way to connect to a common information repository (also known as the WMI repository). This repository contains management information that you can query and manipulate. There are two parallel sets of cmdlets that you can use to perform tasks by using WMI or CIM.","title":"WMI and CMI basics"},{"location":"wmi_cim/#wmi-cmdlets","text":"WMI cmdlets use the same repository as CIM cmdlets. The only difference is how the WMI cmdlets connect to a remote computer. WMI cmdlets don't support session-based connections. These commands support only ad-hoc remote connections over DCOM. Whether used by WMI or CIM commands, DCOM might be difficult to use on some networks. DCOM uses the remote procedure call (RPC) protocol, which connects by using randomly selected port numbers. Special firewall exceptions are required for DCOM to work correctly. The Windows Management Instrumentation service provides the connectivity for WMI. WMI cmdlets don't require any version of the Windows Management Framework on a remote computer. They also don't require Windows PowerShell remoting to be enabled. If the remote computer has the Windows Firewall feature enabled, you need to ensure that the remote administration exceptions are enabled on the remote computer. If the remote computer has a different local firewall enabled, equivalent exceptions must be created and enabled. There are different tools designed to explore the different classes of WMI. One of them is WMI Explorer","title":"WMI cmdlets"},{"location":"wmi_cim/#get-wmiobject","text":"You can use the Get-WmiObject cmdlet to explore WMI namespaces. For example, if you wanted to query the classes related to disks, you could use the following command: Get-WmiObject -Namespace root \\ CIMv2 -list | where name -like '*disk*' The following command displays a complete list of classes within the root\\CIMv2 namespace: Get-WmiObject -Namespace root \\ CIMv2 -list To interrogate a specific class, use the -class parameter: Get-WmiObject -Namespace root \\ CIMv2 -class win32_desktop The above command can be abbreviated, since the default namespace is root\\CIMv2 , and the -class parameter are both positional: Get-WmiObject win32_desktop","title":"Get-WmiObject"},{"location":"wmi_cim/#cim-cmdlets","text":"You can use CIM cmdlets to access the repository on local or remote computers. Multiple protocols for connectivity are supported and the protocol varies, depending on how the connection is created. Component Object Model (COM) is a protocol for local communication between software components. Distributed COM (DCOM) is an older proprietary Microsoft protocol for connectivity which uses dynamic ports. Web Services for Management (WS-MAN) is a web-based protocol defined by the DMTF for connectivity. A WS-MAN listener is configured automatically on port 5985. Also, a secure listener is created on port 5986 if a certificate is available. CIM cmdlets can create connections in three ways: Local connections. When you don't specify a remote computer, the CIM cmdlets use a local COM session to access and communicate with the repository. Ad-hoc connections. When you specify a remote computer by using the -ComputerName parameter with a CIM cmdlet, the remote connection uses WS-MAN. CIM sessions. You can precreate a CIM session with specific options for connectivity to remote computers. When you create a CIM session, you can specify whether to use WS-MAN or DCOM. To use the CIM cmdlets on a remote computer, the remote computer doesn't need to have PowerShell installed. The remote computer needs to support WS-MAN to connect to it with CIM cmdlets. You can use CIM cmdlets with Linux computers. In Windows, WS-MAN connectivity is provided by the Windows Remote Management (WinRM) service. This service also provides support for Windows PowerShell remoting, but PowerShell remoting is not required for the CIM cmdlets.","title":"CIM Cmdlets"},{"location":"wmi_cim/#get-ciminstance","text":"The Get-CimInstance command was introduced in Powershell version 3, and works much like Get-WmiObject , except for the following: The -ClassName parameter is used instead of -Class . There is no -list parameter to list all classes in a namespace. The Get-CimClass cmdlet must be used with the -Namespace parameter. Examples: List the instances of the Win32_LogicalDisk class: Get-CimInstance -ClassName win32_logicaldisk Get the list of classes from root\\CIMv2 , filtering out those that have to do with disks: Get-CimClass -Namespace root \\ CIMv2 | where cimclassname -Like '*disk*'","title":"Get-CimInstance"},{"location":"wmi_cim/#cim-or-wmi","text":"In general, you should use CIM cmdlets instead of the older WMI cmdlets. Microsoft considers the WMI commands within Windows PowerShell to be deprecated, although the underlying WMI repository is still a current technology. You should rely primarily on CIM commands and use WMI commands only when CIM commands aren't practical. CIM cmdlets also provide easier network connectivity. Because CIM cmdlets use WS-MAN for remote connectivity, the firewall rules for known ports are easier to create than the randomly generated ports used by DCOM. If remote computers don't support using WS-MAN, you can specify the use of DCOM for connectivity by using a CIM session.","title":"CIM or WMI?"},{"location":"wmi_cim/#using-cmdlets-instead-of-classes","text":"The repository is not well-documented, so discovering the classes that you need to perform a specific task might be difficult and impractical. If there is a PowerShell cmdlet for managing a specific item such as networking, then it's typically easier to use that cmdlet instead of the equivalent class methods exposed through CIM cmdlets. These purpose-built cmdlets often use CIM or WMI but hide their complexity from you. This approach gives you the advantages of Windows PowerShell cmdlets, such as discoverability and built-in documentation, while also giving you the existing functionality of the repository.","title":"Using cmdlets instead of classes"},{"location":"wmi_cim/#repositories-wmi-and-cim","text":"The repository that Common Information Model (CIM) and Windows Management Instrumentation (WMI) use is organized into namespaces. A namespace is a folder that groups related items for organizational purposes. Namespaces contain classes. A class represents a manageable software or hardware component. For example, the Windows operating system provides classes for processors, disk drives, services, user accounts, and so on. Each computer on the network might have slightly different namespaces and classes. For example, a domain controller might have a class named ActiveDirectory that doesn't exist on other computers. To find the top-level namespaces, run the following command: Get-CimInstance -Namespace root -ClassName __Namespace In the previous command, there are two underscores (_) in the class name of __Namespace. Some of the namespaces returned might include: subscription DEFAULT CIMV2 msdtc Cli Intel_ME SECURITY HyperVCluster SecurityCenter2 RSOP Intel PEH StandardCimv2 WMI directory Policy virtualization Interop Hardware ServiceModel SecurityCenter Microsoft Appv dcim When you work with the repository, you typically work with instances. An instance is an actual occurrence of a class. For example, if your computer has two processor sockets, you'll have two instances of the class that represents processors. If your computer doesn't have an attached tape drive, you'll have zero instances of the tape drive class. Instances are objects, similar to the objects that you've already used in Windows PowerShell. Instances have properties, and some instances have methods. Properties describe the attributes of an instance. For example, a network adapter instance might have properties that describe its speed, power state, and so on. Methods tell an instance to do something. For example, the instance that represents the operating system might have a method to restart the operating system. The root\\CIMv2 namespace contains all information about the Windows operating system and the underlying hardware. On client computers, the namespace root\\SecurityCenter2 ( root\\SecurityCenter in earlier versions of the operating system) contains information about firewall, antivirus, and antispyware software installed on the computer. Within each namespace, WMI includes a series of classes. Each class represents a type of management component that WMI knows how to query. For example, the Win32_LogicalDisk class in the root\\CIMv2 namespace contains information about logical disks, while the AntiSpywareProduct class in the root\\SecurityCenterv2 namespace contains information about antispyware products. . If manageable components exist for a certain class, they will appear as instances of that class. Class names in the root\\CIMv2 namespace usually start with Win32_ (even on 64-bit machines) or CIM_ . Typically, the properties of such instances are read-only (that is, you cannot make changes to the parameter values).","title":"Repositories WMI and CIM"},{"location":"wmi_cim/#listing-classes","text":"Most of the time, when you use Common Information Model (CIM) and Windows Management Instrumentation (WMI) you're trying to accomplish a specific task. To identify how to accomplish that task, you typically do an internet search to identify if anyone has provided sample code that accomplishes a similar task. Then you can modify that code for your purposes and identify the CIM or WMI classes that they're using. When you don't find useful sample code, you might want to browse the available classes to check if anything is suitable. To explore the classes available to you by using CIM and WMI, you can list the classes available in a namespace. For example, to list all the classes in the root\\CIMv2 namespace, run either of these commands: Get-WmiObject -Namespace root \\ CIMv2 -List #or Get-CimClass -Namespace root \\ CIMv2 In the root\\CIMv2 namespace, you'll notice some class names that start with Win32_ and others that start with CIM_. This namespace is the only one that uses these prefixes. Classes that start with CIM_ are typically abstract classes. Classes that start with Win32_ are typically more specific versions of the abstract classes, and they contain information that's specific to the Windows operating system. Many administrators feel that the repository is difficult to work with. Finding the class that you need to perform a particular task is a guessing game. You have to guess what the class might be named and then review the class list to figure out whether you're correct. Then you must query the class to determine whether it contains the information that you need. Because many classes outside the root\\CIMv2 namespace are not well-documented, this is your best approach. No central directory of repository classes exists. The repository doesn't include a search system. You can use Windows PowerShell to perform a basic keyword search of repository class names. For example, to find all the classes in the root\\CIMv2 namespace having network in the class name, use the following command: Get-CimClass * network * | Sort CimClassName However, this technique does not provide the ability to search class descriptions because that information isn't stored in the repository. An internet search engine provides more viable alternative to search for possible class names. There's one specific WMI class object that can cause problems for system administrators. This is the Win32_Product class. You can use this class to query installed software, but be aware that returning the results takes a long time and has negative performance implications. When you query this class, the provider performs a Windows Installer (MSI) reconfiguration on every MSI package on the system as the query is being performed. Microsoft recommends using the Win32reg_AddRemovePrograms class as an alternative, but this class is only available on systems with the Microsoft Endpoint Configuration Manager client installed.","title":"Listing classes"},{"location":"wmi_cim/#query-instances","text":"Once you've identified the class you want to query, you can use Windows PowerShell to retrieve the specific instances of that class. For example, if you want to retrieve all instances of the Win32_LogicalDisk class from the root\\CIMv2 namespace, run either of the following commands: Get-WmiObject -Class Win32_LogicalDisk # or Get-CimInstance -ClassName Win32_LogicalDisk The output from these commands is formatted differently, but they contain the same information. When using Get-CimInstance, you can use tab completion for the class name. This isn't possible with Get-WmiObject. Both the -Class parameter of Get-WmiObject and the -ClassName parameter of Get-CimInstance are positional. The names of positional parameters don't need to be specified.","title":"Query instances"},{"location":"wmi_cim/#filtering-instances","text":"By default, both commands retrieve all available instances of the specified class. You can specify filter criteria to retrieve a smaller set of instances. The filter languages used by these commands don't use Windows PowerShell comparison operators. Instead, they use traditional programming operators, as listed in the following table. Comparison WMI and CIM operator Windows PowerShell operator Equal to = -eq Not equal to <> -ne Greater than > -gt Less than < -lt Less than or equal to <= -le Greater than or equal to >= -ge Wildcard string match LIKE (with % as the wildcard) -like (with * as the wildcard) Require two or more conditions to be true AND -and Require one of two or more conditions to be true OR -or For example, to retrieve only the instances of Win32_LogicalDisk for which the DriveType property is 3, run either of the following commands: Get-WmiObject -Class Win32_LogicalDisk -Filter \"DriveType=3\" #or Get-CimInstance -ClassName Win32_LogicalDisk -Filter \"DriveType=3\" Many class properties use integers to represent different kinds of things. For example, in the Win32_LogicalDisk class, a DriveType property of 3 represents a local fixed disk. A value of 5 represents an optical disk, such as a DVD drive. You have to examine the class documentation to learn what each value represents.","title":"Filtering instances"},{"location":"wmi_cim/#querying-by-using-wql","text":"Both WMI and CIM accept query statements written in WMI Query Language (WQL) . WQL is a subset of Structured Query Language (SQL) that is specific to querying WMI. Their format is fairly intuitive so it's relatively straightforward to author them. For example, the following queries are equivalent to the previously described commands that retrieve the specific instance of the Win32_LogicalDisk class: Get-WmiObject -Query \"SELECT * FROM Win32_LogicalDisk WHERE DriveType = 3\" #or Get-CimInstance -Query \"SELECT * FROM Win32_LogicalDisk WHERE DriveType = 3\"","title":"Querying by using WQL"},{"location":"wmi_cim/#discover-methods","text":"A method is an action that you can perform on an object. Repository objects that you query by using Common Information Model (CIM) or Windows Management Instrumentation (WMI) have methods that reconfigure the manageable components that the objects represent. For example, the Win32_Service class instances represent background services. The class has a Change method that reconfigures many of a service\u2019s settings, including the sign-in password, name, and start mode. When you query instances of a class, you can use the Get-Member cmdlet to discover the methods available for that type of object. The following examples depict how to use Get-Member to review the properties and methods for instances of Win32_Service: Get-WmiObject -Class Win32_Service | Get-Member -MemberType Method # or Get-CimInstance -ClassName Win32_Service | Get-Member -MemberType Method You can also use Get-CimClass to review the methods available for a specific class: Get-CimClass -Class Win32_Service | Select-Object -ExpandProperty CimClassMethods The methods available to managing object instances vary, depending on the type of object. The output of the commands doesn't explain how to use the methods, so unless you already know how to use them, you will need to find the relevant documentation by relying on other sources of information, such as results of an internet search. If any method documentation exists, the documentation webpage for the repository class will include it. Remember that repository classes aren't typically well-documented, especially the classes that aren't in the root\\CIMv2 namespace. An internet search engine provides the fastest way to find the documentation for a class. When you enter the class name into a search engine, one of the first few search results is typically the class documentation page. Generally, the documentation page includes a section named Methods that lists the class methods. Select any method name to display the instructions for using that method. The documentation allows you to determine the arguments that each method requires. For example, the Win32Shutdown method of the Win32_OperatingSystem class accepts a single argument. This argument is an integer, and it tells the method to either shut down, restart, or sign out. To use a method on an object, you invoke it. You can accomplish this by using direct invocation, which includes a reference to the object that supports the method, followed by the method name. Alternatively, you can use the Invoke-WmiMethod or Invoke-CimMethod cmdlets. If you use the cmdlets, the cmdlet you use needs to match the type of object you're working with.","title":"Discover Methods"},{"location":"wmi_cim/#direct-invocation","text":"Direct invocation is typically used when you've loaded Windows Management Instrumentation (WMI) objects into a variable. Then, you can invoke methods available for that object type by specifying the variable name, a dot (.), and then the method. This is similar to how you display property values for an object contained in a variable. The following example queries the spooler service as a WMI object and then invokes the StopService method. $WmiSpoolerService = Get-WmiObject -Class Win32_Service -Filter \"Name='Spooler'\" $WmiSpoolerService . StopService () The StopService method in the previous example doesn't require any parameters to be passed to it, so there's no value within the parentheses. If you invoke a method that requires parameters, their values are placed within the parentheses. The following example sets the value of the start mode parameter to Manual: $WmiSpoolerService . ChangeStartMode ( \"Manual\" ) To identify the parameters required for a method, you should review the documentation for its class. Be aware that parameters for WMI method parameters need to be passed in a specific order. To identify the order, you can use the GetMethodParameters() method. The following example queries the parameters for the Change method: $WmiSpoolerService . GetMethodParameters ( \"Change\" ) If the method requires multiple parameters and you don't want to change some of them, you can pass a $null value for the parameters you don't want to change. Additionally, you don't need to specify parameters that are positioned after the one you want to change. In the following example, the Change method has 11 parameters, but only the second parameter (display name) is being configured. $WimSpoolerService . Change ( $null , \"Printer Service\" ) Because $null is treated as a parameter value to skip when calling a method, you can't set a value to $null by invoking a method on a WMI object. Objects retrieved by Get-CimInstance are static and don't have methods. Therefore, you can't use them by relying on direct invocation.","title":"Direct invocation"},{"location":"wmi_cim/#using-the-invoke-wmimethod-cmdlet","text":"The Invoke-WmiMethod cmdlet is another way to invoke a method for a WMI object with different syntax. The -Name parameter is used to specify the method to invoke and the -Argument parameter is used to specify the parameter values that are passed to the method. If required, multiple parameters are passed as a comma-separated list or array. The parameter values need to be in a specific order just as they were for direct invocation. You can use the Invoke-WmiMethod cmdlet by itself, or you can use the pipeline to send it a WMI object. Here are two examples that work the same way: Get-WmiObject -Class Win32_OperatingSystem | Invoke-WmiMethod -Name Win32Shutdown -Argument 0 # or Invoke-WmiMethod -Class Win32_OperatingSystem -Name Win32Shutdown -Argument 0 The Get-WmiObject and Invoke-Method cmdlets both have the -ComputerName parameter that lets you run the cmdlet on a remote computer.","title":"Using the Invoke-WmiMethod Cmdlet"},{"location":"wmi_cim/#using-the-invoke-cimmethod-cmdlet","text":"The Invoke-CimMethod cmdlets provide similar functionality to the Invoke-WmiMethod cmdlet, but argument list for Invoke-CimMethod is a dictionary object. Such an object consists of one or more key-value pairs. The key for each pair is the parameter name, and the value for each pair is the corresponding parameter value. In the following example, Path is the name of the parameter and Notepad.exe is the value: Invoke-CimMethod -ComputerName LON-DC1 -ClassName Win32_Process -MethodName Create -Arguments @{ CommandLine = 'Notepad.exe' } To include multiple parameters in the dictionary, use a semicolon to separate each key-value pair. Because the parameters are named, the key-value pairs can be in any order. To invoke a method on a specific instance of an object, you retrieve the object first by using the Get-CimInstance cmdlet. You can pipe the object directly to the Invoke-CimMethod cmdlet or store it in a variable first. If the object provides all of the necessary information, then you don't need to specify any arguments. The following example retrieves any running instances of Notepad.exe and terminates them: Get-CimInstance -ClassName Win32_Process -Filter \"Name='notepad.exe'\" | Invoke-CimMethod -MethodName Terminate If you use the -ComputerName or -CIMSession parameters with the Get-CimInstance cmdlet and pipe the resulting object to the Invoke-CimMethod cmdlet, the method is invoked on whatever computer or session the object came from. For example, to terminate a process on a remote computer, you can run the following command: Get-CimInstance -ClassName Win32_Process -Filter \"Name='notepad.exe'\" -Computername LON-DC1 | Invoke-CimMethod -MethodName Terminate","title":"Using the Invoke-CimMethod cmdlet"},{"location":"Advanced/Credentials/","text":"Get-Credential As a best practice, administrators should have two user accounts. Each administrator should have a standard user account that's used for day-to-day activity and a second account with administrative permissions. Separating these roles helps to avoid accidental damage to computer systems and limits the potential effects of malware. The Get-Credential cmdlet can help you use the administrative account while you're still signed in to a standard user account. One way to elevate privileges when you run a script is to use the Run as administrator option when you open the Windows PowerShell prompt. If you use Run as administrator, you're prompted for credentials. So, all actions performed at that Windows PowerShell prompt use the credentials provided. As an alternative to using Run as administrator for running a script, you can have your script prompt for credentials instead. Many Windows PowerShell cmdlets allow an alternate set of credentials to be provided. That way, the credentials that the script obtains can be used to run individual commands in the script. You can prompt for credentials by using Get-Credential. The syntax for using the Get-Credential cmdlet is: $cred = Get-Credential Set-ADUser -Identity $user -Department \"Marketing\" -Credential $cred Storing Credentials By Using Export-Clixml You can store credentials to a file for later reuse without being prompted for credentials. To store credentials to a file, you use Export-Clixml. For a credential object, Export-Clixml encrypts the credential object before storing it in an XML file. Use the following syntax to store a credential object to a file. $cred | Export-Clixml C :\\ cred . xml The encryption used by Export-Clixml is user-specific and computer-specific. That means that if you store the encrypted credentials, only you can retrieve the encrypted credentials and only on the computer you originally used to store them. This action helps keep the credentials secure, but it also means that they can't be shared with other users. By Using The SecretManagement Module Microsoft has released the SecretManagement module that you can use to store and retrieve credentials. This method works better for storing credentials that can be shared among multiple users and computers. The cmdlets included in the SecretManagement module can access credentials from multiple secret vaults. Some well-known vaults are: KeePass LastPass CredMan Azure KeyVault The SecretManagement module is available in the PowerShell Gallery. You can install the SecretManagement module by running the following command: Install-Module Microsoft . PowerShell . SecretManagement Microsoft also provides the SecretStore module that you can use to create a local secret vault for storing credentials. However, similar to using Export-Clixml, the vault is stored on the local machine and in the current user context.","title":"Credentials"},{"location":"Advanced/Credentials/#get-credential","text":"As a best practice, administrators should have two user accounts. Each administrator should have a standard user account that's used for day-to-day activity and a second account with administrative permissions. Separating these roles helps to avoid accidental damage to computer systems and limits the potential effects of malware. The Get-Credential cmdlet can help you use the administrative account while you're still signed in to a standard user account. One way to elevate privileges when you run a script is to use the Run as administrator option when you open the Windows PowerShell prompt. If you use Run as administrator, you're prompted for credentials. So, all actions performed at that Windows PowerShell prompt use the credentials provided. As an alternative to using Run as administrator for running a script, you can have your script prompt for credentials instead. Many Windows PowerShell cmdlets allow an alternate set of credentials to be provided. That way, the credentials that the script obtains can be used to run individual commands in the script. You can prompt for credentials by using Get-Credential. The syntax for using the Get-Credential cmdlet is: $cred = Get-Credential Set-ADUser -Identity $user -Department \"Marketing\" -Credential $cred","title":"Get-Credential"},{"location":"Advanced/Credentials/#storing-credentials","text":"","title":"Storing Credentials"},{"location":"Advanced/Credentials/#by-using-export-clixml","text":"You can store credentials to a file for later reuse without being prompted for credentials. To store credentials to a file, you use Export-Clixml. For a credential object, Export-Clixml encrypts the credential object before storing it in an XML file. Use the following syntax to store a credential object to a file. $cred | Export-Clixml C :\\ cred . xml The encryption used by Export-Clixml is user-specific and computer-specific. That means that if you store the encrypted credentials, only you can retrieve the encrypted credentials and only on the computer you originally used to store them. This action helps keep the credentials secure, but it also means that they can't be shared with other users.","title":"By Using Export-Clixml"},{"location":"Advanced/Credentials/#by-using-the-secretmanagement-module","text":"Microsoft has released the SecretManagement module that you can use to store and retrieve credentials. This method works better for storing credentials that can be shared among multiple users and computers. The cmdlets included in the SecretManagement module can access credentials from multiple secret vaults. Some well-known vaults are: KeePass LastPass CredMan Azure KeyVault The SecretManagement module is available in the PowerShell Gallery. You can install the SecretManagement module by running the following command: Install-Module Microsoft . PowerShell . SecretManagement Microsoft also provides the SecretStore module that you can use to create a local secret vault for storing credentials. However, similar to using Export-Clixml, the vault is stored on the local machine and in the current user context.","title":"By Using The SecretManagement Module"},{"location":"Advanced/ErrorHandling/","text":"As you develop more scripts, you'll find that efficient troubleshooting makes your script development much faster. A large part of efficient troubleshooting is understanding error messages. For some difficult problems, you can use breakpoints to stop a script partially through running to query values for variables. Try/Catch/Finally Try { # Do something with a file. } Catch [System.IO.IOException] { Write-Host \"Something went wrong\" } Catch { # Catch all. It's not an IOException but something else. } Finally { # Clean up resources. } Inspecting errors An exception object contains: A message. The message tells you in a few words what went wrong. The stacktrace. The stacktrace tells you which statements ran before the error. Imagine you have a call to function A, followed by B, followed by C. The script stops responding at C. The stacktrace will show that chain of calls. The offending row. The exception object also tells you which row the script was running when the error occurred. This information can help you debug your code. So how do you inspect an exception object? There's a built-in variable, $ , that has an exception property. To get the error message, for example, you would use $ .exception.message. Try { # Do something with a file. } Catch [System.IO.IOException] { Write-Host \"Something IO went wrong: $( $_ . exception . message ) \" } Catch { Write-Host \"Something else went wrong: $( $_ . exception . message ) \" } Raising errors In some situations, you might want to cause an error: Non-terminating errors. For this type of error, PowerShell just notifies you that something went wrong, by using the Write-Error cmdlet, for example. The script continues to run. That might not be the behavior you want. To raise the severity of the error, you can use a parameter like -ErrorAction to cause an error that can be caught with Try/Catch, like so: Try { Get-Content './file.txt' -ErrorAction Stop } Catch { Write-Error \"File can't be found\" } By using the -ErrorAction parameter and the value Stop, you can cause an error that Try/Catch can catch. Business rules. You might have a situation where the code doesn't actually stop responding, but you want it to for business reasons. Imagine you're sanitizing input and you check whether a parameter is a path. A business requirement might specify only certain paths are allowed, or the path needs to look a certain way. If the checks fail, it makes sense to throw an error. In a situation like this, you can use a Throw block: Try { If ( $Path -eq './forbidden' ) { Throw \"Path not allowed\" } # Carry on. } Catch { Write-Error \" $( $_ . exception . message ) \" # Path not allowed. } In general, don't use Throw for parameter validation. Use validation attributes instead. If you can't make your code work with these attributes, a Throw might be OK. $ErrorActionPreference Windows PowerShell has a built-in, global variable named $ErrorActionPreference. When a command generates a non-terminating error, the command checks that variable to decide what it should do. The variable can have one of the following four possible values: Continue is the default, and it tells the command to display an error message and continue to run. SilentlyContinue tells the command to display no error message, but to continue running. Inquire tells the command to display a prompt asking the user what to do. Stop tells the command to treat the error as terminating and to stop running. $ErrorActionPreference = 'Inquire' Be selective about using SilentlyContinue for $ErrorActionPreference. You might think that this makes your script better for users, but it could make troubleshooting difficult. If you intend to trap an error within your script so that you can manage the error, commands must use the Stop action. You can trap and manage only terminating errors. -ErrorAction parameter All Windows PowerShell commands have the \u2013ErrorAction parameter. This parameter has the alias \u2013EA. The parameter accepts the same values as $ErrorActionPreference, and the parameter overrides the variable for that command. If you expect an error to occur on a command, you use \u2013ErrorAction to set that command\u2019s error action to Stop. Doing this lets you trap and manage the error for that command but leaves all other commands to use the action in $ErrorActionPreference. An example is: Get-WmiObject -Class Win32_BIOS -ComputerName LON-SVR1 , LON-DC1 -ErrorAction Stop The only time that you'll modify $ErrorActionPreference is when you expect an error outside of a Windows PowerShell command, such as when you're running a method such as the following Get-Process \u2013 Name Notepad | ForEach -Object { $PSItem . Kill () } In this example, the Kill() method might generate an error. But because it's not a Windows PowerShell command, it doesn't have the \u2013ErrorAction parameter. You would instead set $ErrorActionPreference to Stop before running the method, and then set the variable back to Continue after you run the method. Breakpoints A breakpoint pauses a script and provides an interactive prompt. At the interactive prompt, you can query or modify variable values and then continue the script. You use breakpoints to troubleshoot scripts when they aren't behaving as expected. At a Windows PowerShell prompt, you can set breakpoints by using the Set-PSBreakPoint cmdlet. Breakpoints can be set based on the line of the script, a specific command being used, or a specific variable being used. Set-PSBreakPoint -Script \"MyScript.ps1\" -Line 23 The following example depicts how to set a breakpoint for a specific command: Set-PSBreakPoint -Command \"Set-ADUser\" -Script \"MyScript.ps1\" When you set a breakpoint based on a command, you can include wildcards. For example, you could use the value *-ADUser to trigger a breakpoint for Get-ADUser, Set-ADUser, New-ADUser, and Remove-ADUser. To set a breakpoint for a specific variable, do the following: Set-PSBreakPoint -Variable \"computer\" -Script \"MyScript.ps1\" -Mode ReadWrite You can use the -Mode parameter for variables to identify whether you want to break when the variable value is read, written, or both. Valid values are Read, Write, and ReadWrite. The default action for Set-PSBreakPoint is break, which provides the interactive prompt. However, you can use the -Action parameter to specify code that runs instead. This allows you to perform complex operations such as evaluating variable values and only breaking if the value is outside a specific range. Breakpoints are stored in memory rather than as part of the script. Breakpoints aren't shared between multiple Windows PowerShell prompts and are removed when the prompt is closed. Microsoft Visual Studio Code allows you to set and use breakpoints with more advanced options and you can configure conditional breakpoints that are triggered when variables are outside of a range or match a specific value. Information about variable contents is also easier to find in Visual Studio Code. After a breakpoint is triggered and you're in the debugger, there's a variables section that displays the contents of variable so that you don't need to interrogate them.","title":"Handling Errors"},{"location":"Advanced/ErrorHandling/#trycatchfinally","text":"Try { # Do something with a file. } Catch [System.IO.IOException] { Write-Host \"Something went wrong\" } Catch { # Catch all. It's not an IOException but something else. } Finally { # Clean up resources. }","title":"Try/Catch/Finally"},{"location":"Advanced/ErrorHandling/#inspecting-errors","text":"An exception object contains: A message. The message tells you in a few words what went wrong. The stacktrace. The stacktrace tells you which statements ran before the error. Imagine you have a call to function A, followed by B, followed by C. The script stops responding at C. The stacktrace will show that chain of calls. The offending row. The exception object also tells you which row the script was running when the error occurred. This information can help you debug your code. So how do you inspect an exception object? There's a built-in variable, $ , that has an exception property. To get the error message, for example, you would use $ .exception.message. Try { # Do something with a file. } Catch [System.IO.IOException] { Write-Host \"Something IO went wrong: $( $_ . exception . message ) \" } Catch { Write-Host \"Something else went wrong: $( $_ . exception . message ) \" }","title":"Inspecting errors"},{"location":"Advanced/ErrorHandling/#raising-errors","text":"In some situations, you might want to cause an error: Non-terminating errors. For this type of error, PowerShell just notifies you that something went wrong, by using the Write-Error cmdlet, for example. The script continues to run. That might not be the behavior you want. To raise the severity of the error, you can use a parameter like -ErrorAction to cause an error that can be caught with Try/Catch, like so: Try { Get-Content './file.txt' -ErrorAction Stop } Catch { Write-Error \"File can't be found\" } By using the -ErrorAction parameter and the value Stop, you can cause an error that Try/Catch can catch. Business rules. You might have a situation where the code doesn't actually stop responding, but you want it to for business reasons. Imagine you're sanitizing input and you check whether a parameter is a path. A business requirement might specify only certain paths are allowed, or the path needs to look a certain way. If the checks fail, it makes sense to throw an error. In a situation like this, you can use a Throw block: Try { If ( $Path -eq './forbidden' ) { Throw \"Path not allowed\" } # Carry on. } Catch { Write-Error \" $( $_ . exception . message ) \" # Path not allowed. } In general, don't use Throw for parameter validation. Use validation attributes instead. If you can't make your code work with these attributes, a Throw might be OK.","title":"Raising errors"},{"location":"Advanced/ErrorHandling/#erroractionpreference","text":"Windows PowerShell has a built-in, global variable named $ErrorActionPreference. When a command generates a non-terminating error, the command checks that variable to decide what it should do. The variable can have one of the following four possible values: Continue is the default, and it tells the command to display an error message and continue to run. SilentlyContinue tells the command to display no error message, but to continue running. Inquire tells the command to display a prompt asking the user what to do. Stop tells the command to treat the error as terminating and to stop running. $ErrorActionPreference = 'Inquire' Be selective about using SilentlyContinue for $ErrorActionPreference. You might think that this makes your script better for users, but it could make troubleshooting difficult. If you intend to trap an error within your script so that you can manage the error, commands must use the Stop action. You can trap and manage only terminating errors.","title":"$ErrorActionPreference"},{"location":"Advanced/ErrorHandling/#-erroraction-parameter","text":"All Windows PowerShell commands have the \u2013ErrorAction parameter. This parameter has the alias \u2013EA. The parameter accepts the same values as $ErrorActionPreference, and the parameter overrides the variable for that command. If you expect an error to occur on a command, you use \u2013ErrorAction to set that command\u2019s error action to Stop. Doing this lets you trap and manage the error for that command but leaves all other commands to use the action in $ErrorActionPreference. An example is: Get-WmiObject -Class Win32_BIOS -ComputerName LON-SVR1 , LON-DC1 -ErrorAction Stop The only time that you'll modify $ErrorActionPreference is when you expect an error outside of a Windows PowerShell command, such as when you're running a method such as the following Get-Process \u2013 Name Notepad | ForEach -Object { $PSItem . Kill () } In this example, the Kill() method might generate an error. But because it's not a Windows PowerShell command, it doesn't have the \u2013ErrorAction parameter. You would instead set $ErrorActionPreference to Stop before running the method, and then set the variable back to Continue after you run the method.","title":"-ErrorAction parameter"},{"location":"Advanced/ErrorHandling/#breakpoints","text":"A breakpoint pauses a script and provides an interactive prompt. At the interactive prompt, you can query or modify variable values and then continue the script. You use breakpoints to troubleshoot scripts when they aren't behaving as expected. At a Windows PowerShell prompt, you can set breakpoints by using the Set-PSBreakPoint cmdlet. Breakpoints can be set based on the line of the script, a specific command being used, or a specific variable being used. Set-PSBreakPoint -Script \"MyScript.ps1\" -Line 23 The following example depicts how to set a breakpoint for a specific command: Set-PSBreakPoint -Command \"Set-ADUser\" -Script \"MyScript.ps1\" When you set a breakpoint based on a command, you can include wildcards. For example, you could use the value *-ADUser to trigger a breakpoint for Get-ADUser, Set-ADUser, New-ADUser, and Remove-ADUser. To set a breakpoint for a specific variable, do the following: Set-PSBreakPoint -Variable \"computer\" -Script \"MyScript.ps1\" -Mode ReadWrite You can use the -Mode parameter for variables to identify whether you want to break when the variable value is read, written, or both. Valid values are Read, Write, and ReadWrite. The default action for Set-PSBreakPoint is break, which provides the interactive prompt. However, you can use the -Action parameter to specify code that runs instead. This allows you to perform complex operations such as evaluating variable values and only breaking if the value is outside a specific range. Breakpoints are stored in memory rather than as part of the script. Breakpoints aren't shared between multiple Windows PowerShell prompts and are removed when the prompt is closed. Microsoft Visual Studio Code allows you to set and use breakpoints with more advanced options and you can configure conditional breakpoints that are triggered when variables are outside of a range or match a specific value. Information about variable contents is also easier to find in Visual Studio Code. After a breakpoint is triggered and you're in the debugger, there's a variables section that displays the contents of variable so that you don't need to interrogate them.","title":"Breakpoints"},{"location":"Advanced/ad-ac/","text":"The Active Directory module for Windows PowerShell also has cmdlets to create, modify, and delete computer accounts. You can use these cmdlets for individual operations or as part of a script to perform bulk operations. The cmdlets for managing computer objects have the text \u201ccomputer\u201d in their names. Cmdlet Description New-ADComputer Creates a new computer account Set-ADComputer Modifies properties of a computer account Get-ADComputer Displays properties of a computer account Remove-ADComputer Deletes a computer account Test-ComputerSecureChannel Verifies or repairs the trust relationship between a computer and the domain Reset-ComputerMachinePassword Resets the password for a computer account Creating new computer accounts You can use the New-ADComputer cmdlet to create a new computer account before you join the computer to the domain. You do this so that you can create the computer account in the correct OU before deploying the computer. Parameter Description \u2011Name Defines the name of a computer account \u2011Path Defines the OU or container where a computer account is created \u2011Enabled Defines whether the computer account is enabled or disabled; by default, a computer account is enabled, and a random password is generated The following example is a command that you can use to create a computer account: New-ADComputer -Name LON-CL10 -Path \"ou=marketing,dc=adatum,dc=com\" -Enabled $true Repairing the trust relationship for a computer account You can use the Test-ComputerSecureChannel cmdlet with the -Repair parameter to repair a lost trust relationship between a computer and a domain. You must run the cmdlet on the computer with the lost trust relationship. Account vs. device management cmdlets -ADComputer cmdlets are part of the Active Directory module and manage the computer object, not the physical device or its operating system. For example, you can use the Add\u2011Computer cmdlet to join a computer to a domain. To manage the properties of the physical computer and its operating system, use the -Computer cmdlets. The Active Directory module for Windows PowerShell also has cmdlets to create, modify, and delete computer accounts. You can use these cmdlets for individual operations or as part of a script to perform bulk operations.","title":"Accounts"},{"location":"Advanced/ad-ac/#creating-new-computer-accounts","text":"You can use the New-ADComputer cmdlet to create a new computer account before you join the computer to the domain. You do this so that you can create the computer account in the correct OU before deploying the computer. Parameter Description \u2011Name Defines the name of a computer account \u2011Path Defines the OU or container where a computer account is created \u2011Enabled Defines whether the computer account is enabled or disabled; by default, a computer account is enabled, and a random password is generated The following example is a command that you can use to create a computer account: New-ADComputer -Name LON-CL10 -Path \"ou=marketing,dc=adatum,dc=com\" -Enabled $true","title":"Creating new computer accounts"},{"location":"Advanced/ad-ac/#repairing-the-trust-relationship-for-a-computer-account","text":"You can use the Test-ComputerSecureChannel cmdlet with the -Repair parameter to repair a lost trust relationship between a computer and a domain. You must run the cmdlet on the computer with the lost trust relationship.","title":"Repairing the trust relationship for a computer account"},{"location":"Advanced/ad-ac/#account-vs-device-management-cmdlets","text":"-ADComputer cmdlets are part of the Active Directory module and manage the computer object, not the physical device or its operating system. For example, you can use the Add\u2011Computer cmdlet to join a computer to a domain. To manage the properties of the physical computer and its operating system, use the -Computer cmdlets. The Active Directory module for Windows PowerShell also has cmdlets to create, modify, and delete computer accounts. You can use these cmdlets for individual operations or as part of a script to perform bulk operations.","title":"Account vs. device management cmdlets"},{"location":"Advanced/ad-gr/","text":"The management of Active Directory groups closely relates to the management of users. You can use the Active Directory module for Windows PowerShell cmdlets to create and delete groups and to modify group properties. You can also use these cmdlets to change the group membership. Managing groups Cmdlets for modifying groups have the text \u201cgroup\u201d in their names. Cmdlet Description New-ADGroup Creates a new group Set-ADGroup Modifies properties of a group Get-ADGroup Displays properties of a group Remove-ADGroup Deletes a group Cmdlets that modify group membership by adding members to a group, for example, have the text \u201cgroupmember\u201d in their names. Cmdlet Description Add-ADGroupMember Adds members to a group Get-ADGroupMember Displays members of a group Remove-ADGroupMember Removes members from a group Cmdlets that modify the groups that a user, computer, or other Active Directory object is a member of have the text \u201cprincipalgroupmembership\u201d in their names. Cmdlet Description Add-ADPrincipalGroupMembership Adds group membership to an object Get-ADPrincipalGroupMembership Displays group membership of an object Remove-ADPrincipalGroupMembership Removes group membership from an object Creating new groups You can use the New\u2011ADGroup cmdlet to create groups. When you create groups by using the New\u2011ADGroup cmdlet, you must use the \u2011GroupScope parameter in addition to the group name. This parameter is the only one required. Parameter Description \u2011Name Defines the name of a group \u2011GroupScope Defines the scope of a group as DomainLocal, Global, or Universal; you must provide this parameter \u2011DisplayName Defines the Lightweight Directory Access Protocol (LDAP) display name for an object \u2011GroupCategory Defines whether a group is a security group or a distribution group; if you don't specify either, a security group is created \u2011ManagedBy Defines a user or group that can manage a group \u2011Path Defines the OU or container in which a group is created \u2011SamAccountName Defines a name that is backward-compatible with older operating systems For example, to create a new group named FileServerAdmins, enter the following command in the console, and then press the Enter key: New-ADGroup -Name FileServerAdmins -GroupScope Global Managing group membership As previously mentioned, you can use the -ADGroupMember or the -ADPrincipalGroupMembership cmdlets to manage group management in two different ways. The difference between the two is a matter of focusing on an object and modifying the groups to which it belongs, or focusing on the group and modifying the members that belong to it. Additionally, you can choose which set to use based on the decision to pipe a list of members to the command or provide a list of members. *-ADGroupMember cmdlets modify the membership of a group. For example: You can add or remove members of a group. You can pass a list of groups to these cmdlets. You can't pipe a list of members to these cmdlets. *-ADPrincipalGroupMembership cmdlets modify the group membership of an object such as a user. For example: You can add a user account as a member to a group. You can't provide a list of groups to these cmdlets. You can pipe a list of members to these cmdlets. The Active Directory module for Windows PowerShell cmdlets can be used to create and delete groups and to modify group properties. You can also use these cmdlets to change the group membership.","title":"Groups"},{"location":"Advanced/ad-gr/#managing-groups","text":"Cmdlets for modifying groups have the text \u201cgroup\u201d in their names. Cmdlet Description New-ADGroup Creates a new group Set-ADGroup Modifies properties of a group Get-ADGroup Displays properties of a group Remove-ADGroup Deletes a group Cmdlets that modify group membership by adding members to a group, for example, have the text \u201cgroupmember\u201d in their names. Cmdlet Description Add-ADGroupMember Adds members to a group Get-ADGroupMember Displays members of a group Remove-ADGroupMember Removes members from a group Cmdlets that modify the groups that a user, computer, or other Active Directory object is a member of have the text \u201cprincipalgroupmembership\u201d in their names. Cmdlet Description Add-ADPrincipalGroupMembership Adds group membership to an object Get-ADPrincipalGroupMembership Displays group membership of an object Remove-ADPrincipalGroupMembership Removes group membership from an object","title":"Managing groups"},{"location":"Advanced/ad-gr/#creating-new-groups","text":"You can use the New\u2011ADGroup cmdlet to create groups. When you create groups by using the New\u2011ADGroup cmdlet, you must use the \u2011GroupScope parameter in addition to the group name. This parameter is the only one required. Parameter Description \u2011Name Defines the name of a group \u2011GroupScope Defines the scope of a group as DomainLocal, Global, or Universal; you must provide this parameter \u2011DisplayName Defines the Lightweight Directory Access Protocol (LDAP) display name for an object \u2011GroupCategory Defines whether a group is a security group or a distribution group; if you don't specify either, a security group is created \u2011ManagedBy Defines a user or group that can manage a group \u2011Path Defines the OU or container in which a group is created \u2011SamAccountName Defines a name that is backward-compatible with older operating systems For example, to create a new group named FileServerAdmins, enter the following command in the console, and then press the Enter key: New-ADGroup -Name FileServerAdmins -GroupScope Global","title":"Creating new groups"},{"location":"Advanced/ad-gr/#managing-group-membership","text":"As previously mentioned, you can use the -ADGroupMember or the -ADPrincipalGroupMembership cmdlets to manage group management in two different ways. The difference between the two is a matter of focusing on an object and modifying the groups to which it belongs, or focusing on the group and modifying the members that belong to it. Additionally, you can choose which set to use based on the decision to pipe a list of members to the command or provide a list of members. *-ADGroupMember cmdlets modify the membership of a group. For example: You can add or remove members of a group. You can pass a list of groups to these cmdlets. You can't pipe a list of members to these cmdlets. *-ADPrincipalGroupMembership cmdlets modify the group membership of an object such as a user. For example: You can add a user account as a member to a group. You can't provide a list of groups to these cmdlets. You can pipe a list of members to these cmdlets. The Active Directory module for Windows PowerShell cmdlets can be used to create and delete groups and to modify group properties. You can also use these cmdlets to change the group membership.","title":"Managing group membership"},{"location":"Advanced/ad-obj/","text":"Active Directory object cmdlets You'll sometimes need to manage Active Directory objects that don't have their own management cmdlets, such as contacts. You might also want to manage multiple object types in a single operation, such as moving users and computers from one OU to another OU. The Active Directory module provides cmdlets that allow you to create, delete, and modify these objects and their properties. Because these cmdlets can manage all objects, they repeat some functionality of the cmdlets for managing users, computers, groups, and OUs. *-ADObject cmdlets sometimes perform faster than cmdlets that are specific to object type. This is because those cmdlets add the cost of filtering the set of applicable objects to their operations. Cmdlets for changing generic Active Directory objects have the text \u201cObject\u201d in the noun part of the name. Cmdlet Description New-ADObject Creates a new Active Directory object Set-ADObject Modifies properties of an Active Directory object Get-ADObject Displays properties of an Active Directory object Remove-ADObject Deletes an Active Directory object Rename-ADObject Renames an Active Directory object Restore-ADObject Restores a deleted Active Directory object from the Active Directory Recycle Bin Move-ADObject Moves an Active Directory object from one container to another container Sync-ADObject Syncs an Active Directory object between two domain controllers Creating a new Active Directory object You can use the New\u2011ADObject cmdlet to create objects. When using New-ADObject, you must specify the name and the object type. Parameter Description \u2011Name Defines the name of an object \u2011Type Defines the LDAP type of an object \u2011OtherAttributes Defines properties of an object that isn't accessible from other parameters \u2011Path Defines the container in which an object is created The following command creates a new contact object: New-ADObject -Name \"AnaBowmancontact\" -Type contact The Active Directory module provides cmdlets that allow you to create, delete, and modify those objects that don't have their own management cmdlets.","title":"Objects"},{"location":"Advanced/ad-obj/#active-directory-object-cmdlets","text":"You'll sometimes need to manage Active Directory objects that don't have their own management cmdlets, such as contacts. You might also want to manage multiple object types in a single operation, such as moving users and computers from one OU to another OU. The Active Directory module provides cmdlets that allow you to create, delete, and modify these objects and their properties. Because these cmdlets can manage all objects, they repeat some functionality of the cmdlets for managing users, computers, groups, and OUs. *-ADObject cmdlets sometimes perform faster than cmdlets that are specific to object type. This is because those cmdlets add the cost of filtering the set of applicable objects to their operations. Cmdlets for changing generic Active Directory objects have the text \u201cObject\u201d in the noun part of the name. Cmdlet Description New-ADObject Creates a new Active Directory object Set-ADObject Modifies properties of an Active Directory object Get-ADObject Displays properties of an Active Directory object Remove-ADObject Deletes an Active Directory object Rename-ADObject Renames an Active Directory object Restore-ADObject Restores a deleted Active Directory object from the Active Directory Recycle Bin Move-ADObject Moves an Active Directory object from one container to another container Sync-ADObject Syncs an Active Directory object between two domain controllers","title":"Active Directory object cmdlets"},{"location":"Advanced/ad-obj/#creating-a-new-active-directory-object","text":"You can use the New\u2011ADObject cmdlet to create objects. When using New-ADObject, you must specify the name and the object type. Parameter Description \u2011Name Defines the name of an object \u2011Type Defines the LDAP type of an object \u2011OtherAttributes Defines properties of an object that isn't accessible from other parameters \u2011Path Defines the container in which an object is created The following command creates a new contact object: New-ADObject -Name \"AnaBowmancontact\" -Type contact The Active Directory module provides cmdlets that allow you to create, delete, and modify those objects that don't have their own management cmdlets.","title":"Creating a new Active Directory object"},{"location":"Advanced/ad-ou/","text":"Windows PowerShell provides cmdlets that you can use to create, modify, and delete Active Directory Domain Services (AD DS) Organizational Units (OUs). Like the cmdlets for users, groups, and computers, you can use these cmdlets for individual operations or as part of a script to perform bulk operations. OU management cmdlets have the text \u201corganizationalunit\u201d in the name. Cmdlet Description New-ADOrganizationalUnit Creates an OU Set-ADOrganizationalUnit Modifies properties of an OU Get-ADOrganizationalUnit Displays properties of an OU Remove-ADOrganizationalUnit Deletes an OU Creating new OUs You can use the New\u2011ADOrganizationalUnit cmdlet to create a new OU to represent departments or physical locations within your organization. Parameter Description \u2011Name Defines the name of a new OU \u2011Path Defines the location of a new OU \u2011ProtectedFromAccidentalDeletion Prevents anyone from accidentally deleting an OU; the default value is $true The following example is a command to create a new OU: New-ADOrganizationalUnit -Name Sales -Path \"ou=marketing,dc=adatum,dc=com\" -ProtectedFromAccidentalDeletion $true Windows PowerShell provides cmdlets that you can use to create, modify, and delete Active Directory Domain Services (AD DS) Organizational Units (OUs). These too can be used for individual operations or as part of a script to perform bulk operations.","title":"Organizational Units"},{"location":"Advanced/ad-ou/#creating-new-ous","text":"You can use the New\u2011ADOrganizationalUnit cmdlet to create a new OU to represent departments or physical locations within your organization. Parameter Description \u2011Name Defines the name of a new OU \u2011Path Defines the location of a new OU \u2011ProtectedFromAccidentalDeletion Prevents anyone from accidentally deleting an OU; the default value is $true The following example is a command to create a new OU: New-ADOrganizationalUnit -Name Sales -Path \"ou=marketing,dc=adatum,dc=com\" -ProtectedFromAccidentalDeletion $true Windows PowerShell provides cmdlets that you can use to create, modify, and delete Active Directory Domain Services (AD DS) Organizational Units (OUs). These too can be used for individual operations or as part of a script to perform bulk operations.","title":"Creating new OUs"},{"location":"Advanced/ad-ur/","text":"Active Directory Domain Services (AD DS) and its related services form the core of Windows Server\u2013based networks. The AD DS database stores information about the objects that are part of the network environment, such as accounts for users, computers, and groups. The AD DS database is searchable and provides a mechanism for applying configuration and security settings for all of those objects. You can use the Active Directory module for Windows PowerShell to automate AD DS administration. By using Windows PowerShell for AD DS administration tasks, you can speed them up by making bulk updates instead of updating AD DS objects individually. If you don't have the Active Directory module installed on your machine, you'll need to download the correct Remote Server Administration Tools (RSAT) package for your operating system. RSAT is included as a set of Features on Demand, starting with the Windows 10 October 2018 Update. To install an RSAT package, you can refer to Optional features in Settings and select Add a feature to review the list of available RSAT tools. For AD DS administration, you'll need to select the RSAT: Active Directory Domain Services and Lightweight Directory Services Tools option. The Active Directory module for Windows PowerShell works for both Windows PowerShell and PowerShell. To find Active Directory cmdlets, search for the prefix \u201cAD,\u201d which most Active Directory cmdlets have in the noun part of the cmdlet name. Manage User Accounts User management is a core responsibility of administrators. You can use the Active Directory module for Windows PowerShell cmdlets to create, modify, and delete user accounts individually or in bulk. User account cmdlets have the word \u201cUser\u201d or \u201cAccount\u201d in the noun part of the name. To identify the available cmdlets, include them in wildcard name searches when you're using Get-Help or Get-Command. Cmdlet Description New-ADUser Creates a user account Get-ADUser Retrieves a user account Set-ADUser Modifies properties of a user account Remove-ADUser Deletes a user account Set-ADAccountPassword Resets the password of a user account Unlock-ADAccount Unlocks a user account that's been locked after exceeding the permitted number of incorrect sign-in attempts Enable-ADAccount Enables a user account Disable-ADAccount Disables a user account Retrieving users The Get-ADUser cmdlet requires that you identify the user or users that you want to retrieve. You can do this by using the -Identity parameter, which accepts one of several property values, including the Security Accounts Manager (SAM) account name or distinguished name. Windows PowerShell only returns a default set of properties when you use Get-ADUser. To review other properties, you'll need to use the -Properties parameter with a comma-separated list of properties or the \u201c*\u201d wildcard. For example, you can retrieve the default set of properties along with the department and email address of a user with the SAM account anabowman by entering the following command in the console, and then pressing the Enter key: Get-ADUser -Identity anabowman -Properties Department , EmailAddress The other way to specify a user or users is with the -Filter parameter. The -Filter parameter accepts a query based on regular expressions, which later modules in this course describe in more detail. For example, to retrieve all AD DS users and their properties, enter the following command in the console, and then press the Enter key: Get-ADUser -Filter * -Properties * Creating new user accounts When you use the New\u2011ADUser cmdlet to create new user accounts, the -Name parameter is required. You can also set most other user properties, including a password. When you create a new account, consider the following points: If you don't use the -AccountPassword parameter, then no password is set, and the user account is disabled. You can't set the -Enabled parameter as $true when no password is set. If you use the -AccountPassword parameter to specify a password, then you must specify a variable that contains the password as a secure string or choose to enter the password from the console. A secure string is encrypted in memory. If you set a password, then you can enable the user account by setting the -Enabled parameter as $true. Parameter Description \u2011AccountExpirationDate Defines the expiration date for a user account \u2011AccountPassword Defines the password for a user account \u2011ChangePasswordAtLogon Requires a user account to change passwords at the next sign-in \u2011Department Defines the department for a user account \u2011DisplayName Defines the display name for a user account \u2011HomeDirectory Defines the location of the home directory for a user account \u2011HomeDrive Defines the drive letters that map to the home directory for a user account \u2011GivenName Defines the first name of a user account To add a user account and set its Department attribute to IT , enter the following command in the console, and then press the Enter key: New-ADUser \"Ana Bowman\" -Department IT Because no password was set by the command you ran, the user account is disabled, and you can't enable it until a password is assigned. The Active Directory module for Windows PowerShell cmdlets can help with user management, which is a core responsibility of administrators. It helps create, modify, and delete user accounts individually or in bulk.","title":"Users"},{"location":"Advanced/ad-ur/#manage-user-accounts","text":"User management is a core responsibility of administrators. You can use the Active Directory module for Windows PowerShell cmdlets to create, modify, and delete user accounts individually or in bulk. User account cmdlets have the word \u201cUser\u201d or \u201cAccount\u201d in the noun part of the name. To identify the available cmdlets, include them in wildcard name searches when you're using Get-Help or Get-Command. Cmdlet Description New-ADUser Creates a user account Get-ADUser Retrieves a user account Set-ADUser Modifies properties of a user account Remove-ADUser Deletes a user account Set-ADAccountPassword Resets the password of a user account Unlock-ADAccount Unlocks a user account that's been locked after exceeding the permitted number of incorrect sign-in attempts Enable-ADAccount Enables a user account Disable-ADAccount Disables a user account","title":"Manage User Accounts"},{"location":"Advanced/ad-ur/#retrieving-users","text":"The Get-ADUser cmdlet requires that you identify the user or users that you want to retrieve. You can do this by using the -Identity parameter, which accepts one of several property values, including the Security Accounts Manager (SAM) account name or distinguished name. Windows PowerShell only returns a default set of properties when you use Get-ADUser. To review other properties, you'll need to use the -Properties parameter with a comma-separated list of properties or the \u201c*\u201d wildcard. For example, you can retrieve the default set of properties along with the department and email address of a user with the SAM account anabowman by entering the following command in the console, and then pressing the Enter key: Get-ADUser -Identity anabowman -Properties Department , EmailAddress The other way to specify a user or users is with the -Filter parameter. The -Filter parameter accepts a query based on regular expressions, which later modules in this course describe in more detail. For example, to retrieve all AD DS users and their properties, enter the following command in the console, and then press the Enter key: Get-ADUser -Filter * -Properties *","title":"Retrieving users"},{"location":"Advanced/ad-ur/#creating-new-user-accounts","text":"When you use the New\u2011ADUser cmdlet to create new user accounts, the -Name parameter is required. You can also set most other user properties, including a password. When you create a new account, consider the following points: If you don't use the -AccountPassword parameter, then no password is set, and the user account is disabled. You can't set the -Enabled parameter as $true when no password is set. If you use the -AccountPassword parameter to specify a password, then you must specify a variable that contains the password as a secure string or choose to enter the password from the console. A secure string is encrypted in memory. If you set a password, then you can enable the user account by setting the -Enabled parameter as $true. Parameter Description \u2011AccountExpirationDate Defines the expiration date for a user account \u2011AccountPassword Defines the password for a user account \u2011ChangePasswordAtLogon Requires a user account to change passwords at the next sign-in \u2011Department Defines the department for a user account \u2011DisplayName Defines the display name for a user account \u2011HomeDirectory Defines the location of the home directory for a user account \u2011HomeDrive Defines the drive letters that map to the home directory for a user account \u2011GivenName Defines the first name of a user account To add a user account and set its Department attribute to IT , enter the following command in the console, and then press the Enter key: New-ADUser \"Ana Bowman\" -Department IT Because no password was set by the command you ran, the user account is disabled, and you can't enable it until a password is assigned. The Active Directory module for Windows PowerShell cmdlets can help with user management, which is a core responsibility of administrators. It helps create, modify, and delete user accounts individually or in bulk.","title":"Creating new user accounts"},{"location":"Advanced/job-back/","text":"In addition to the traditional tasks that run in the foreground within the Windows PowerShell console or ISE, you also can run background tasks. When you run a command as a background job, Windows PowerShell performs the task asynchronously in its own thread. This thread is separate from the pipeline thread that the command uses. When a command runs as a background job, even if it takes a long time to complete, you regain access to the PowerShell prompt immediately. This allows you to run other commands while the job runs in the background. Types of Background Jobs There are three basic types of background jobs: Local jobs run their commands on the local computer and typically access only local resources. However, you can create local jobs that target a remote computer. For example, you could create a local job that includes the following command, where the \u2013ComputerName parameter makes it connect to a remote computer: Get-Service \u2013 Name * -ComputerName LON-DC1 Remote jobs use Windows PowerShell remote to transmit commands to one or more remote computers. The commands run on those remote computers and the results are returned to the local computer and stored in memory. Windows PowerShell Help files refer to this kind of job as a remote job. CIM and WMI jobs use the Common Information Model (CIM) and Windows Management Instrumentation (WMI) repository of management information. The commands run on your computer but can connect to one or more remote computers' repositories. Local jobs that use CIM commands use the Start-Job command, whereas WMI and other commands use the -AsJob parameter within a WMI command. Each job type has specific characteristics. For example, local and Windows PowerShell remote jobs run in a background Windows PowerShell run space. Think of them as running in a hidden instance of Windows PowerShell. Other types of jobs might have different characteristics. Also, add-in modules add more job types to Windows PowerShell, and those job types have their own characteristics. Remote jobs are useful for managing multiple remote computers simultaneously. Remote computers run Windows PowerShell remote commands by using their own local resources. Therefore, you can include any command in the job. Remember that these job types aren't the only ones that Windows PowerShell supports. Use modules and other add-ins to create other job types. Workflow jobs help you automate long-running tasks, or workflows, by simultaneously targeting multiple managed computers or devices. Windows PowerShell workflows offer extra resiliency benefits. When you restart target devices, unfinished workflow automatically restarts on the target device or devices and continues with the job's workflow commands. It's important to note that interactive Windows PowerShell console workflow jobs aren't available in a noninteractive Windows PowerShell console. Scheduling a task to run at machine startup won't find suspended jobs from a noninteractive console. Scheduled tasks can't find workflow jobs to resume unless you're signed in to an interactive session. Local Jobs Start local jobs by running Start-Job. Provide either the \u2013ScriptBlock parameter to specify a single command line or a small number of commands. Provide the \u2013FilePath parameter to run an entire script on a background thread. By default, jobs receive a sequential job identification (ID) number and a default job name. You can't change the assigned job ID number, but you can use the \u2013Name parameter to specify a custom job name. Custom names make it easier to retrieve a job and identify it in the job list. At first, job ID numbers might not seem to be sequential. However, you'll learn the reason for this later in this module. You can specify the \u2013Credential parameter to run a job under a different user account. Other parameters allow you to run the command under a specific Windows PowerShell version, in a 32-bit session, and in other sessions. Here are examples of how to start local jobs: Start-Job -ScriptBlock { Dir C :\\ -Recurse } -Name LocalDirectory Id Name PSJobTypeName State HasMoreData Location -- ---- ------------- ----- ----------- -------- 2 LocalDirectory BackgroundJob Running True localhost Start-Job -FilePath C :\\ test . ps1 -Name TestScript Id Name PSJobTypeName State HasMoreData Location -- ---- ------------- ----- ----------- -------- 4 TestScript BackgroundJob Running True localhost Remote Jobs Start Windows PowerShell remote jobs by running Invoke-Command. This is the same command that sends commands to a remote computer. Add the \u2013AsJob parameter to make the command run in the background. Use the \u2013JobName parameter to specify a custom job name. All other parameters of Invoke-Command are used in the same way. Here's an example: Invoke-Command -ScriptBlock { Get-EventLog -LogName System -Newest 10 } -ComputerName LON-DC1 , LON-CL1 , LON-SVR1 -AsJob -JobName RemoteLogs Id Name PSJobTypeName State HasMoreData Location -- ---- ------------- ----- ----------- -------- 6 RemoteLogs RemoteJob Running True LON-DC1 ... The \u2013ComputerName parameter is a parameter of Invoke-Command, not of Get-EventLog. The parameter causes the local computer to coordinate the Windows PowerShell remote connections to the three computers specified. Each computer receives only the Get-EventLog command and runs it locally, returning results. The computer on which you run Invoke-Command creates and manages remote jobs. You can refer to that computer as the initiating computer. The commands inside the job are transmitted to remote computers, which then run them and return results to the initiating computer. The initiating computer stores the job\u2019s results in its memory. CIM and WMI Jobs To use CIM commands in a job, you must launch the job with Start-Job. Here's an example: Start-Job -ScriptBlock { Get-CimInstance -ClassName Win32_ComputerSystem } Id Name PSJobTypeName State HasMoreData Location Command -- ---- ------------- ----- ----------- -------- ------- 3 Job3 BackgroundJob Running True localhost Get-CimInstance -Class .. You also can run other commands that use CIM as jobs by using Start-Job. An example is Invoke-CimMethod. The fact that CIM commands don't have an \u2013AsJob parameter isn't important. You just need to remember to use the job commands when you want to run CIM commands as jobs. Start a WMI job by running Get-WmiObject. This is the same command you'd use to query WMI instances. Add the \u2013AsJob parameter to run the command on a background thread. There's no option to provide a custom job name. The Get-Help information for Get-WmiObject states the following for the \u2013AsJob parameter: To use this parameter with remote computers, the local and remote computers must be configured for Windows PowerShell remoting. Additionally, you must start Windows PowerShell by using the Run as administrator option in Windows 7 and newer versions of Windows. WMI jobs don't require that you enable Windows PowerShell remoting on either the initiating computer or the remote computer. However, they do require that WMI be accessible on the remote computers. Here's an example: Get-WmiObject -Class Win32_NTEventLogFile -ComputerName localhost , LON-DC1 -AsJob Id Name PSJobTypeName State HasMoreData Location -- --- - ------------- ----- ----------- -------- 10 Job10 WmiJob Running True localho ... Job Objects Notice that each of the preceding examples results in a job object. It represents the running job, and you can use it to monitor and manage the job. Each job consists of at least two job objects. The parent job is the top-level object and represents the entire job, regardless of the number of computers to which the job connects. The parent job contains one or more child jobs. Each child job represents a single computer. A local job contains only one child job. Windows PowerShell remoting and WMI jobs contain one child job for each computer that you specify. Retrieving Jobs Run Get-Job to list all current jobs. You can list a specified job by adding the \u2013ID or \u2013Name parameter and specifying the desired job ID or job name. Retrieve child jobs by using the job ID. Here are examples: Get-Job Id Name PSJobTypeName State HasMoreData Location -- ---- ------------- ----- ----------- -------- 2 LocalDirectory BackgroundJob Running True localhost 4 TestScript BackgroundJob Completed True localhost 6 RemoteLogs RemoteJob Failed True LON-DC1 ... 10 Job10 WmiJob Failed False localho ... Get-Job -Name TestScript Id Name PSJobTypeName State HasMoreData Location -- ---- ------------- ----- ----------- -------- 4 TestScript BackgroundJob Completed True localhost Get-Job -ID 5 Id Name PSJobTypeName State HasMoreData Location -- ---- ------------- ----- ----------- -------- 5 Job5 Completed True localhost Notice that each job has a state. Parent jobs always display the state of any failed child jobs, even if other child jobs succeeded. In other words, if a parent job contains four child jobs, and three of those jobs finished successfully but one failed, the parent job status will be Failed. Listing Jobs List the child jobs of a specified parent job by retrieving the parent job object and expanding its ChildJobs property. In Windows PowerShell 3.0 and newer, use the -IncludeChildJobs parameter of Get-Job to display a job\u2019s child jobs. Here's an example: C :\\ PS > Get-Job -Name RemoteJobs -IncludeChildJobs Id Name PSJobTypeName State HasMoreData Location -- ---- ------------- ----- ----------- -------- 7 Job7 Failed False LON-DC1 8 Job8 Completed True LON-CL1 9 Job9 Failed False LON-SVR1 The earlier method uses the following example: Get-Job -Name RemoteLogs | Select -ExpandProperty ChildJobs Id Name PSJobTypeName State HasMoreData Location -- ---- ------------- ----- ----------- -------- 7 Job7 Failed False LON-DC1 8 Job8 Completed True LON-CL1 9 Job9 Failed False LON-SVR1 This technique enables you to discover the job ID numbers and names of the child job objects. Notice that child jobs all have a default name that corresponds with their ID number. The preceding syntax will work in Windows PowerShell 2.0 and newer versions. Job-Management Commands Manage jobs by using several available Windows PowerShell commands. Pipe one or more jobs to each of these commands or specify jobs by using the \u2013ID or \u2013Name parameters. Both parameters accept multiple values, which means that you can specify a comma-separated list of job ID numbers or names. The job-management commands include: Stop-Job, which halts a job that's running. Use this command to cancel a job that's in an infinite loop or that has run longer than you want. Remove-Job, which deletes a job object, including any command results stored in memory. Use this command when you're finished working with a job, so the shell releases memory. Wait-Job, which you typically use in a script. It pauses script processing until the jobs you indicate reach the specified state. Use this command in a script to start several jobs, and then make the script wait until those jobs complete before continuing. The Windows PowerShell process manages remote, WMI, and local jobs. When you close a PowerShell session, Windows PowerShell removes all jobs and their results, and you can no longer access them. Retrieve Results When a job runs, Windows PowerShell stores all command outputs in memory, starting with the first output that the command produced. You don't have to wait for a command to complete before output becomes available. The job list indicates whether a job has stored results that you haven\u2019t yet retrieved. Here's an example: Get-Job Id Name PSJobTypeName State HasMoreData Location -- ---- ------------- ----- ----------- -------- 13 Job13 BackgroundJob Running True localhost In this example, job ID 13 is still running, but the HasMoreData column indicates that results already have been stored in memory. To receive a job's results, use the Receive-Job command. By default, job results are removed from memory after they're delivered to you. That means that you can use Receive-Job only once per job. Add the \u2013Keep parameter to retain a copy of the job results in memory, so that you can retrieve them again. If you retrieve the results of a parent job, you'll receive the results from all child jobs. You also can retrieve the results of a single child job or multiple child jobs. You also can retrieve the results of a job that's still running. However, unless you specify \u2013Keep, the job object\u2019s results will be empty until the job\u2019s command adds new output. Here's an example: Receive-Job \u2013 ID 13 -Keep | Format-Table \u2013 Property Name , Length","title":"Background Jobs"},{"location":"Advanced/job-back/#types-of-background-jobs","text":"There are three basic types of background jobs: Local jobs run their commands on the local computer and typically access only local resources. However, you can create local jobs that target a remote computer. For example, you could create a local job that includes the following command, where the \u2013ComputerName parameter makes it connect to a remote computer: Get-Service \u2013 Name * -ComputerName LON-DC1 Remote jobs use Windows PowerShell remote to transmit commands to one or more remote computers. The commands run on those remote computers and the results are returned to the local computer and stored in memory. Windows PowerShell Help files refer to this kind of job as a remote job. CIM and WMI jobs use the Common Information Model (CIM) and Windows Management Instrumentation (WMI) repository of management information. The commands run on your computer but can connect to one or more remote computers' repositories. Local jobs that use CIM commands use the Start-Job command, whereas WMI and other commands use the -AsJob parameter within a WMI command. Each job type has specific characteristics. For example, local and Windows PowerShell remote jobs run in a background Windows PowerShell run space. Think of them as running in a hidden instance of Windows PowerShell. Other types of jobs might have different characteristics. Also, add-in modules add more job types to Windows PowerShell, and those job types have their own characteristics. Remote jobs are useful for managing multiple remote computers simultaneously. Remote computers run Windows PowerShell remote commands by using their own local resources. Therefore, you can include any command in the job. Remember that these job types aren't the only ones that Windows PowerShell supports. Use modules and other add-ins to create other job types. Workflow jobs help you automate long-running tasks, or workflows, by simultaneously targeting multiple managed computers or devices. Windows PowerShell workflows offer extra resiliency benefits. When you restart target devices, unfinished workflow automatically restarts on the target device or devices and continues with the job's workflow commands. It's important to note that interactive Windows PowerShell console workflow jobs aren't available in a noninteractive Windows PowerShell console. Scheduling a task to run at machine startup won't find suspended jobs from a noninteractive console. Scheduled tasks can't find workflow jobs to resume unless you're signed in to an interactive session.","title":"Types of Background Jobs"},{"location":"Advanced/job-back/#local-jobs","text":"Start local jobs by running Start-Job. Provide either the \u2013ScriptBlock parameter to specify a single command line or a small number of commands. Provide the \u2013FilePath parameter to run an entire script on a background thread. By default, jobs receive a sequential job identification (ID) number and a default job name. You can't change the assigned job ID number, but you can use the \u2013Name parameter to specify a custom job name. Custom names make it easier to retrieve a job and identify it in the job list. At first, job ID numbers might not seem to be sequential. However, you'll learn the reason for this later in this module. You can specify the \u2013Credential parameter to run a job under a different user account. Other parameters allow you to run the command under a specific Windows PowerShell version, in a 32-bit session, and in other sessions. Here are examples of how to start local jobs: Start-Job -ScriptBlock { Dir C :\\ -Recurse } -Name LocalDirectory Id Name PSJobTypeName State HasMoreData Location -- ---- ------------- ----- ----------- -------- 2 LocalDirectory BackgroundJob Running True localhost Start-Job -FilePath C :\\ test . ps1 -Name TestScript Id Name PSJobTypeName State HasMoreData Location -- ---- ------------- ----- ----------- -------- 4 TestScript BackgroundJob Running True localhost","title":"Local Jobs"},{"location":"Advanced/job-back/#remote-jobs","text":"Start Windows PowerShell remote jobs by running Invoke-Command. This is the same command that sends commands to a remote computer. Add the \u2013AsJob parameter to make the command run in the background. Use the \u2013JobName parameter to specify a custom job name. All other parameters of Invoke-Command are used in the same way. Here's an example: Invoke-Command -ScriptBlock { Get-EventLog -LogName System -Newest 10 } -ComputerName LON-DC1 , LON-CL1 , LON-SVR1 -AsJob -JobName RemoteLogs Id Name PSJobTypeName State HasMoreData Location -- ---- ------------- ----- ----------- -------- 6 RemoteLogs RemoteJob Running True LON-DC1 ... The \u2013ComputerName parameter is a parameter of Invoke-Command, not of Get-EventLog. The parameter causes the local computer to coordinate the Windows PowerShell remote connections to the three computers specified. Each computer receives only the Get-EventLog command and runs it locally, returning results. The computer on which you run Invoke-Command creates and manages remote jobs. You can refer to that computer as the initiating computer. The commands inside the job are transmitted to remote computers, which then run them and return results to the initiating computer. The initiating computer stores the job\u2019s results in its memory.","title":"Remote Jobs"},{"location":"Advanced/job-back/#cim-and-wmi-jobs","text":"To use CIM commands in a job, you must launch the job with Start-Job. Here's an example: Start-Job -ScriptBlock { Get-CimInstance -ClassName Win32_ComputerSystem } Id Name PSJobTypeName State HasMoreData Location Command -- ---- ------------- ----- ----------- -------- ------- 3 Job3 BackgroundJob Running True localhost Get-CimInstance -Class .. You also can run other commands that use CIM as jobs by using Start-Job. An example is Invoke-CimMethod. The fact that CIM commands don't have an \u2013AsJob parameter isn't important. You just need to remember to use the job commands when you want to run CIM commands as jobs. Start a WMI job by running Get-WmiObject. This is the same command you'd use to query WMI instances. Add the \u2013AsJob parameter to run the command on a background thread. There's no option to provide a custom job name. The Get-Help information for Get-WmiObject states the following for the \u2013AsJob parameter: To use this parameter with remote computers, the local and remote computers must be configured for Windows PowerShell remoting. Additionally, you must start Windows PowerShell by using the Run as administrator option in Windows 7 and newer versions of Windows. WMI jobs don't require that you enable Windows PowerShell remoting on either the initiating computer or the remote computer. However, they do require that WMI be accessible on the remote computers. Here's an example: Get-WmiObject -Class Win32_NTEventLogFile -ComputerName localhost , LON-DC1 -AsJob Id Name PSJobTypeName State HasMoreData Location -- --- - ------------- ----- ----------- -------- 10 Job10 WmiJob Running True localho ...","title":"CIM and WMI Jobs"},{"location":"Advanced/job-back/#job-objects","text":"Notice that each of the preceding examples results in a job object. It represents the running job, and you can use it to monitor and manage the job. Each job consists of at least two job objects. The parent job is the top-level object and represents the entire job, regardless of the number of computers to which the job connects. The parent job contains one or more child jobs. Each child job represents a single computer. A local job contains only one child job. Windows PowerShell remoting and WMI jobs contain one child job for each computer that you specify.","title":"Job Objects"},{"location":"Advanced/job-back/#retrieving-jobs","text":"Run Get-Job to list all current jobs. You can list a specified job by adding the \u2013ID or \u2013Name parameter and specifying the desired job ID or job name. Retrieve child jobs by using the job ID. Here are examples: Get-Job Id Name PSJobTypeName State HasMoreData Location -- ---- ------------- ----- ----------- -------- 2 LocalDirectory BackgroundJob Running True localhost 4 TestScript BackgroundJob Completed True localhost 6 RemoteLogs RemoteJob Failed True LON-DC1 ... 10 Job10 WmiJob Failed False localho ... Get-Job -Name TestScript Id Name PSJobTypeName State HasMoreData Location -- ---- ------------- ----- ----------- -------- 4 TestScript BackgroundJob Completed True localhost Get-Job -ID 5 Id Name PSJobTypeName State HasMoreData Location -- ---- ------------- ----- ----------- -------- 5 Job5 Completed True localhost Notice that each job has a state. Parent jobs always display the state of any failed child jobs, even if other child jobs succeeded. In other words, if a parent job contains four child jobs, and three of those jobs finished successfully but one failed, the parent job status will be Failed.","title":"Retrieving Jobs"},{"location":"Advanced/job-back/#listing-jobs","text":"List the child jobs of a specified parent job by retrieving the parent job object and expanding its ChildJobs property. In Windows PowerShell 3.0 and newer, use the -IncludeChildJobs parameter of Get-Job to display a job\u2019s child jobs. Here's an example: C :\\ PS > Get-Job -Name RemoteJobs -IncludeChildJobs Id Name PSJobTypeName State HasMoreData Location -- ---- ------------- ----- ----------- -------- 7 Job7 Failed False LON-DC1 8 Job8 Completed True LON-CL1 9 Job9 Failed False LON-SVR1 The earlier method uses the following example: Get-Job -Name RemoteLogs | Select -ExpandProperty ChildJobs Id Name PSJobTypeName State HasMoreData Location -- ---- ------------- ----- ----------- -------- 7 Job7 Failed False LON-DC1 8 Job8 Completed True LON-CL1 9 Job9 Failed False LON-SVR1 This technique enables you to discover the job ID numbers and names of the child job objects. Notice that child jobs all have a default name that corresponds with their ID number. The preceding syntax will work in Windows PowerShell 2.0 and newer versions.","title":"Listing Jobs"},{"location":"Advanced/job-back/#job-management-commands","text":"Manage jobs by using several available Windows PowerShell commands. Pipe one or more jobs to each of these commands or specify jobs by using the \u2013ID or \u2013Name parameters. Both parameters accept multiple values, which means that you can specify a comma-separated list of job ID numbers or names. The job-management commands include: Stop-Job, which halts a job that's running. Use this command to cancel a job that's in an infinite loop or that has run longer than you want. Remove-Job, which deletes a job object, including any command results stored in memory. Use this command when you're finished working with a job, so the shell releases memory. Wait-Job, which you typically use in a script. It pauses script processing until the jobs you indicate reach the specified state. Use this command in a script to start several jobs, and then make the script wait until those jobs complete before continuing. The Windows PowerShell process manages remote, WMI, and local jobs. When you close a PowerShell session, Windows PowerShell removes all jobs and their results, and you can no longer access them.","title":"Job-Management Commands"},{"location":"Advanced/job-back/#retrieve-results","text":"When a job runs, Windows PowerShell stores all command outputs in memory, starting with the first output that the command produced. You don't have to wait for a command to complete before output becomes available. The job list indicates whether a job has stored results that you haven\u2019t yet retrieved. Here's an example: Get-Job Id Name PSJobTypeName State HasMoreData Location -- ---- ------------- ----- ----------- -------- 13 Job13 BackgroundJob Running True localhost In this example, job ID 13 is still running, but the HasMoreData column indicates that results already have been stored in memory. To receive a job's results, use the Receive-Job command. By default, job results are removed from memory after they're delivered to you. That means that you can use Receive-Job only once per job. Add the \u2013Keep parameter to retain a copy of the job results in memory, so that you can retrieve them again. If you retrieve the results of a parent job, you'll receive the results from all child jobs. You also can retrieve the results of a single child job or multiple child jobs. You also can retrieve the results of a job that's still running. However, unless you specify \u2013Keep, the job object\u2019s results will be empty until the job\u2019s command adds new output. Here's an example: Receive-Job \u2013 ID 13 -Keep | Format-Table \u2013 Property Name , Length","title":"Retrieve Results"},{"location":"Advanced/job-sched/","text":"Scheduled jobs are a combination of Windows PowerShell background jobs and Windows Task Scheduler tasks. Similar to background jobs, you define scheduled jobs in Windows PowerShell. Additionally, like tasks, job results are saved to disk, and scheduled jobs can run even if Windows PowerShell isn't running. Scheduled tasks Scheduled tasks are part of the Windows core infrastructure components. Other Windows components and products that run on Windows extensively use scheduled tasks. They're generally simpler than scheduled jobs. The Task Scheduler enables you to configure a schedule for running almost any program or process, in any security context, triggered by various system events or a particular date or time. However, scheduled tasks can't capture and manipulate task output. A scheduled task can run almost anything runnable on a Windows device, so it's impossible to anticipate and capture the scheduled task\u2019s output. However, because a Windows PowerShell scheduled job is always a Windows PowerShell script, even if that script runs a non-Windows PowerShell program, the system is able to capture output. In this case, a Windows PowerShell object is returned at the end of the script block. A scheduled task consists of: The Action, which specifies the program to be run. The Principal, which identifies the context to use to run an action. The Trigger, which defines the time or system event that determines when the program is to be run. The Additional settings, which further configure the task and control how the action is run. Commands that work with scheduled tasks are in the ScheduledTasks module that's included with Windows 10 and Windows Server 2019. To review the complete list of commands, run the following command: Get-Command \u2013 Module ScheduledTasks As an example, check on the available scheduled tasks by running the Get-ScheduledTask command. This will list all available scheduled tasks, regardless of whether they're enabled or disabled. Get information on a specific task by running Get-ScheduledTask with the -TaskPath parameter. For best practices, ensure that you put the actual path in quotes. Get further information about a particular task by using the Get-ScheduledTaskInfo command. You can then combine these commands using a pipeline to get additional information. For example, retrieve detailed information about the Automatic Update task running on your system by entering the following command: Get-ScheduledTask -TaskPath \"\\Microsoft\\Windows\\WindowsUpdate\\\" | Get-ScheduledTaskInfo You also can create and run scheduled tasks from the Task Scheduler. However, what if you're running Windows PowerShell commands or scripts, or Windows tools that don't write their output to a file? If output is important to you, a better choice is using a Windows PowerShell scheduled job. After that job is in the Task Scheduler, you can manipulate it further. You can start or stop it in the Task Scheduler. If you want to create multiple scheduled jobs or tasks locally, or even on remote computers, automate their creation and maintenance with the scheduled job or the scheduled task commands. Adding Windows PowerShell scripts as scheduled jobs in the Task Scheduler can greatly improve your productivity. PowerShell Gallery contains thousands of scripts that you can use or modify for your specific use, and these scripts are separated into various categories. For example, there are hundreds of viable scripts that you can run against Active Directory Domain Services (AD DS) and other Active Directory services. Some of these scripts can be very useful. An example is the script that finds user accounts that haven't been used for more than 90 days and then disables them, which can help strengthen domain security. You can modify this script to your specific domain, and then create it as a scheduled job. After you configure this task, you can then find and manipulate the job in the Task Scheduler. Schedule it to run every week and provide a report about what accounts, if any, were disabled. Define Scheduled Jobs Scheduled jobs are a useful combination of Windows PowerShell background jobs and Windows Task Scheduler tasks. Similar to the latter, scheduled jobs are saved to disk. You can review and manage Windows PowerShell scheduled jobs in the Task Scheduler, enabling and disabling tasks or simply running the scheduled job. You can even use the scheduled job: As a template for creating other scheduled jobs. To establish a one-time schedule or periodic schedule for starting jobs. To set conditions under which jobs start again. You can do all of these tasks from the Task Scheduler. Windows PowerShell saves the results of scheduled jobs to disk and creates a running log of job output. Scheduled jobs have a customized set of commands that you can use to manage them. You can use these commands to create, edit, manage, disable, and re-enable scheduled jobs, job triggers, and job options. To create a scheduled job, use the scheduled job commands. Note that anything created in Task Scheduler is considered a scheduled task even if it's in the Microsoft\\Windows\\PowerShell\\ScheduledJobs path in the Task Scheduler. After you create a scheduled job, review and manage it in the Task Scheduler by selecting a scheduled job to: Find the job triggers on the Triggers tab. Find the scheduled job options on the General and Conditions tabs. Review the job instances that have already been run on the History tab. When you change a scheduled job setting in Task Scheduler, the change applies for all future instances of that scheduled job. The commands that work with scheduled jobs in the PSScheduledJob module are included in the current versions of the Windows Server and Client operating systems. To review the complete list of commands, run the following command: Get-Command \u2013 Module PSScheduledJob Scheduled jobs consist of three components: The job itself defines the command that will run. Job options define options and running criteria. Job triggers define when the job will run. You typically create a job option object and a job trigger object, and store those objects in variables. You then use those variables when creating the actual scheduled job. The ScheduledTasks module includes commands that can manage all tasks in the Windows Task Scheduler. Job options Use New-ScheduledJobOption to create a new job option object. This command has several parameters that let you define options for the job, such as: \u2013HideInTaskScheduler, which prevents the job from displaying in the Task Scheduler. If you don't include this option, the final job will display in the Task Scheduler graphical user interface (GUI). \u2013RunElevated, which configures the job to run under elevated permissions. \u2013WakeToRun, which wakes the computer when the job is scheduled to run. Use other parameters to configure jobs that run when the computer is idle and other options. Many parameters correspond to options in the Task Scheduler GUI. Create a new option object and store it in a variable by using the following command: $opt = New-ScheduledJobOption \u2013 RequireNetwork \u2013 RunElevated -WakeToRun You don't need to create an option object if you don't want to specify any of its configuration items. Job triggers A job trigger defines when a job will run. Each job can have multiple triggers. You create a trigger object by using the New-JobTrigger command. There are five basic types of triggers: \u2013Once specifies a job that runs one time only. You can also specify a \u2013RandomDelay, and you must specify the \u2013At parameter to define when the job will run. That parameter accepts a System.DateTime object or a string that can be interpreted as a date. \u2013Weekly specifies a job that runs weekly. You can specify a \u2013RandomDelay, and you must specify both the \u2013At and \u2013DaysOfWeek parameters. \u2013At accepts a date and time to define when the job will run. \u2013DaysOfWeek accepts one or more days of the week to run the job. You'll typically use \u2013At to specify a time and use \u2013DaysOfWeek to define the days the job should run. \u2013Daily specifies a job that runs every day. You must specify \u2013At and provide a time when the job will run. You can also specify a \u2013RandomDelay. \u2013AtLogOn specifies a job that runs when the user logs on. This kind of job is similar to a logon script, except that it's defined locally rather than in the domain. You can specify \u2013User to limit the user accounts that trigger the job, and \u2013RandomDelay to add a random delay. \u2013AtStartUp is similar to \u2013AtLogOn, except that it runs the job when the computer starts. That typically runs the job before a user signs in. For example, the following command creates a trigger that runs on Mondays and Thursdays every week, at 3:00 PM local time: $trigger = New-JobTrigger -Weekly -DaysOfWeek Monday , Thursday -At '3:00PM' Create and Register a Scheduled Job Use Register-ScheduledJob to create and register a new scheduled job. Specify any of the following parameters: \u2013Name is required and specifies a display name for the job. \u2013ScriptBlock is required and specifies the command or commands that the job runs. You also could specify + \u2013FilePath and provide the path and name of a Windows PowerShell script file that the job will run. \u2013Credential is optional and specifies the user account that will be used to run the job. \u2013InitializationScript accepts an optional script block. The command or commands in that script block will run before the job starts. \u2013MaxResultCount is optional and specifies the maximum number of result sets to store on disk. After this number is reached, the shell deletes older results to make room for new ones. The default value for the + -MaxResultCount parameter is 32. \u2013ScheduledJobOption accepts a job option object. \u2013Trigger accepts a job trigger object. To register a new job by using an option object in $opt and a trigger object in $trigger, use the following example: $opt = New-ScheduledJobOption -WakeToRun $trigger = New-ScheduledTaskTrigger -Once -At ( Get-Date ). AddMinutes ( 5 ) Register-ScheduledJob -Trigger $trigger -ScheduledJobOption $opt -ScriptBlock { Dir C :\\ } -MaxResultCount 5 -Name \"LocalDir\" Id Name JobTriggers Command Enabled -- ---- ----------- ------- ------- 1 LocalDir 1 Dir C :\\ True Windows PowerShell registers the resulting job in the Windows Task Scheduler and creates the job definition on disk. Job definitions are XML files stored in your profile folder in \\AppData\\Local\\Microsoft\\Windows\\PowerShell\\ScheduledJobs. You can run Get-ScheduledJob to review a list of scheduled jobs on the local computer. If you know a scheduled job\u2019s name, you can use Get-JobTrigger and the \u2013Name parameter to retrieve a list of that job\u2019s triggers. Retrieve The Results Because scheduled jobs can run when Windows PowerShell isn't running, results are stored on disk in XML files. If you create a job by using the \u2013MaxResultCount parameter, the shell automatically deletes old XML files to make room for new ones. This deletion ensures that no more XML files exist than were specified in the \u2013MaxResultCount parameter. After a scheduled job finishes, running Get-Job in Windows PowerShell displays the scheduled job's results as a job object. Here's an example: Get-Job Id Name PSJobTypeName State HasMoreData Location Command -- ---- ------------- ----- ----------- -------- ------- 6 LocalDir PSScheduledJob Completed True localhost Dir C :\\ You can use Receive-Job to get a scheduled job's results. If you don't specify \u2013Keep, you can receive a job's results only once per Windows PowerShell session. However, because the results are stored on disk, you can open a new Windows PowerShell session and receive the results again. For example: Receive-Job -id 6 -Keep Directory : C :\\ Mode LastWriteTime Length Name ---- ------------- ------ ---- d ---- 7 / 26 / 2021 12 : 33 AM PerfLogs d-r -- 11 / 28 / 2021 1 : 54 PM Program Files d-r -- 12 / 28 / 2021 2 : 22 PM Program Files ( x86 ) d ---- 11 / 16 / 2021 9 : 33 AM reports d ---- 9 / 18 / 2021 7 : 28 AM Review d ---- 1 / 5 / 2022 7 : 49 AM scr d ---- 1 / 5 / 2022 7 : 50 AM scrx d-r -- 9 / 15 / 2021 8 : 16 AM Users d ---- 12 / 19 / 2021 3 : 24 AM Windows -a --- 1 / 1 / 2022 9 : 39 AM 2892628 EventReport . html -a --- 1 / 2 / 2022 12 : 37 PM 82 Get-DiskInfo . ps1 -a --- 12 / 30 / 2021 12 : 33 PM 246 test . ps1 Each time the scheduled job runs, Windows PowerShell creates a new job object to represent the results of the most recent job that ran. You can use Remove-Job to remove a job and delete its results file from disk, as the following example depicts: Get-Job -id 6 | Remove-Job","title":"Scheduled Jobs"},{"location":"Advanced/job-sched/#scheduled-tasks","text":"Scheduled tasks are part of the Windows core infrastructure components. Other Windows components and products that run on Windows extensively use scheduled tasks. They're generally simpler than scheduled jobs. The Task Scheduler enables you to configure a schedule for running almost any program or process, in any security context, triggered by various system events or a particular date or time. However, scheduled tasks can't capture and manipulate task output. A scheduled task can run almost anything runnable on a Windows device, so it's impossible to anticipate and capture the scheduled task\u2019s output. However, because a Windows PowerShell scheduled job is always a Windows PowerShell script, even if that script runs a non-Windows PowerShell program, the system is able to capture output. In this case, a Windows PowerShell object is returned at the end of the script block. A scheduled task consists of: The Action, which specifies the program to be run. The Principal, which identifies the context to use to run an action. The Trigger, which defines the time or system event that determines when the program is to be run. The Additional settings, which further configure the task and control how the action is run. Commands that work with scheduled tasks are in the ScheduledTasks module that's included with Windows 10 and Windows Server 2019. To review the complete list of commands, run the following command: Get-Command \u2013 Module ScheduledTasks As an example, check on the available scheduled tasks by running the Get-ScheduledTask command. This will list all available scheduled tasks, regardless of whether they're enabled or disabled. Get information on a specific task by running Get-ScheduledTask with the -TaskPath parameter. For best practices, ensure that you put the actual path in quotes. Get further information about a particular task by using the Get-ScheduledTaskInfo command. You can then combine these commands using a pipeline to get additional information. For example, retrieve detailed information about the Automatic Update task running on your system by entering the following command: Get-ScheduledTask -TaskPath \"\\Microsoft\\Windows\\WindowsUpdate\\\" | Get-ScheduledTaskInfo You also can create and run scheduled tasks from the Task Scheduler. However, what if you're running Windows PowerShell commands or scripts, or Windows tools that don't write their output to a file? If output is important to you, a better choice is using a Windows PowerShell scheduled job. After that job is in the Task Scheduler, you can manipulate it further. You can start or stop it in the Task Scheduler. If you want to create multiple scheduled jobs or tasks locally, or even on remote computers, automate their creation and maintenance with the scheduled job or the scheduled task commands. Adding Windows PowerShell scripts as scheduled jobs in the Task Scheduler can greatly improve your productivity. PowerShell Gallery contains thousands of scripts that you can use or modify for your specific use, and these scripts are separated into various categories. For example, there are hundreds of viable scripts that you can run against Active Directory Domain Services (AD DS) and other Active Directory services. Some of these scripts can be very useful. An example is the script that finds user accounts that haven't been used for more than 90 days and then disables them, which can help strengthen domain security. You can modify this script to your specific domain, and then create it as a scheduled job. After you configure this task, you can then find and manipulate the job in the Task Scheduler. Schedule it to run every week and provide a report about what accounts, if any, were disabled.","title":"Scheduled tasks"},{"location":"Advanced/job-sched/#define-scheduled-jobs","text":"Scheduled jobs are a useful combination of Windows PowerShell background jobs and Windows Task Scheduler tasks. Similar to the latter, scheduled jobs are saved to disk. You can review and manage Windows PowerShell scheduled jobs in the Task Scheduler, enabling and disabling tasks or simply running the scheduled job. You can even use the scheduled job: As a template for creating other scheduled jobs. To establish a one-time schedule or periodic schedule for starting jobs. To set conditions under which jobs start again. You can do all of these tasks from the Task Scheduler. Windows PowerShell saves the results of scheduled jobs to disk and creates a running log of job output. Scheduled jobs have a customized set of commands that you can use to manage them. You can use these commands to create, edit, manage, disable, and re-enable scheduled jobs, job triggers, and job options. To create a scheduled job, use the scheduled job commands. Note that anything created in Task Scheduler is considered a scheduled task even if it's in the Microsoft\\Windows\\PowerShell\\ScheduledJobs path in the Task Scheduler. After you create a scheduled job, review and manage it in the Task Scheduler by selecting a scheduled job to: Find the job triggers on the Triggers tab. Find the scheduled job options on the General and Conditions tabs. Review the job instances that have already been run on the History tab. When you change a scheduled job setting in Task Scheduler, the change applies for all future instances of that scheduled job. The commands that work with scheduled jobs in the PSScheduledJob module are included in the current versions of the Windows Server and Client operating systems. To review the complete list of commands, run the following command: Get-Command \u2013 Module PSScheduledJob Scheduled jobs consist of three components: The job itself defines the command that will run. Job options define options and running criteria. Job triggers define when the job will run. You typically create a job option object and a job trigger object, and store those objects in variables. You then use those variables when creating the actual scheduled job. The ScheduledTasks module includes commands that can manage all tasks in the Windows Task Scheduler.","title":"Define Scheduled Jobs"},{"location":"Advanced/job-sched/#job-options","text":"Use New-ScheduledJobOption to create a new job option object. This command has several parameters that let you define options for the job, such as: \u2013HideInTaskScheduler, which prevents the job from displaying in the Task Scheduler. If you don't include this option, the final job will display in the Task Scheduler graphical user interface (GUI). \u2013RunElevated, which configures the job to run under elevated permissions. \u2013WakeToRun, which wakes the computer when the job is scheduled to run. Use other parameters to configure jobs that run when the computer is idle and other options. Many parameters correspond to options in the Task Scheduler GUI. Create a new option object and store it in a variable by using the following command: $opt = New-ScheduledJobOption \u2013 RequireNetwork \u2013 RunElevated -WakeToRun You don't need to create an option object if you don't want to specify any of its configuration items.","title":"Job options"},{"location":"Advanced/job-sched/#job-triggers","text":"A job trigger defines when a job will run. Each job can have multiple triggers. You create a trigger object by using the New-JobTrigger command. There are five basic types of triggers: \u2013Once specifies a job that runs one time only. You can also specify a \u2013RandomDelay, and you must specify the \u2013At parameter to define when the job will run. That parameter accepts a System.DateTime object or a string that can be interpreted as a date. \u2013Weekly specifies a job that runs weekly. You can specify a \u2013RandomDelay, and you must specify both the \u2013At and \u2013DaysOfWeek parameters. \u2013At accepts a date and time to define when the job will run. \u2013DaysOfWeek accepts one or more days of the week to run the job. You'll typically use \u2013At to specify a time and use \u2013DaysOfWeek to define the days the job should run. \u2013Daily specifies a job that runs every day. You must specify \u2013At and provide a time when the job will run. You can also specify a \u2013RandomDelay. \u2013AtLogOn specifies a job that runs when the user logs on. This kind of job is similar to a logon script, except that it's defined locally rather than in the domain. You can specify \u2013User to limit the user accounts that trigger the job, and \u2013RandomDelay to add a random delay. \u2013AtStartUp is similar to \u2013AtLogOn, except that it runs the job when the computer starts. That typically runs the job before a user signs in. For example, the following command creates a trigger that runs on Mondays and Thursdays every week, at 3:00 PM local time: $trigger = New-JobTrigger -Weekly -DaysOfWeek Monday , Thursday -At '3:00PM'","title":"Job triggers"},{"location":"Advanced/job-sched/#create-and-register-a-scheduled-job","text":"Use Register-ScheduledJob to create and register a new scheduled job. Specify any of the following parameters: \u2013Name is required and specifies a display name for the job. \u2013ScriptBlock is required and specifies the command or commands that the job runs. You also could specify + \u2013FilePath and provide the path and name of a Windows PowerShell script file that the job will run. \u2013Credential is optional and specifies the user account that will be used to run the job. \u2013InitializationScript accepts an optional script block. The command or commands in that script block will run before the job starts. \u2013MaxResultCount is optional and specifies the maximum number of result sets to store on disk. After this number is reached, the shell deletes older results to make room for new ones. The default value for the + -MaxResultCount parameter is 32. \u2013ScheduledJobOption accepts a job option object. \u2013Trigger accepts a job trigger object. To register a new job by using an option object in $opt and a trigger object in $trigger, use the following example: $opt = New-ScheduledJobOption -WakeToRun $trigger = New-ScheduledTaskTrigger -Once -At ( Get-Date ). AddMinutes ( 5 ) Register-ScheduledJob -Trigger $trigger -ScheduledJobOption $opt -ScriptBlock { Dir C :\\ } -MaxResultCount 5 -Name \"LocalDir\" Id Name JobTriggers Command Enabled -- ---- ----------- ------- ------- 1 LocalDir 1 Dir C :\\ True Windows PowerShell registers the resulting job in the Windows Task Scheduler and creates the job definition on disk. Job definitions are XML files stored in your profile folder in \\AppData\\Local\\Microsoft\\Windows\\PowerShell\\ScheduledJobs. You can run Get-ScheduledJob to review a list of scheduled jobs on the local computer. If you know a scheduled job\u2019s name, you can use Get-JobTrigger and the \u2013Name parameter to retrieve a list of that job\u2019s triggers.","title":"Create and Register a Scheduled Job"},{"location":"Advanced/job-sched/#retrieve-the-results","text":"Because scheduled jobs can run when Windows PowerShell isn't running, results are stored on disk in XML files. If you create a job by using the \u2013MaxResultCount parameter, the shell automatically deletes old XML files to make room for new ones. This deletion ensures that no more XML files exist than were specified in the \u2013MaxResultCount parameter. After a scheduled job finishes, running Get-Job in Windows PowerShell displays the scheduled job's results as a job object. Here's an example: Get-Job Id Name PSJobTypeName State HasMoreData Location Command -- ---- ------------- ----- ----------- -------- ------- 6 LocalDir PSScheduledJob Completed True localhost Dir C :\\ You can use Receive-Job to get a scheduled job's results. If you don't specify \u2013Keep, you can receive a job's results only once per Windows PowerShell session. However, because the results are stored on disk, you can open a new Windows PowerShell session and receive the results again. For example: Receive-Job -id 6 -Keep Directory : C :\\ Mode LastWriteTime Length Name ---- ------------- ------ ---- d ---- 7 / 26 / 2021 12 : 33 AM PerfLogs d-r -- 11 / 28 / 2021 1 : 54 PM Program Files d-r -- 12 / 28 / 2021 2 : 22 PM Program Files ( x86 ) d ---- 11 / 16 / 2021 9 : 33 AM reports d ---- 9 / 18 / 2021 7 : 28 AM Review d ---- 1 / 5 / 2022 7 : 49 AM scr d ---- 1 / 5 / 2022 7 : 50 AM scrx d-r -- 9 / 15 / 2021 8 : 16 AM Users d ---- 12 / 19 / 2021 3 : 24 AM Windows -a --- 1 / 1 / 2022 9 : 39 AM 2892628 EventReport . html -a --- 1 / 2 / 2022 12 : 37 PM 82 Get-DiskInfo . ps1 -a --- 12 / 30 / 2021 12 : 33 PM 246 test . ps1 Each time the scheduled job runs, Windows PowerShell creates a new job object to represent the results of the most recent job that ran. You can use Remove-Job to remove a job and delete its results file from disk, as the following example depicts: Get-Job -id 6 | Remove-Job","title":"Retrieve The Results"},{"location":"Advanced/local/","text":"You most likely use the Windows 10 GUI interface to change configuration settings and perform management tasks on Windows 10 workstations. However, you might be able to perform some tasks quicker by opening a PowerShell console and running a cmdlet. The Microsoft.PowerShell.Management module includes many built-in cmdlets that can be used to obtain information and perform specific operations on a local computer. To review the cmdlets included in this module, you can enter the following: Get-command -module Microsoft . PowerShell . Management Cmdlet Description Get-ComputerInfo Retrieves all system and operating system properties from the computer Get-Service Retrieves a list of all services on the computer Get-EventLog Retrieves events and event logs from local and remote computers (only available in Windows PowerShell 5.1) Get-Process Retrieves a list of all active processes on a local or remote computer Stop-Service Stops one or more running services Stop-Process Stops one or more running processes Stop-Computer Shuts down local and remote computers Clear-EventLog Deletes all of the entries from the specified event logs on the local computer or on remote computers Clear-RecycleBin Deletes the content of a computer's recycle bin Restart-Computer Restarts the operating system on local and remote computers Restart-Service Stops and then starts one or more services Running management cmdlets The following cmdlets are examples of how to use some of the management cmdlets in Windows 10: To retrieve detailed information about the local computer, run the following command: Get-ComputerInfo To retrieve the latest five error entries from the Application log, run the following command: Get-EventLog -LogName Application -Newest 5 -EntryType Error To clear the Application log on the local computer, run the following command: Clear-EventLog -LogName Application For more information on the cmdlets available in the Microsoft.PowerShell.Management module, refer to Microsoft.PowerShell.Management Manage Permissions The Microsoft.PowerShell.Security module includes many built-in cmdlets that you can use to manage the basic security features on a Windows computer. To review the cmdlets included in this module, you can enter the following command: Get-command -module Microsoft . PowerShell . Security To manage access permissions on a file or folder, you use the following cmdlets included in the Microsoft.PowerShell.Security module. Cmdlet Description Get-Acl This cmdlet gets objects that represent the security descriptor of a file or resource. The security descriptor includes the access control lists (ACLs) of the resource. The ACL lists permissions that users and groups have to access the resource. Set-Acl This cmdlet changes the security descriptor of a specified item, such as a file, folder, or a registry key, to match the values in a security descriptor that you supply. Retrieving access permissions The Get-Acl cmdlet displays the security descriptor for an object. For example, you can retrieve the security descriptor for a folder named C:\\Folder1. By default, the output displays in a table format. If you pipe the output to a list format, you can review all the information included in the security descriptor. Get-Acl -Path C :\\ Folder1 | Format-List By using the following command, you can retrieve a more verbose list of the access property with the file system rights, access control type, and inheritance settings for the specified object: ( Get-Acl -Path C :\\ Folder1 ). Access You can also retrieve only specific Access properties formatted in a table format, as the following example depicts: ( Get-Acl -Path C :\\ Folder1 ). Access | Format-Table IdentityReference , FileSystemRights , AccessControlType , IsInherited Updating File and Folder Access Permissions The Set-Acl cmdlet is used to apply changes to the ACL on a specific object. The process for modifying file or folder permissions consists of the following steps: Use Get-Acl to retrieve the existing ACL rules for the object. Create a new FileSystemAccessRule to be applied to the object. Add the new rule to the existing ACL permission set. Use Set-Acl to apply the new ACL to the existing file or folder. The following example assigns the Modify permission to C:\\Folder1 for a local user named User1. The first step is to declare a variable that includes the existing ACL rules for Folder1. The second step is to create a new FileSystemAccessRule variable which specifies the access specifications to be applied. The third step is to add the new access rule to the existing ACL rules for Folder1: Finally, you need to apply the new ACL to Folder1: $ACL = Get-Acl -Path C :\\ Folder1 $AccessRule = New-Object System . Security . AccessControl . FileSystemAccessRule ( \"User1\" , \"Modify\" , \"Allow\" ) $ACL . SetAccessRule ( $AccessRule ) $ACL | Set-Acl -Path C :\\ Folder1 You can also configure an access rule to remove Folder1 permissions for User1 by simply changing step 3 to \\(ACL.RemoveAccessRule(\\) AccessRule). Copying a Security Descriptor To a New Object If you want to copy the exact security descriptor to a new object, you can use a combination of the Get-Acl and Set-Acl commands as follows: Get-Acl -Path C :\\ Folder1 | Set-ACL -Path C :\\ Folder2 These commands copy the values from the security descriptor of C:\\Folder1 to the security descriptor of Folder2. When the commands complete, the security descriptors for both folders are identical.","title":"Manage Local"},{"location":"Advanced/local/#running-management-cmdlets","text":"The following cmdlets are examples of how to use some of the management cmdlets in Windows 10: To retrieve detailed information about the local computer, run the following command: Get-ComputerInfo To retrieve the latest five error entries from the Application log, run the following command: Get-EventLog -LogName Application -Newest 5 -EntryType Error To clear the Application log on the local computer, run the following command: Clear-EventLog -LogName Application For more information on the cmdlets available in the Microsoft.PowerShell.Management module, refer to Microsoft.PowerShell.Management","title":"Running management cmdlets"},{"location":"Advanced/local/#manage-permissions","text":"The Microsoft.PowerShell.Security module includes many built-in cmdlets that you can use to manage the basic security features on a Windows computer. To review the cmdlets included in this module, you can enter the following command: Get-command -module Microsoft . PowerShell . Security To manage access permissions on a file or folder, you use the following cmdlets included in the Microsoft.PowerShell.Security module. Cmdlet Description Get-Acl This cmdlet gets objects that represent the security descriptor of a file or resource. The security descriptor includes the access control lists (ACLs) of the resource. The ACL lists permissions that users and groups have to access the resource. Set-Acl This cmdlet changes the security descriptor of a specified item, such as a file, folder, or a registry key, to match the values in a security descriptor that you supply.","title":"Manage Permissions"},{"location":"Advanced/local/#retrieving-access-permissions","text":"The Get-Acl cmdlet displays the security descriptor for an object. For example, you can retrieve the security descriptor for a folder named C:\\Folder1. By default, the output displays in a table format. If you pipe the output to a list format, you can review all the information included in the security descriptor. Get-Acl -Path C :\\ Folder1 | Format-List By using the following command, you can retrieve a more verbose list of the access property with the file system rights, access control type, and inheritance settings for the specified object: ( Get-Acl -Path C :\\ Folder1 ). Access You can also retrieve only specific Access properties formatted in a table format, as the following example depicts: ( Get-Acl -Path C :\\ Folder1 ). Access | Format-Table IdentityReference , FileSystemRights , AccessControlType , IsInherited","title":"Retrieving access permissions"},{"location":"Advanced/local/#updating-file-and-folder-access-permissions","text":"The Set-Acl cmdlet is used to apply changes to the ACL on a specific object. The process for modifying file or folder permissions consists of the following steps: Use Get-Acl to retrieve the existing ACL rules for the object. Create a new FileSystemAccessRule to be applied to the object. Add the new rule to the existing ACL permission set. Use Set-Acl to apply the new ACL to the existing file or folder. The following example assigns the Modify permission to C:\\Folder1 for a local user named User1. The first step is to declare a variable that includes the existing ACL rules for Folder1. The second step is to create a new FileSystemAccessRule variable which specifies the access specifications to be applied. The third step is to add the new access rule to the existing ACL rules for Folder1: Finally, you need to apply the new ACL to Folder1: $ACL = Get-Acl -Path C :\\ Folder1 $AccessRule = New-Object System . Security . AccessControl . FileSystemAccessRule ( \"User1\" , \"Modify\" , \"Allow\" ) $ACL . SetAccessRule ( $AccessRule ) $ACL | Set-Acl -Path C :\\ Folder1 You can also configure an access rule to remove Folder1 permissions for User1 by simply changing step 3 to \\(ACL.RemoveAccessRule(\\) AccessRule).","title":"Updating File and Folder Access Permissions"},{"location":"Advanced/local/#copying-a-security-descriptor-to-a-new-object","text":"If you want to copy the exact security descriptor to a new object, you can use a combination of the Get-Acl and Set-Acl commands as follows: Get-Acl -Path C :\\ Folder1 | Set-ACL -Path C :\\ Folder2 These commands copy the values from the security descriptor of C:\\Folder1 to the security descriptor of Folder2. When the commands complete, the security descriptors for both folders are identical.","title":"Copying a Security Descriptor To a New Object"},{"location":"Advanced/modules/","text":"Modules are groups of related PowerShell capabilities that are bundled together into a single unit. For the purposes of this class, you can think of them as containers hosting multiple cmdlets. Modules help with organizing cmdlets into distributable units. Microsoft and other software companies provide modules as part of the management tools for their applications and services. To use a module's cmdlets, the module must be loaded into the current PowerShell session. This typically takes place automatically but, depending on your configuration, might require that you load modules explicitly by running the Import-Module cmdlet. Autoloading In Windows PowerShell version 3.0 and newer, modules load automatically if you run a cmdlet that is part of that module. This works if the module that contains the cmdlet is in a folder under the module load paths. By default, these folders include %systemdir%\\WindowsPowerShell\\v1.0\\Modules and %userprofiles%\\Documents\\WindowsPowerShell\\Modules. The list of folders is stored in the $env:PSModulePath environment variable. When you explicitly import a module by name, PowerShell checks the locations referenced by that environment variable. For PowerShell 7, the PSModulePath includes the following locations: C:\\Users\\ \\Documents\\PowerShell\\Modules C:\\Program Files\\PowerShell\\Modules C:\\Program Files\\PowerShell\\7\\Modules C:\\Program Files\\WindowsPowerShell\\Modules C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\Modules When using Windows PowerShell, the path %systemdir%\\WindowsPowerShell\\v1.0\\Modules is commonly referred to by using the combination of the $PSHome environment variable (which points to %systemdir%\\WindowsPowerShell\\v1.0) and the Modules path (that is, by using the $PSHome\\Modules notation). For PowerShell 7.0, the $PSHome environment variable refers to C:\\Program Files\\PowerShell\\7 Using Modules To Discover Cmdlets When you use the Get-Module command, it displays a partial list of cmdlets that the module you reference contains. However, you can use the module in another way to find its cmdlets. For example, if you've discovered the module NetAdapter, you would expect that it should contain cmdlets you can use to manage network adapters. You can find all applicable commands in that module by running the Get-Command \u2013Module NetAdapter command. The \u2013Module parameter restricts the results to just those commands in the designated module. PowerShell Gallery The PowerShell Gallery is a central repository for Windows PowerShell\u2013related content, including scripts and modules. The PowerShell Gallery uses the Windows PowerShell module, PowerShellGet. This module is part of Windows PowerShell 5.0 and newer. PowerShellGet contains cmdlets for finding and installing modules, scripts, and commands from the online gallery. For example, the Find-Command cmdlet searches for commands, functions, and aliases. It works similar to the Get-Command cmdlet, including support for wildcards. You can pass the results of the Find-Command cmdlet to the Install-Module cmdlet, which the PowerShellGet module also contains. Install-Module will install the module that contains the cmdlet that you discovered. The following table lists the two cmdlets used most often to find content in the PowerShell Gallery. Table 1: Cmdlets used to find content in the PowerShell Gallery Cmdlet Description Find-Module Use this cmdlet to search for Windows PowerShell modules in the PowerShell Gallery. The simplest usage conducts searches based on the module name, but you can also search based on the command name, version, DscResource, and RoleCapability. Find-Script Use this cmdlet to search for Windows PowerShell scripts in the PowerShell Gallery. The simplest usage conducts searches based on the script name, but you can also search based on the version. Create Modules You can create modules to store functions and share those functions among scripts. After you put your functions into modules, they're discoverable just as cmdlets are. Also, like the modules included with Windows, the modules you create load automatically when a function is required. As a best practice, you should name your functions in modules with a naming structure similar to the cmdlet naming convention. For example, you would use the verb-noun format. Functions in modules can include comment-based help that's discoverable by using Get-Help. To support this, you need to include the help information in each function. In many cases, you already have your functions in a Windows PowerShell script file. To convert a script file containing only functions to a module, rename it with the .psm1 file extension. No structural changes in the file are required. Windows PowerShell uses the $PSModulePath environmental variable to define the paths from which modules are loaded. In Windows PowerShell 5.0, the following paths are listed: C:\\Users\\UserID\\Documents\\WindowsPowerShell\\Modules C:\\Program Files\\WindowsPowerShell\\Modules C:\\Windows\\System32\\WindowsPowerShell\\1.0\\Modules Windows PowerShell 7 includes the following other paths: C:\\Program Files\\PowerShell\\Modules C:\\Program Files\\PowerShell\\7\\Modules If you store modules in C:\\Users\\UserID\\Document\\WindowsPowerShell\\Modules, they're only available to a single user. Modules aren't placed directly in the Modules directory. Instead, you must create a subfolder with the same name as the file and place the file in that folder. For example, if you have a module named AdatumFunctions.psm1, you'd place it in C:\\Program Files\\WindowsPowerShell\\Modules\\AdatumFunctions. Dot Sourcing Dot sourcing is a method for importing another script into the current scope. If you have a script file that contains functions, you can use dot sourcing to load the functions into memory at a Windows PowerShell prompt. Normally, when you run the script file with functions, the functions are removed from memory when the script completes. When you use dot sourcing, the functions remain in memory, and you can use them at the Windows PowerShell prompt. You can also use dot sourcing within a script to import content from another script. Dot sourcing can load from a local file or over the network by using a Universal Naming Convention (UNC) path. The syntax for using dot sourcing is: . C :\\ scripts \\ functions . ps1 At one time, dot sourcing was the only method available to maintain a centralized repository of functions that could be reused across multiple scripts. However, modules are a more standardized and preferred method for maintaining functions used across scripts.","title":"Modules"},{"location":"Advanced/modules/#autoloading","text":"In Windows PowerShell version 3.0 and newer, modules load automatically if you run a cmdlet that is part of that module. This works if the module that contains the cmdlet is in a folder under the module load paths. By default, these folders include %systemdir%\\WindowsPowerShell\\v1.0\\Modules and %userprofiles%\\Documents\\WindowsPowerShell\\Modules. The list of folders is stored in the $env:PSModulePath environment variable. When you explicitly import a module by name, PowerShell checks the locations referenced by that environment variable. For PowerShell 7, the PSModulePath includes the following locations: C:\\Users\\ \\Documents\\PowerShell\\Modules C:\\Program Files\\PowerShell\\Modules C:\\Program Files\\PowerShell\\7\\Modules C:\\Program Files\\WindowsPowerShell\\Modules C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\Modules When using Windows PowerShell, the path %systemdir%\\WindowsPowerShell\\v1.0\\Modules is commonly referred to by using the combination of the $PSHome environment variable (which points to %systemdir%\\WindowsPowerShell\\v1.0) and the Modules path (that is, by using the $PSHome\\Modules notation). For PowerShell 7.0, the $PSHome environment variable refers to C:\\Program Files\\PowerShell\\7","title":"Autoloading"},{"location":"Advanced/modules/#using-modules-to-discover-cmdlets","text":"When you use the Get-Module command, it displays a partial list of cmdlets that the module you reference contains. However, you can use the module in another way to find its cmdlets. For example, if you've discovered the module NetAdapter, you would expect that it should contain cmdlets you can use to manage network adapters. You can find all applicable commands in that module by running the Get-Command \u2013Module NetAdapter command. The \u2013Module parameter restricts the results to just those commands in the designated module.","title":"Using Modules To Discover Cmdlets"},{"location":"Advanced/modules/#powershell-gallery","text":"The PowerShell Gallery is a central repository for Windows PowerShell\u2013related content, including scripts and modules. The PowerShell Gallery uses the Windows PowerShell module, PowerShellGet. This module is part of Windows PowerShell 5.0 and newer. PowerShellGet contains cmdlets for finding and installing modules, scripts, and commands from the online gallery. For example, the Find-Command cmdlet searches for commands, functions, and aliases. It works similar to the Get-Command cmdlet, including support for wildcards. You can pass the results of the Find-Command cmdlet to the Install-Module cmdlet, which the PowerShellGet module also contains. Install-Module will install the module that contains the cmdlet that you discovered. The following table lists the two cmdlets used most often to find content in the PowerShell Gallery. Table 1: Cmdlets used to find content in the PowerShell Gallery Cmdlet Description Find-Module Use this cmdlet to search for Windows PowerShell modules in the PowerShell Gallery. The simplest usage conducts searches based on the module name, but you can also search based on the command name, version, DscResource, and RoleCapability. Find-Script Use this cmdlet to search for Windows PowerShell scripts in the PowerShell Gallery. The simplest usage conducts searches based on the script name, but you can also search based on the version.","title":"PowerShell Gallery"},{"location":"Advanced/modules/#create-modules","text":"You can create modules to store functions and share those functions among scripts. After you put your functions into modules, they're discoverable just as cmdlets are. Also, like the modules included with Windows, the modules you create load automatically when a function is required. As a best practice, you should name your functions in modules with a naming structure similar to the cmdlet naming convention. For example, you would use the verb-noun format. Functions in modules can include comment-based help that's discoverable by using Get-Help. To support this, you need to include the help information in each function. In many cases, you already have your functions in a Windows PowerShell script file. To convert a script file containing only functions to a module, rename it with the .psm1 file extension. No structural changes in the file are required. Windows PowerShell uses the $PSModulePath environmental variable to define the paths from which modules are loaded. In Windows PowerShell 5.0, the following paths are listed: C:\\Users\\UserID\\Documents\\WindowsPowerShell\\Modules C:\\Program Files\\WindowsPowerShell\\Modules C:\\Windows\\System32\\WindowsPowerShell\\1.0\\Modules Windows PowerShell 7 includes the following other paths: C:\\Program Files\\PowerShell\\Modules C:\\Program Files\\PowerShell\\7\\Modules If you store modules in C:\\Users\\UserID\\Document\\WindowsPowerShell\\Modules, they're only available to a single user. Modules aren't placed directly in the Modules directory. Instead, you must create a subfolder with the same name as the file and place the file in that folder. For example, if you have a module named AdatumFunctions.psm1, you'd place it in C:\\Program Files\\WindowsPowerShell\\Modules\\AdatumFunctions.","title":"Create Modules"},{"location":"Advanced/modules/#dot-sourcing","text":"Dot sourcing is a method for importing another script into the current scope. If you have a script file that contains functions, you can use dot sourcing to load the functions into memory at a Windows PowerShell prompt. Normally, when you run the script file with functions, the functions are removed from memory when the script completes. When you use dot sourcing, the functions remain in memory, and you can use them at the Windows PowerShell prompt. You can also use dot sourcing within a script to import content from another script. Dot sourcing can load from a local file or over the network by using a Universal Naming Convention (UNC) path. The syntax for using dot sourcing is: . C :\\ scripts \\ functions . ps1 At one time, dot sourcing was the only method available to maintain a centralized repository of functions that could be reused across multiple scripts. However, modules are a more standardized and preferred method for maintaining functions used across scripts.","title":"Dot Sourcing"},{"location":"Advanced/rem_adv/","text":"Windows PowerShell provides access protection to variables, aliases, functions, and Windows PowerShell drives by limiting where they can be changed and read. By enforcing a few simple rules using Windows PowerShell scopes, you ensure that you don't inadvertently change an item that shouldn't be changed. The basic rules of scopes are: Unless you explicitly make it private, items you include in a scope are visible in the scope in which it was created and in any child scope. You can use variables, aliases, functions, or Windows PowerShell drives in one or more scopes. Items you create within a scope can be changed only in the scope in which the item was created unless you explicitly stipulate a different scope. If you create an item in a scope and the item has the same name as an item in a different scope, the original item might get hidden under the new item. However, it doesn't get overridden or changed. You can use local variables in remote commands, but you must indicate that the variable is defined in the local session. Windows PowerShell assumes that the variables used in remote commands are defined in the session in which the command runs. The $Using: scope modifier As mentioned earlier, starting with Windows PowerShell 3.0, you can implement the $Using: scope modifier to identify a local variable in a remote command. This is a special scope modifier and is the most straightforward way to reference a local variable in a remote command. This technique passes on the variable value(s) to the remote computer, and therefore involves less processing across the hosts being used. By default, variables in remote commands are assumed to be defined in the remote session. The syntax of Using is $Using:. In the following example, the $ps variable is created in the local session but is used in the session in which the command runs. The $Using: scope modifier identifies $ps as a local variable: $ps = \"Windows PowerShell\" Invoke-Command -ComputerName LON-DC1 -ScriptBlock { Get-WinEvent -LogName $Using : ps } You can also apply the $Using: scope modifier in PSSessions such as in the following example: $s = New-PSSession -ComputerName LON-DC1 $ps = \"Windows PowerShell\" Invoke-Command -Sessions $s -ScriptBlock { Get-WinEvent -LogName $Using : ps } Enable Multi-hop Remoting Another challenge with remoting is related to delegating credentials across multiple remote connections. By default, credentials can be delegated across only one connection, or hop. This restrictions delegation prevents the remote computer from further delegating your credentials, since this could introduce an extra security risk. In general, this is the scenario we want to address: You're signed in to ServerA. From ServerA, you start a remote PowerShell session to connect to ServerB. A command you run on ServerB via your PowerShell Remoting session attempts to access a resource on ServerC. Access to the resource on ServerC is denied because the credentials you used to create the PowerShell Remoting session are not passed from ServerB to ServerC. The need to perform multiple hop (or, multi-hop) delegation can often occur in production environments. For example, in some organizations administrators aren't permitted to connect directly from their client computers to a server in the datacenter. Instead, they must connect to an intermediate gateway or jump server, and then from there connect to the server they intend to manage. In its default configuration, remoting doesn't permit this approach. After you're connected to a remote computer, your credential can go no further than the remote computer. Trying to access any resource that isn't located on that computer typically results in a failure because your access isn't accompanied by a credential. The solution is to enable Credential Security Support Provider (CredSSP). Enabling CredSSP CredSSP caches credentials on the remote server (ServerB, from the previous example). Because of this, you should be aware that using CredSSP opens you up to potential credential theft attacks. If the remote computer is compromised, the attacker has access to the user's credentials. CredSSP is disabled by default on both client and server computers. You should enable CredSSP only in the most trusted environments. For example, a domain administrator connecting to a domain controller could have CredSSP enabled because the domain controller is highly trusted. You must enable the CredSSP protocol both on the initiating computer, referred to as the client, and on the receiving computer, referred to as the server. Doing this enables the receiving computer to delegate your credential one additional hop. To configure the client, run the following command, substituting servername with the name of the server that will be able to redelegate your credential: Enable-WsManCredSSP \u2013 Role Client \u2013 Delegate servername The server name can contain wildcard characters. However, using the asterisk ( ) wildcard by itself is too permissive because you would be enabling any computer to redelegate your credential, even an unauthorized user. Instead, consider a limited wildcard pattern, such as .ADATUM.com, which would limit redelegation to computers in that domain. To configure the server, run Enable-WsManCredSSP \u2013Role Server. No delegated computer list is required on the server. You also can configure these settings through Group Policy, which offers a more centralized and consistent configuration across an enterprise. There have been numerous security breaches documented while using CredSSP, and therefore it's no longer a preferred option. You should instead use constrained delegation. Resource-based, Kerberos-constrained delegation Starting with Windows Server 2012, you can forgo using CredSSP and instead use constrained delegation. Constrained delegation implements delegation of service tickets by using security descriptors rather than an allow list of server names. This allows the resource to determine which security principals can request tickets on behalf of another user. Resource-based constrained delegation works correctly regardless of domain functional level. Constrained delegation requires: Access to a domain controller in the same domain as the host computer from which the Windows PowerShell remoting commands are being run. Access to a domain controller in the domain hosting the remote server you're trying to access from the intermediate remote server. The code for setting up the permissions requires a computer running Windows Server with the Active Directory PowerShell Remote Server Administration Tools (RSAT). You can add RSAT as a Windows feature by running the following two commands: Add-WindowsFeature RSAT-AD-PowerShell Import-Module ActiveDirectory To grant resource-based, Kerberos-constrained delegation from LON-SVR1 through LON-SVR2 to LON-SVR3, run the following command: Set-ADComputer -Identity LON-SVR2 -PrincipalsAllowedToDelegateToAccount LON-SVR3 One issue could cause this command to fail. The Key Distribution Center (KDC) has a 15-minute SPN negative cache. If LON-SVR2 has already tried to communicate with LON-SVR3, then there's a negative cache entry. You'll need to clear the cache on LON-SVR2 by using one of the following techniques: Run the command klist purge -li 0x3e7. This is the preferred and fastest method. Wait 15 minutes for the cache to clear automatically. Restart LON-SVR2. To test constrained delegation, run the following code example: $cred = Get-Credential Adatum \\ TestUser Invoke-Command -ComputerName LON-SVR1 . Name -Credential $cred -ScriptBlock { Test-Path \\\\$( $using : ServerC . Name )\\ C $ ` Get-Process lsass -ComputerName $( $using : LON-SVR2 . Name ) Get-EventLog -LogName System -Newest 3 -ComputerName $using : LON-SVR3 . Name } Just Enough Administration Just Enough Administration (JEA) is a security technology that enables delegated administration for anything managed by PowerShell. With JEA, you can: Reduce the number of administrators on your machines by using virtual accounts or group-managed service accounts to perform privileged actions on behalf of regular users. Limit what users can do by specifying which cmdlets, functions, and external commands they can run. Better understand what your users are doing by reviewing transcripts and logs that depict exactly which commands a user ran during their session. Highly privileged accounts used to administer your servers pose a serious security risk. Should an attacker compromise one of these accounts, they could launch lateral attacks across your organization. Each compromised account gives an attacker access to even more accounts and resources, and puts them one step closer to stealing company secrets, launching a denial-of-service (DOS) attack, and more. It's not always easy to remove administrative privileges, either. Consider the common scenario where the DNS role is installed on the same machine as your Active Directory domain controller. Your DNS administrators require local administrator privileges to fix issues with the DNS server. But to do so, you must make them members of the highly privileged Administrators security group. This approach effectively gives DNS Administrators the ability to gain control over your entire domain and access to all the resources on that machine. JEA addresses this problem through the principle of least privilege. With JEA, you can configure a management endpoint for DNS administrators that gives them access only to the PowerShell commands they need to get their job done. This means you can provide the appropriate access to repair a poisoned DNS cache or restart the DNS server without unintentionally giving them rights to Active Directory, or to browse the file system, or run potentially dangerous scripts. Better yet, when the JEA session is configured to use temporary, privileged virtual accounts, your DNS administrators can connect to the server by using non-admin credentials and still run commands that typically require admin privileges. JEA enables you to remove users from widely privileged local or domain administrator roles and carefully control what they can do on each machine. JEA is a feature included in PowerShell 5.0 and newer. For full functionality, you should install the latest version of PowerShell available for your system. PowerShell Remoting provides the foundation on which JEA is built. It's necessary to ensure PowerShell Remoting is enabled and properly secured before you can use JEA. When creating a JEA endpoint, you need to define one or more role capabilities that describe what someone can do in a JEA session. A role capability is a PowerShell data file with the .psrc extension that lists all the cmdlets, functions, providers, and external programs that are made available to connecting users. You can create a new PowerShell role capability file with the New-PSRoleCapabilityFile cmdlet. You should then edit the resulting role capability file to allow the commands required for the role. The PowerShell help documentation contains several examples of how you can configure the file.","title":"Advanced"},{"location":"Advanced/rem_adv/#the-using-scope-modifier","text":"As mentioned earlier, starting with Windows PowerShell 3.0, you can implement the $Using: scope modifier to identify a local variable in a remote command. This is a special scope modifier and is the most straightforward way to reference a local variable in a remote command. This technique passes on the variable value(s) to the remote computer, and therefore involves less processing across the hosts being used. By default, variables in remote commands are assumed to be defined in the remote session. The syntax of Using is $Using:. In the following example, the $ps variable is created in the local session but is used in the session in which the command runs. The $Using: scope modifier identifies $ps as a local variable: $ps = \"Windows PowerShell\" Invoke-Command -ComputerName LON-DC1 -ScriptBlock { Get-WinEvent -LogName $Using : ps } You can also apply the $Using: scope modifier in PSSessions such as in the following example: $s = New-PSSession -ComputerName LON-DC1 $ps = \"Windows PowerShell\" Invoke-Command -Sessions $s -ScriptBlock { Get-WinEvent -LogName $Using : ps }","title":"The $Using: scope modifier"},{"location":"Advanced/rem_adv/#enable-multi-hop-remoting","text":"Another challenge with remoting is related to delegating credentials across multiple remote connections. By default, credentials can be delegated across only one connection, or hop. This restrictions delegation prevents the remote computer from further delegating your credentials, since this could introduce an extra security risk. In general, this is the scenario we want to address: You're signed in to ServerA. From ServerA, you start a remote PowerShell session to connect to ServerB. A command you run on ServerB via your PowerShell Remoting session attempts to access a resource on ServerC. Access to the resource on ServerC is denied because the credentials you used to create the PowerShell Remoting session are not passed from ServerB to ServerC. The need to perform multiple hop (or, multi-hop) delegation can often occur in production environments. For example, in some organizations administrators aren't permitted to connect directly from their client computers to a server in the datacenter. Instead, they must connect to an intermediate gateway or jump server, and then from there connect to the server they intend to manage. In its default configuration, remoting doesn't permit this approach. After you're connected to a remote computer, your credential can go no further than the remote computer. Trying to access any resource that isn't located on that computer typically results in a failure because your access isn't accompanied by a credential. The solution is to enable Credential Security Support Provider (CredSSP).","title":"Enable Multi-hop Remoting"},{"location":"Advanced/rem_adv/#enabling-credssp","text":"CredSSP caches credentials on the remote server (ServerB, from the previous example). Because of this, you should be aware that using CredSSP opens you up to potential credential theft attacks. If the remote computer is compromised, the attacker has access to the user's credentials. CredSSP is disabled by default on both client and server computers. You should enable CredSSP only in the most trusted environments. For example, a domain administrator connecting to a domain controller could have CredSSP enabled because the domain controller is highly trusted. You must enable the CredSSP protocol both on the initiating computer, referred to as the client, and on the receiving computer, referred to as the server. Doing this enables the receiving computer to delegate your credential one additional hop. To configure the client, run the following command, substituting servername with the name of the server that will be able to redelegate your credential: Enable-WsManCredSSP \u2013 Role Client \u2013 Delegate servername The server name can contain wildcard characters. However, using the asterisk ( ) wildcard by itself is too permissive because you would be enabling any computer to redelegate your credential, even an unauthorized user. Instead, consider a limited wildcard pattern, such as .ADATUM.com, which would limit redelegation to computers in that domain. To configure the server, run Enable-WsManCredSSP \u2013Role Server. No delegated computer list is required on the server. You also can configure these settings through Group Policy, which offers a more centralized and consistent configuration across an enterprise. There have been numerous security breaches documented while using CredSSP, and therefore it's no longer a preferred option. You should instead use constrained delegation.","title":"Enabling CredSSP"},{"location":"Advanced/rem_adv/#resource-based-kerberos-constrained-delegation","text":"Starting with Windows Server 2012, you can forgo using CredSSP and instead use constrained delegation. Constrained delegation implements delegation of service tickets by using security descriptors rather than an allow list of server names. This allows the resource to determine which security principals can request tickets on behalf of another user. Resource-based constrained delegation works correctly regardless of domain functional level. Constrained delegation requires: Access to a domain controller in the same domain as the host computer from which the Windows PowerShell remoting commands are being run. Access to a domain controller in the domain hosting the remote server you're trying to access from the intermediate remote server. The code for setting up the permissions requires a computer running Windows Server with the Active Directory PowerShell Remote Server Administration Tools (RSAT). You can add RSAT as a Windows feature by running the following two commands: Add-WindowsFeature RSAT-AD-PowerShell Import-Module ActiveDirectory To grant resource-based, Kerberos-constrained delegation from LON-SVR1 through LON-SVR2 to LON-SVR3, run the following command: Set-ADComputer -Identity LON-SVR2 -PrincipalsAllowedToDelegateToAccount LON-SVR3 One issue could cause this command to fail. The Key Distribution Center (KDC) has a 15-minute SPN negative cache. If LON-SVR2 has already tried to communicate with LON-SVR3, then there's a negative cache entry. You'll need to clear the cache on LON-SVR2 by using one of the following techniques: Run the command klist purge -li 0x3e7. This is the preferred and fastest method. Wait 15 minutes for the cache to clear automatically. Restart LON-SVR2. To test constrained delegation, run the following code example: $cred = Get-Credential Adatum \\ TestUser Invoke-Command -ComputerName LON-SVR1 . Name -Credential $cred -ScriptBlock { Test-Path \\\\$( $using : ServerC . Name )\\ C $ ` Get-Process lsass -ComputerName $( $using : LON-SVR2 . Name ) Get-EventLog -LogName System -Newest 3 -ComputerName $using : LON-SVR3 . Name }","title":"Resource-based, Kerberos-constrained delegation"},{"location":"Advanced/rem_adv/#just-enough-administration","text":"Just Enough Administration (JEA) is a security technology that enables delegated administration for anything managed by PowerShell. With JEA, you can: Reduce the number of administrators on your machines by using virtual accounts or group-managed service accounts to perform privileged actions on behalf of regular users. Limit what users can do by specifying which cmdlets, functions, and external commands they can run. Better understand what your users are doing by reviewing transcripts and logs that depict exactly which commands a user ran during their session. Highly privileged accounts used to administer your servers pose a serious security risk. Should an attacker compromise one of these accounts, they could launch lateral attacks across your organization. Each compromised account gives an attacker access to even more accounts and resources, and puts them one step closer to stealing company secrets, launching a denial-of-service (DOS) attack, and more. It's not always easy to remove administrative privileges, either. Consider the common scenario where the DNS role is installed on the same machine as your Active Directory domain controller. Your DNS administrators require local administrator privileges to fix issues with the DNS server. But to do so, you must make them members of the highly privileged Administrators security group. This approach effectively gives DNS Administrators the ability to gain control over your entire domain and access to all the resources on that machine. JEA addresses this problem through the principle of least privilege. With JEA, you can configure a management endpoint for DNS administrators that gives them access only to the PowerShell commands they need to get their job done. This means you can provide the appropriate access to repair a poisoned DNS cache or restart the DNS server without unintentionally giving them rights to Active Directory, or to browse the file system, or run potentially dangerous scripts. Better yet, when the JEA session is configured to use temporary, privileged virtual accounts, your DNS administrators can connect to the server by using non-admin credentials and still run commands that typically require admin privileges. JEA enables you to remove users from widely privileged local or domain administrator roles and carefully control what they can do on each machine. JEA is a feature included in PowerShell 5.0 and newer. For full functionality, you should install the latest version of PowerShell available for your system. PowerShell Remoting provides the foundation on which JEA is built. It's necessary to ensure PowerShell Remoting is enabled and properly secured before you can use JEA. When creating a JEA endpoint, you need to define one or more role capabilities that describe what someone can do in a JEA session. A role capability is a PowerShell data file with the .psrc extension that lists all the cmdlets, functions, providers, and external programs that are made available to connecting users. You can create a new PowerShell role capability file with the New-PSRoleCapabilityFile cmdlet. You should then edit the resulting role capability file to allow the commands required for the role. The PowerShell help documentation contains several examples of how you can configure the file.","title":"Just Enough Administration"},{"location":"Advanced/rem_mod/","text":"One-to-one Remoting One-to-one remoting resembles the SSH tool that's used on many UNIX and Linux computers in that you use a command prompt on the remote computer. While the implementation of remoting is quite different from SSH, their use cases are fairly similar. In Windows PowerShell, you enter commands on your local computer, which then transmits them to the remote computer where they run. Results are serialized into XML and transmitted back to your computer, which then deserializes them into objects and puts them into the Windows PowerShell pipeline. Unlike SSH, one-to-one remoting isn't built on the Telnet protocol. To start one-to-one Windows PowerShell remoting, run the Enter-PSSession command, combined with its \u2013ComputerName parameter. You can use other parameters to perform basic connection customization, which we'll cover in later topics. After you're connected, the Windows PowerShell prompt changes to indicate the computer to which you're connected. To exit the session and return to the local command prompt, run Exit-PSSession. If you close Windows PowerShell while connected, the connection will close on its own. One-to-many Remoting One-to-many remoting lets you send a single command to multiple computers in parallel. Each computer will run the command that you transmit, serialize the results into XML, and transmit those results back to your computer. Your computer then deserializes the XML into objects and puts them into the Windows PowerShell pipeline. When doing this, several properties are added to each object, including a PSComputerName property that indicates which computer each result came from. That property lets you sort, group, and filter based on computer name. You can use one-to-many remoting using two different techniques: Invoke-Command \u2013ComputerName name1,name2 \u2013ScriptBlock { command }. This technique sends the command (or commands) contained in the script block to the computers that you list. This technique is useful for sending one or two commands; multiple commands are separated by a semicolon. Invoke-Command \u2013ComputerName name1,name2 \u2013FilePath filepath. This technique sends the contents of a script file with a .ps1 file name extension to the computers that you list. The local computer opens the file and reads its contents. However, the remote computers don't have to have direct access to the file. This technique is useful for sending a large file of commands, such as a complete script. Within any script block (including the script block provided to the \u2013ScriptBlock parameter) you can use a semicolon to separate multiple commands. For example, { Get-Service ; Get-Process } will run Get-Service, and then run Get-Process. Throttling To help you manage the resources on your local computer, PowerShell includes a per-command throttling feature that lets you limit the number of concurrent remote connections established for each command. By default, Windows PowerShell will connect to only 32 computers at once. If you list more than 32 computers, the connections to the other computers will be queued. Once sessions to some of the computers from the first batch complete and return their results, connections to the computers in the next batch will be initiated. You can alter this behavior by using the \u2013ThrottleLimit parameter of Invoke-Command. Raising the number doesn't put an extra load on the remote computers. However, it does put an extra load on the computer where Invoke-Command was invoked. It also utilizes more bandwidth. Each concurrent connection is basically a thread of Windows PowerShell. Therefore, raising the number of computers consumes memory and processor speed on the local computer. Passing values The script block or file contents are transmitted as literal text to the remote computers that run them exactly as is. The computer doesn't parse the script block or file on which the Invoke-Command was run. Consider the following command example: $var = 'BITS' Invoke-Command \u2013 ScriptBlock { Get-Service \u2013 Name $var } \u2013 Computer LON-DC1 In this scenario, the variable $var is being set on the local computer rather than being included into the script block to be run on LON-DC1. In other words, $var is not defined or set in the PowerShell remoting session to LON-DC1, which is a common mistake that administrators new to Windows PowerShell often make. Invoke-Command cannot include variables in its script block or script file unless the remote computer can understand those variables. As such, it might seem more complicated to find a way to pass data from the initiating computer to the remote computer. However, Invoke-Command actually provides a specific mechanism for doing this task. To review, the intent behind the following command is to display a list of the 10 most recent Security event log entries on each targeted computer. However, the command will not work as written: $Log = 'Security' $Quantity = 10 Invoke-Command \u2013 Computer ONE , TWO \u2013 ScriptBlock { Get-EventLog \u2013 LogName $Log \u2013 Newest $Quantity } The problem is that the variables $Log and $Quantity have meanings only on the local computer, and those values are not inserted into the script block prior to those values being sent to the remote computers. Therefore, the remote computers don't know what they mean. The correct syntax for this command is as follows: $Log = 'Security' $Quantity = 10 Invoke-Command \u2013 Computer ONE , TWO \u2013 ScriptBlock { Param ( $x , $y ) Get-EventLog \u2013 LogName $x \u2013 Newest $y } \u2013 ArgumentList $Log , $Quantity By using this syntax, the local variables are passed to the ArgumentList parameter of Invoke-Command. Within the script block, a Param() block is created, which contains the same number of variables as the \u2013ArgumentList list of values, which, in this case, is two. Note that you can assign any names to the variables within the Param() block. They will receive data from the ArgumentList parameter based on order. In other words, because $Log was listed first on ArgumentList, its value will be passed to $x because that's the first entry in the Param() block. The variables in the Param() block can then be used inside the script block, as depicted in the example. This syntax will work for Windows PowerShell 2.0 and newer. However, Windows PowerShell 3.0 introduced a simplified alternative approach. If you have a local variable $variable, and you want to include its contents in a command that will be run on a remote computer, you can run the following syntax: Invoke-Command \u2013 ScriptBlock { Do -Something $Using : variable } \u2013 ComputerName REMOTE The $Using: prefix is properly processed by the local and remote computers, resulting in the $Using:variable being replaced with the contents of the local variable $variable. Running commands locally and remotely Pay close attention to the commands that you enclose in the script block, which will be passed to the remote computer. Remember that your local computer won't process any script block contents, but simply pass it to the remote computer. For example, consider the following command: Invoke-Command \u2013 ScriptBlock { Do -Something \u2013 Credential ( Get-Credential ) } -ComputerName LON-DC1 This command will run the Get-Credential cmdlet on the remote computer. If you try running Get-Credential on a local computer, it will use a graphical dialog box to prompt for the credential. Now consider this modified version of the command: Invoke-Command \u2013 ScriptBlock { Param ( $c ) Do -Something \u2013 Credential $c } -ComputerName LON-DC1 -ArgumentList ( Get-Credential ) This command runs Get-Credential on the local computer and runs it only once. The resulting object is passed into the $c parameter of the script block, enabling each computer to use the same credential. These examples illustrate the importance of writing remoting commands carefully. By using a combination of running commands remotely and locally, you can achieve various useful goals. Persistence Using the techniques outlined here, every time you use Invoke-Command, the remote computer creates a new wsmprovhost process, and runs the command or commands. It then returns the results, and then closes that Windows PowerShell instance. Each successive Invoke-Command, even if made to the same computer, is akin to opening a new Windows PowerShell window. Any work done by a previous session won't exist unless you save it to a disk or some other persistent storage. For example, consider the following command: Invoke-Command \u2013 ComputerName LON-DC1 \u2013 ScriptBlock { $x = 'BITS' } Invoke-Command \u2013 ComputerName LON-DC1 \u2013 ScriptBlock { Get-Service \u2013 Name $x } In this example, the Get-Service would fail, because it's dependent on the value of a variable created as part of the previous wsmprovhost process. When the first script invoked by the Invoke-Command completes, its variables are cleared from memory. To address this issue, you can create a wsmprovhost process on a remote computer so that you can successfully send successive commands to it. Windows PowerShell can create persistent connections, which are known as sessions, or more accurately, PSSessions. The PS designation signifies Windows PowerShell and differentiates these sessions from other kinds of sessions that might be present in other technologies, such as a Remote Desktop Services (RDS) session. After making a PowerShell session to a remote computer, you run the desired commands within the session, but you leave the PowerShell session running. By doing this, you can run more commands in the session. Multiple computer names The \u2013ComputerName parameter of Invoke-Command can accept any collection of string objects as computer names. The following list describes different techniques that can be used to create such collections: -ComputerName ONE,TWO,THREE. A static, comma-separated list of computer names. -ComputerName (Get-Content Names.txt). Reads names from a text file named Names.txt, assuming the file contains one computer name per line. -ComputerName (Import-Csv Computers.csv | Select \u2013ExpandProperty Computer). Reads a comma-separated value (CSV) file that's named Computers.csv and contains a column named Computer that contains computer names. -ComputerName (Get-ADComputer \u2013Filter * | Select \u2013ExpandProperty Name). Queries every computer object in AD DS, which can take a significant amount of time in a large domain. Common mistakes when using computer names Be careful where you specify a computer name. For example, review the following command: Invoke-Command \u2013 ScriptBlock { Get-Service \u2013 ComputerName ONE , TWO } This command doesn't provide a \u2013ComputerName parameter to Invoke-Command. Therefore, the command runs on the local computer. The local computer will run Get-Service targeting computers named ONE and TWO. The protocols used by Get-Service will be used instead of Windows PowerShell remoting. Compare this with the following command: Invoke-Command \u2013 ScriptBlock { Get-Service } \u2013 ComputerName ONE , TWO This command will use Windows PowerShell remoting to connect to computers named ONE and TWO. Each of these computers will run Get-Service locally, returning their results using remoting. For more interactive Windows PowerShell remoting situations, you can manage individual sessions as separate entities. To do this, you first create a session by using the New-PSSession command. The benefit of using the New-PSSession command is that the session will persist throughout multiple Invoke-Command instances, allowing you to pass variables and objects to other commands in your script. You can create persistent sessions by using the New-PSSession command and assigning it to a variable. You then can reference the variable later by using the Invoke-Command command. When finished, you can close persistent sessions by using the Remove-PSSession command. Compare Remoting Output with Local Output When you run a command such as Get-Process on your local computer, the command returns object or objects of the type System.Diagnostics.Process and adds them to the Windows PowerShell pipeline. These objects have properties, methods, and frequently, events. Methods provide the ability to perform task. For example, the Kill() method of a Process object terminates the process that this object represents. The process of converting an object into a form that can be readily transported is known as serialization. Serialization takes an object's state and transforms it into serial data format, such as XML or binary format. Deserialization converts the formatted XML or binary data into an object type. When a command runs on a remote computer, that computer serializes the results in XML, and transmits that XML text to your computer. You do this to put the object\u2019s information into a format that can be transmitted over a network. However, for complex objects the serialization process can use only static information about an object\u2014in other words, its properties. When your computer receives the XML, it's deserialized back into objects that are put in the Windows PowerShell pipeline. When you have a Process object, by piping it to Get-Member, you know it's now of the type Deserialized.System.Diagnostics.Process, a related, but different, kind of object. The deserialized object has no methods and no events. Given the serialization and deserialization which is part of PowerShell remoting, you should consider any objects that are obtained in this manner to be a static snapshot. The values of object properties are not updatable, and the objects cannot be used to perform any actions. Therefore, any tasks that require interacting with remote objects should be performed on the remote computer as part of the PowerShell remoting session. For example, here is an example of a command that will not yield the desired results: Invoke-Command \u2013 Computer LON-DC1 \u2013 ScriptBlock { Get-Process \u2013 Name Note * } | Stop-Process In this example, you're retrieving Process objects, but the task of stopping processes takes place on the local computer rather than the remote one. This will result in stopping any local processes that happen to have the names matching the remote ones. The proper way to accomplish the intended outcome would be to run: Invoke-Command \u2013 Computer LON-DC1 \u2013 ScriptBlock { Get-Process \u2013 Name Note * | Stop-Process } In this case, the processing has occurred entirely on the remote computer, with only the final results being serialized and sent back. The difference between these two commands is subtle but important to understand.","title":"Modes"},{"location":"Advanced/rem_mod/#one-to-one-remoting","text":"One-to-one remoting resembles the SSH tool that's used on many UNIX and Linux computers in that you use a command prompt on the remote computer. While the implementation of remoting is quite different from SSH, their use cases are fairly similar. In Windows PowerShell, you enter commands on your local computer, which then transmits them to the remote computer where they run. Results are serialized into XML and transmitted back to your computer, which then deserializes them into objects and puts them into the Windows PowerShell pipeline. Unlike SSH, one-to-one remoting isn't built on the Telnet protocol. To start one-to-one Windows PowerShell remoting, run the Enter-PSSession command, combined with its \u2013ComputerName parameter. You can use other parameters to perform basic connection customization, which we'll cover in later topics. After you're connected, the Windows PowerShell prompt changes to indicate the computer to which you're connected. To exit the session and return to the local command prompt, run Exit-PSSession. If you close Windows PowerShell while connected, the connection will close on its own.","title":"One-to-one Remoting"},{"location":"Advanced/rem_mod/#one-to-many-remoting","text":"One-to-many remoting lets you send a single command to multiple computers in parallel. Each computer will run the command that you transmit, serialize the results into XML, and transmit those results back to your computer. Your computer then deserializes the XML into objects and puts them into the Windows PowerShell pipeline. When doing this, several properties are added to each object, including a PSComputerName property that indicates which computer each result came from. That property lets you sort, group, and filter based on computer name. You can use one-to-many remoting using two different techniques: Invoke-Command \u2013ComputerName name1,name2 \u2013ScriptBlock { command }. This technique sends the command (or commands) contained in the script block to the computers that you list. This technique is useful for sending one or two commands; multiple commands are separated by a semicolon. Invoke-Command \u2013ComputerName name1,name2 \u2013FilePath filepath. This technique sends the contents of a script file with a .ps1 file name extension to the computers that you list. The local computer opens the file and reads its contents. However, the remote computers don't have to have direct access to the file. This technique is useful for sending a large file of commands, such as a complete script. Within any script block (including the script block provided to the \u2013ScriptBlock parameter) you can use a semicolon to separate multiple commands. For example, { Get-Service ; Get-Process } will run Get-Service, and then run Get-Process.","title":"One-to-many Remoting"},{"location":"Advanced/rem_mod/#throttling","text":"To help you manage the resources on your local computer, PowerShell includes a per-command throttling feature that lets you limit the number of concurrent remote connections established for each command. By default, Windows PowerShell will connect to only 32 computers at once. If you list more than 32 computers, the connections to the other computers will be queued. Once sessions to some of the computers from the first batch complete and return their results, connections to the computers in the next batch will be initiated. You can alter this behavior by using the \u2013ThrottleLimit parameter of Invoke-Command. Raising the number doesn't put an extra load on the remote computers. However, it does put an extra load on the computer where Invoke-Command was invoked. It also utilizes more bandwidth. Each concurrent connection is basically a thread of Windows PowerShell. Therefore, raising the number of computers consumes memory and processor speed on the local computer.","title":"Throttling"},{"location":"Advanced/rem_mod/#passing-values","text":"The script block or file contents are transmitted as literal text to the remote computers that run them exactly as is. The computer doesn't parse the script block or file on which the Invoke-Command was run. Consider the following command example: $var = 'BITS' Invoke-Command \u2013 ScriptBlock { Get-Service \u2013 Name $var } \u2013 Computer LON-DC1 In this scenario, the variable $var is being set on the local computer rather than being included into the script block to be run on LON-DC1. In other words, $var is not defined or set in the PowerShell remoting session to LON-DC1, which is a common mistake that administrators new to Windows PowerShell often make. Invoke-Command cannot include variables in its script block or script file unless the remote computer can understand those variables. As such, it might seem more complicated to find a way to pass data from the initiating computer to the remote computer. However, Invoke-Command actually provides a specific mechanism for doing this task. To review, the intent behind the following command is to display a list of the 10 most recent Security event log entries on each targeted computer. However, the command will not work as written: $Log = 'Security' $Quantity = 10 Invoke-Command \u2013 Computer ONE , TWO \u2013 ScriptBlock { Get-EventLog \u2013 LogName $Log \u2013 Newest $Quantity } The problem is that the variables $Log and $Quantity have meanings only on the local computer, and those values are not inserted into the script block prior to those values being sent to the remote computers. Therefore, the remote computers don't know what they mean. The correct syntax for this command is as follows: $Log = 'Security' $Quantity = 10 Invoke-Command \u2013 Computer ONE , TWO \u2013 ScriptBlock { Param ( $x , $y ) Get-EventLog \u2013 LogName $x \u2013 Newest $y } \u2013 ArgumentList $Log , $Quantity By using this syntax, the local variables are passed to the ArgumentList parameter of Invoke-Command. Within the script block, a Param() block is created, which contains the same number of variables as the \u2013ArgumentList list of values, which, in this case, is two. Note that you can assign any names to the variables within the Param() block. They will receive data from the ArgumentList parameter based on order. In other words, because $Log was listed first on ArgumentList, its value will be passed to $x because that's the first entry in the Param() block. The variables in the Param() block can then be used inside the script block, as depicted in the example. This syntax will work for Windows PowerShell 2.0 and newer. However, Windows PowerShell 3.0 introduced a simplified alternative approach. If you have a local variable $variable, and you want to include its contents in a command that will be run on a remote computer, you can run the following syntax: Invoke-Command \u2013 ScriptBlock { Do -Something $Using : variable } \u2013 ComputerName REMOTE The $Using: prefix is properly processed by the local and remote computers, resulting in the $Using:variable being replaced with the contents of the local variable $variable.","title":"Passing values"},{"location":"Advanced/rem_mod/#running-commands-locally-and-remotely","text":"Pay close attention to the commands that you enclose in the script block, which will be passed to the remote computer. Remember that your local computer won't process any script block contents, but simply pass it to the remote computer. For example, consider the following command: Invoke-Command \u2013 ScriptBlock { Do -Something \u2013 Credential ( Get-Credential ) } -ComputerName LON-DC1 This command will run the Get-Credential cmdlet on the remote computer. If you try running Get-Credential on a local computer, it will use a graphical dialog box to prompt for the credential. Now consider this modified version of the command: Invoke-Command \u2013 ScriptBlock { Param ( $c ) Do -Something \u2013 Credential $c } -ComputerName LON-DC1 -ArgumentList ( Get-Credential ) This command runs Get-Credential on the local computer and runs it only once. The resulting object is passed into the $c parameter of the script block, enabling each computer to use the same credential. These examples illustrate the importance of writing remoting commands carefully. By using a combination of running commands remotely and locally, you can achieve various useful goals.","title":"Running commands locally and remotely"},{"location":"Advanced/rem_mod/#persistence","text":"Using the techniques outlined here, every time you use Invoke-Command, the remote computer creates a new wsmprovhost process, and runs the command or commands. It then returns the results, and then closes that Windows PowerShell instance. Each successive Invoke-Command, even if made to the same computer, is akin to opening a new Windows PowerShell window. Any work done by a previous session won't exist unless you save it to a disk or some other persistent storage. For example, consider the following command: Invoke-Command \u2013 ComputerName LON-DC1 \u2013 ScriptBlock { $x = 'BITS' } Invoke-Command \u2013 ComputerName LON-DC1 \u2013 ScriptBlock { Get-Service \u2013 Name $x } In this example, the Get-Service would fail, because it's dependent on the value of a variable created as part of the previous wsmprovhost process. When the first script invoked by the Invoke-Command completes, its variables are cleared from memory. To address this issue, you can create a wsmprovhost process on a remote computer so that you can successfully send successive commands to it. Windows PowerShell can create persistent connections, which are known as sessions, or more accurately, PSSessions. The PS designation signifies Windows PowerShell and differentiates these sessions from other kinds of sessions that might be present in other technologies, such as a Remote Desktop Services (RDS) session. After making a PowerShell session to a remote computer, you run the desired commands within the session, but you leave the PowerShell session running. By doing this, you can run more commands in the session.","title":"Persistence"},{"location":"Advanced/rem_mod/#multiple-computer-names","text":"The \u2013ComputerName parameter of Invoke-Command can accept any collection of string objects as computer names. The following list describes different techniques that can be used to create such collections: -ComputerName ONE,TWO,THREE. A static, comma-separated list of computer names. -ComputerName (Get-Content Names.txt). Reads names from a text file named Names.txt, assuming the file contains one computer name per line. -ComputerName (Import-Csv Computers.csv | Select \u2013ExpandProperty Computer). Reads a comma-separated value (CSV) file that's named Computers.csv and contains a column named Computer that contains computer names. -ComputerName (Get-ADComputer \u2013Filter * | Select \u2013ExpandProperty Name). Queries every computer object in AD DS, which can take a significant amount of time in a large domain.","title":"Multiple computer names"},{"location":"Advanced/rem_mod/#common-mistakes-when-using-computer-names","text":"Be careful where you specify a computer name. For example, review the following command: Invoke-Command \u2013 ScriptBlock { Get-Service \u2013 ComputerName ONE , TWO } This command doesn't provide a \u2013ComputerName parameter to Invoke-Command. Therefore, the command runs on the local computer. The local computer will run Get-Service targeting computers named ONE and TWO. The protocols used by Get-Service will be used instead of Windows PowerShell remoting. Compare this with the following command: Invoke-Command \u2013 ScriptBlock { Get-Service } \u2013 ComputerName ONE , TWO This command will use Windows PowerShell remoting to connect to computers named ONE and TWO. Each of these computers will run Get-Service locally, returning their results using remoting. For more interactive Windows PowerShell remoting situations, you can manage individual sessions as separate entities. To do this, you first create a session by using the New-PSSession command. The benefit of using the New-PSSession command is that the session will persist throughout multiple Invoke-Command instances, allowing you to pass variables and objects to other commands in your script. You can create persistent sessions by using the New-PSSession command and assigning it to a variable. You then can reference the variable later by using the Invoke-Command command. When finished, you can close persistent sessions by using the Remove-PSSession command.","title":"Common mistakes when using computer names"},{"location":"Advanced/rem_mod/#compare-remoting-output-with-local-output","text":"When you run a command such as Get-Process on your local computer, the command returns object or objects of the type System.Diagnostics.Process and adds them to the Windows PowerShell pipeline. These objects have properties, methods, and frequently, events. Methods provide the ability to perform task. For example, the Kill() method of a Process object terminates the process that this object represents. The process of converting an object into a form that can be readily transported is known as serialization. Serialization takes an object's state and transforms it into serial data format, such as XML or binary format. Deserialization converts the formatted XML or binary data into an object type. When a command runs on a remote computer, that computer serializes the results in XML, and transmits that XML text to your computer. You do this to put the object\u2019s information into a format that can be transmitted over a network. However, for complex objects the serialization process can use only static information about an object\u2014in other words, its properties. When your computer receives the XML, it's deserialized back into objects that are put in the Windows PowerShell pipeline. When you have a Process object, by piping it to Get-Member, you know it's now of the type Deserialized.System.Diagnostics.Process, a related, but different, kind of object. The deserialized object has no methods and no events. Given the serialization and deserialization which is part of PowerShell remoting, you should consider any objects that are obtained in this manner to be a static snapshot. The values of object properties are not updatable, and the objects cannot be used to perform any actions. Therefore, any tasks that require interacting with remote objects should be performed on the remote computer as part of the PowerShell remoting session. For example, here is an example of a command that will not yield the desired results: Invoke-Command \u2013 Computer LON-DC1 \u2013 ScriptBlock { Get-Process \u2013 Name Note * } | Stop-Process In this example, you're retrieving Process objects, but the task of stopping processes takes place on the local computer rather than the remote one. This will result in stopping any local processes that happen to have the names matching the remote ones. The proper way to accomplish the intended outcome would be to run: Invoke-Command \u2013 Computer LON-DC1 \u2013 ScriptBlock { Get-Process \u2013 Name Note * | Stop-Process } In this case, the processing has occurred entirely on the remote computer, with only the final results being serialized and sent back. The difference between these two commands is subtle but important to understand.","title":"Compare Remoting Output with Local Output"},{"location":"Advanced/rem_sec/","text":"By default, the endpoints that Windows PowerShell creates only allow connections by members of a particular group. Starting with Windows Server 2016 and Windows 10, these groups include the Remote Management Users group and the local Administrators group. In an Active Directory Domain Services (AD DS) domain, the latter also includes members of the Domain Admins domain global group, since that group is a member of the local Administrators group on every domain-joined computer. Prior to Windows Server 2016 and Windows 10, by default, only members of the local Administrators group were allowed to use PowerShell remoting. It is, however, possible to change the defaults. Each endpoint does have a system access control list (SACL) that you can modify to control exactly who can connect to it. PowerShell Remoting and WinRM listen on the following ports: HTTP: 5985 HTTPS: 5986 The default remoting behavior is to delegate your sign-in credentials to the remote computer, although you do have the option of specifying alternative credentials when you make a connection. The remote computer you are connecting to uses those credentials to impersonate you and perform the tasks that you have specified using those credentials. If you have enabled auditing, in addition to the tasks that you perform, the tasks that PowerShell remoting performs on your behalf will also be audited. In effect, remoting is security-transparent and doesn't change your environment\u2019s existing security. With remoting, you can perform all the same tasks that you would perform while physically located in front of the local computer. On private networks, the default Windows Firewall rule for PowerShell Remoting is to accept all connections. On public networks, the default Windows Firewall rule allows PowerShell Remoting connections only from within the same subnet. You must explicitly change that rule to open PowerShell Remoting to all connections on a public network. Security risks and mutual authentication Delegating your credentials to a remote computer involves some security risks. For example, if an attacker successfully impersonates a known remote computer, you could potentially transmit highly privileged credentials to that attacker, who could then use them for malicious purposes. Because of this risk, remoting by default requires mutual authentication, which means that you must authenticate yourself to the remote computer, and the remote computer must also authenticate itself to you. This mutual authentication guarantees that you connect only to the exact computer that you intended. Mutual authentication is a native feature of the Active Directory Kerberos authentication protocol. When you connect between trusted domain computers, mutual authentication occurs automatically. When you connect to non-domain joined computers, you must provide another form of mutual authentication in the form of an SSL certificate and the HTTPS protocol that must be set up in advance. Another option is to turn off the requirement for mutual authentication by adding the remote computer to your local TrustedHosts list. Note however, that TrustedHosts uses Windows NT LAN Manager (NTLM) authentication, which doesn't ensure server identity. As with any protocol using NTLM for authentication, attackers who have access to a domain-joined computer's trusted account could cause the domain controller to create an NTLM session-key and thus impersonate the server. The NTLM authentication protocol cannot ensure the identity of the target server; it can only ensure that it already knows your password. Therefore, you should configure target servers to use SSL for PowerShell Remoting. Obtaining an SSL certificate issued by a trusted Certification Authority that the client trusts and assigning it to the target server enhances security of the NTLM-based authentication, helping validate both the user identity and server identity. Computer name considerations For AD DS-based authentication to work, PowerShell remoting must be able to search for and retrieve Active Directory Domain Services (AD DS) computer objects. This means that you need to refer to target computers by using their fully qualified domain names (FQDN). IP addresses or Domain Name System (DNS) aliases, for example, won't work because they don't provide remoting with the mutual authentication it needs. If you must refer to a computer by an IP address or a DNS alias, you must connect using HTTPS, which means that the remote computer must be configured to accept that protocol. Alternatively, you must add the IP address or DNS alias to your local TrustedHosts list. A special exception is made for the computer name localhost, which enables you to use it to connect to the local computer without any other configuration changes. If the local computer is using a client-based operating system, then WinRM needs to be configured on it. The TrustedHosts list The TrustedHosts list is a locally configured setting that you also can configure by using a Group Policy Object (GPO). The TrustedHosts list enumerates the computers for which mutual authentication isn't possible. Computers must be listed with the same name that you'll use to connect to them, whether that's the actual computer name, a DNS alias, or an IP address. You can use wildcards to specify SRV*, which allows any computer whose name or DNS alias starts with SRV to connect. However, use caution with this list. While the TrustedHosts list makes it easier to connect to nondomain computers without having to set up HTTPS, it bypasses an important security measure. It allows you to send your credentials to a remote computer without determining whether that computer is in fact one that you intended to connect to. You should use the TrustedHosts list only to designate computers that you know not to be compromised, such as servers housed in a protected datacenter. You also can use TrustedHosts to temporarily enable connections to nondomain computers on a controlled network subnet, such as new computers that are undergoing a provisioning process. As a best practice, you should avoid using the TrustedHosts list unless absolutely necessary. Configuring a nondomain computer to use HTTPS is a more secure long-term solution. Privacy By default, remoting uses HTTP, which doesn't offer privacy or encryption of the content of your communication. However, Windows PowerShell can and does apply application-level encryption by default. This means that your communications receive a degree of privacy and protection. On internal networks, this application-level encryption is generally sufficient to satisfy organizational security requirements. In a domain environment that uses the default Kerberos authentication protocol, credentials are sent in the form of encrypted Kerberos tickets that don't include passwords. When you connect by using HTTPS, the entire channel is encrypted by using the encryption keys of the remote computer\u2019s SSL certificate. As a result, even if you use Basic authentication, passwords are not transmitted in clear text. However, when you connect by using HTTP and Basic authentication to a computer that isn't configured for HTTPS, credentials (including passwords) will be transmitted in clear text. This can occur, for example, when you connect to a nondomain computer that you add to your local TrustedHosts list. This can even occur when you use a domain-joined computer by specifying its IP address rather than its host name. Because credentials are transmitted in clear text in that scenario, you should ensure that you connect to a nondomain computer only on a controlled and protected network subnet, such as one specifically designated for new computer provisioning. If you have to routinely connect to a nondomain computer, you should configure it to support HTTPS.","title":"Security"},{"location":"Advanced/rem_sec/#security-risks-and-mutual-authentication","text":"Delegating your credentials to a remote computer involves some security risks. For example, if an attacker successfully impersonates a known remote computer, you could potentially transmit highly privileged credentials to that attacker, who could then use them for malicious purposes. Because of this risk, remoting by default requires mutual authentication, which means that you must authenticate yourself to the remote computer, and the remote computer must also authenticate itself to you. This mutual authentication guarantees that you connect only to the exact computer that you intended. Mutual authentication is a native feature of the Active Directory Kerberos authentication protocol. When you connect between trusted domain computers, mutual authentication occurs automatically. When you connect to non-domain joined computers, you must provide another form of mutual authentication in the form of an SSL certificate and the HTTPS protocol that must be set up in advance. Another option is to turn off the requirement for mutual authentication by adding the remote computer to your local TrustedHosts list. Note however, that TrustedHosts uses Windows NT LAN Manager (NTLM) authentication, which doesn't ensure server identity. As with any protocol using NTLM for authentication, attackers who have access to a domain-joined computer's trusted account could cause the domain controller to create an NTLM session-key and thus impersonate the server. The NTLM authentication protocol cannot ensure the identity of the target server; it can only ensure that it already knows your password. Therefore, you should configure target servers to use SSL for PowerShell Remoting. Obtaining an SSL certificate issued by a trusted Certification Authority that the client trusts and assigning it to the target server enhances security of the NTLM-based authentication, helping validate both the user identity and server identity.","title":"Security risks and mutual authentication"},{"location":"Advanced/rem_sec/#computer-name-considerations","text":"For AD DS-based authentication to work, PowerShell remoting must be able to search for and retrieve Active Directory Domain Services (AD DS) computer objects. This means that you need to refer to target computers by using their fully qualified domain names (FQDN). IP addresses or Domain Name System (DNS) aliases, for example, won't work because they don't provide remoting with the mutual authentication it needs. If you must refer to a computer by an IP address or a DNS alias, you must connect using HTTPS, which means that the remote computer must be configured to accept that protocol. Alternatively, you must add the IP address or DNS alias to your local TrustedHosts list. A special exception is made for the computer name localhost, which enables you to use it to connect to the local computer without any other configuration changes. If the local computer is using a client-based operating system, then WinRM needs to be configured on it.","title":"Computer name considerations"},{"location":"Advanced/rem_sec/#the-trustedhosts-list","text":"The TrustedHosts list is a locally configured setting that you also can configure by using a Group Policy Object (GPO). The TrustedHosts list enumerates the computers for which mutual authentication isn't possible. Computers must be listed with the same name that you'll use to connect to them, whether that's the actual computer name, a DNS alias, or an IP address. You can use wildcards to specify SRV*, which allows any computer whose name or DNS alias starts with SRV to connect. However, use caution with this list. While the TrustedHosts list makes it easier to connect to nondomain computers without having to set up HTTPS, it bypasses an important security measure. It allows you to send your credentials to a remote computer without determining whether that computer is in fact one that you intended to connect to. You should use the TrustedHosts list only to designate computers that you know not to be compromised, such as servers housed in a protected datacenter. You also can use TrustedHosts to temporarily enable connections to nondomain computers on a controlled network subnet, such as new computers that are undergoing a provisioning process. As a best practice, you should avoid using the TrustedHosts list unless absolutely necessary. Configuring a nondomain computer to use HTTPS is a more secure long-term solution.","title":"The TrustedHosts list"},{"location":"Advanced/rem_sec/#privacy","text":"By default, remoting uses HTTP, which doesn't offer privacy or encryption of the content of your communication. However, Windows PowerShell can and does apply application-level encryption by default. This means that your communications receive a degree of privacy and protection. On internal networks, this application-level encryption is generally sufficient to satisfy organizational security requirements. In a domain environment that uses the default Kerberos authentication protocol, credentials are sent in the form of encrypted Kerberos tickets that don't include passwords. When you connect by using HTTPS, the entire channel is encrypted by using the encryption keys of the remote computer\u2019s SSL certificate. As a result, even if you use Basic authentication, passwords are not transmitted in clear text. However, when you connect by using HTTP and Basic authentication to a computer that isn't configured for HTTPS, credentials (including passwords) will be transmitted in clear text. This can occur, for example, when you connect to a nondomain computer that you add to your local TrustedHosts list. This can even occur when you use a domain-joined computer by specifying its IP address rather than its host name. Because credentials are transmitted in clear text in that scenario, you should ensure that you connect to a nondomain computer only on a controlled and protected network subnet, such as one specifically designated for new computer provisioning. If you have to routinely connect to a nondomain computer, you should configure it to support HTTPS.","title":"Privacy"},{"location":"Advanced/rem_sess/","text":"Disconnected sessions In Windows PowerShell 3.0 and newer, you can also manually disconnect from sessions. This allows you to close the session in which a PowerShell session was established, even shut down the local computer, without disrupting commands running in the PowerShell session on the remote computer. This is particularly useful for running commands that take a long time to complete and provides the time and device flexibility that IT professionals need. Controlling sessions Every computer has a drive named WSMan that includes many configuration parameters related to the session, such as: Maximum session run time Maximum idle time Maximum number of incoming connections Maximum number of sessions per administrator You can explore these configuration parameters by running dir WSMan:\\localhost\\shell, and change them in that same location. You also can control many of the settings through Group Policy. Create and manage persistent PSSessions You use the New-PSSession command to create a persistent connection. The command contains many of the same parameters as Invoke-Command, including -Credential, \u2013Port, and \u2013UseSSL. This is because you're creating a connection that is identical to the one Invoke-Command creates. However, instead of closing this connection immediately, you're leaving it running. PowerShell sessions do have an idle timeout, after which the remote computer will close them automatically. A closed PowerShell session differs from a disconnected PowerShell session, because closed PowerShell sessions can't be reconnected. In this case, you can only remove the PowerShell session, and then recreate it. New-PSSession can accept multiple computer names, which causes it to create multiple PowerShell session objects. When you run the New-PSSession command, it outputs objects representing the newly created PowerShell sessions. You can assign these PowerShell sessions to a variable to make them easier to refer to, and to use in the future. You can use a PowerShell session as soon as you create it. Both the Invoke-Command and Enter-PSSession commands can accept a PowerShell session object instead of a computer name. Invoke-Command can accept multiple PowerShell session objects. You use the commands\u2019 \u2013Session parameter for this purpose. When you use this parameter, the commands use the existing PowerShell session instead of creating a new connection. When your command finishes running or you exit the PowerShell session, the PowerShell session remains running and connected, and ready for future use. For example, you can use the following commands to enter a PowerShell session on LON-CL1 and then close it: $client = New-PSSession \u2013 ComputerName LON-CL1 Enter-PSSession \u2013 Session $client Exit-PSSession Alternatively, you could use the following commands to achieve the same results: $computers = New-PSSession \u2013 ComputerName LON-CL1 , LON-DC1 Invoke-Command \u2013 Session $computers \u2013 ScriptBlock { Get-Process } For example, the following command can use the $dc variable to open a PowerShell session to LON-DC1 within a script or code block: $dc = New-PSSession \u2013 ComputerName LON-DC1 The following command creates remote sessions on Server01 and Server02, and the session objects are stored in the $s variable: $s = New-PSSession -ComputerName Server01 , Server02 Now that the sessions are established, you can run any command in them. And because the sessions are persistent, you can collect data from one command and use it in another command. For example, the following command runs a Get-HotFix command in the sessions in the $s variable, and it saves the results in the $h variable: Invoke-Command -Session $s { $h = Get-HotFix } The $h variable is created in each of the sessions in $s, but it doesn't exist in the local session. Now you can use the data in the $h variable with other commands in the same session, and the results are displayed on the local computer. For example: Invoke-Command -Session $s { $h | where { $_ . InstalledBy -ne \"NTAUTHORITY\\SYSTEM\" }} Disconnect PSSessions You can disconnect from PSSessions when both the initiating computer and the remote computer are running Windows PowerShell 3.0 and later. Disconnecting is typically a manual process. In some scenarios, Windows PowerShell can automatically place a connection into the Disconnected state if the connection is interrupted. However, if you manually close the Windows PowerShell host application it won't disconnect from the sessions, it will just close them. Using disconnected sessions is similar to the following process: Use New-PSSession to create the new PSSession. Optionally, use the PSSession to run commands. Run Disconnect-PSSession to disconnect from the PSSession. Pass the PSSession object that you want to disconnect from to the command\u2019s \u2013Session parameter. Optionally, move to another computer and open Windows PowerShell. Run Get-PSSession with the \u2013ComputerName parameter to obtain a list of your PSSessions running on the specified computer. Use Connect-PSSession to reconnect to the desired PSSession. You cannot review or reconnect to another user\u2019s PSSessions on a computer. Implicit Remoting One of the ongoing problems in the Windows management space is version mismatch. For example, Windows servers 2019 and 2022 include many new Windows PowerShell commands. You can make these commands available on Windows 10 or Windows 11 as part of the Remote Server Administration Tools (RSAT). However, you might not be able to use the same approach with older versions of Windows. You must be familiar with another ongoing problem if you recently had to rebuild a workstation. The problem is the sheer amount of time it can take to track down and install administrative tools and Microsoft Management Consoles (MMCs) on a computer. Assuming all of them are compatible with your Windows versions, installation alone can take days. These problems lead administrators to forgo installing tools on workstations, and instead access tools directly on the server through Microsoft Remote Desktop. However, this isn't a good solution because it puts the server in the position of having to be a client, while simultaneously providing services to hundreds or thousands of users. The advent of Server Core, which lacks a graphical user interface (GUI), was in part to make servers perform better and need fewer updates. However, this also means that they can't run GUI tools and MMCs. Implicit remoting brings tools to you Implicit remoting brings a copy of a server\u2019s Windows PowerShell tools to your local computer. In reality, you're not copying the commands at all; you're creating a kind of shortcut, called a proxy function, to the server\u2019s commands. When you run the commands on your local computer, they implicitly run on the server through remoting. Results are then sent back to you. It's exactly as if you ran everything through Invoke-Command, but it's much more convenient. Commands also run quicker, because commands on the server are co-located with the server\u2019s functionality and data. Using implicit remoting While implicit remoting became available in Windows PowerShell 2.0, it became much easier to use starting with Windows PowerShell 3.0. All that's required is to create a session to the server containing the module that you want to use. Then, using Import-Module and its \u2013PSSession parameter, you import the desired module. The commands in that module, and even its Help files become available in your local Windows PowerShell session. With implicit remoting, you have the option of adding a prefix to the noun of commands that you import. Doing this can make it easier, for example, to have multiple versions of the same commands loaded simultaneously without causing a naming collision. For example, if you import both Microsoft Exchange Server 2016 and Exchange Server 2019 commands, you might add the 2016 and 2019 prefix to each of them, respectively. This enables you to run both sets of commands. In reality, each would be running on their respective servers, enabling you to run both sets (perhaps in a migration scenario) side-by-side. The Help option also works for commands that are running through implicit remoting. However, the Help files are drawn through the same remoting session as the commands themselves. Therefore, the remote computer must have an updated copy of its Help files. This can be a concern on servers because they might not be used frequently and might not have had Update-Help run on them recently to pull down the latest Help files.","title":"Sessions"},{"location":"Advanced/rem_sess/#disconnected-sessions","text":"In Windows PowerShell 3.0 and newer, you can also manually disconnect from sessions. This allows you to close the session in which a PowerShell session was established, even shut down the local computer, without disrupting commands running in the PowerShell session on the remote computer. This is particularly useful for running commands that take a long time to complete and provides the time and device flexibility that IT professionals need.","title":"Disconnected sessions"},{"location":"Advanced/rem_sess/#controlling-sessions","text":"Every computer has a drive named WSMan that includes many configuration parameters related to the session, such as: Maximum session run time Maximum idle time Maximum number of incoming connections Maximum number of sessions per administrator You can explore these configuration parameters by running dir WSMan:\\localhost\\shell, and change them in that same location. You also can control many of the settings through Group Policy.","title":"Controlling sessions"},{"location":"Advanced/rem_sess/#create-and-manage-persistent-pssessions","text":"You use the New-PSSession command to create a persistent connection. The command contains many of the same parameters as Invoke-Command, including -Credential, \u2013Port, and \u2013UseSSL. This is because you're creating a connection that is identical to the one Invoke-Command creates. However, instead of closing this connection immediately, you're leaving it running. PowerShell sessions do have an idle timeout, after which the remote computer will close them automatically. A closed PowerShell session differs from a disconnected PowerShell session, because closed PowerShell sessions can't be reconnected. In this case, you can only remove the PowerShell session, and then recreate it. New-PSSession can accept multiple computer names, which causes it to create multiple PowerShell session objects. When you run the New-PSSession command, it outputs objects representing the newly created PowerShell sessions. You can assign these PowerShell sessions to a variable to make them easier to refer to, and to use in the future. You can use a PowerShell session as soon as you create it. Both the Invoke-Command and Enter-PSSession commands can accept a PowerShell session object instead of a computer name. Invoke-Command can accept multiple PowerShell session objects. You use the commands\u2019 \u2013Session parameter for this purpose. When you use this parameter, the commands use the existing PowerShell session instead of creating a new connection. When your command finishes running or you exit the PowerShell session, the PowerShell session remains running and connected, and ready for future use. For example, you can use the following commands to enter a PowerShell session on LON-CL1 and then close it: $client = New-PSSession \u2013 ComputerName LON-CL1 Enter-PSSession \u2013 Session $client Exit-PSSession Alternatively, you could use the following commands to achieve the same results: $computers = New-PSSession \u2013 ComputerName LON-CL1 , LON-DC1 Invoke-Command \u2013 Session $computers \u2013 ScriptBlock { Get-Process } For example, the following command can use the $dc variable to open a PowerShell session to LON-DC1 within a script or code block: $dc = New-PSSession \u2013 ComputerName LON-DC1 The following command creates remote sessions on Server01 and Server02, and the session objects are stored in the $s variable: $s = New-PSSession -ComputerName Server01 , Server02 Now that the sessions are established, you can run any command in them. And because the sessions are persistent, you can collect data from one command and use it in another command. For example, the following command runs a Get-HotFix command in the sessions in the $s variable, and it saves the results in the $h variable: Invoke-Command -Session $s { $h = Get-HotFix } The $h variable is created in each of the sessions in $s, but it doesn't exist in the local session. Now you can use the data in the $h variable with other commands in the same session, and the results are displayed on the local computer. For example: Invoke-Command -Session $s { $h | where { $_ . InstalledBy -ne \"NTAUTHORITY\\SYSTEM\" }}","title":"Create and manage persistent PSSessions"},{"location":"Advanced/rem_sess/#disconnect-pssessions","text":"You can disconnect from PSSessions when both the initiating computer and the remote computer are running Windows PowerShell 3.0 and later. Disconnecting is typically a manual process. In some scenarios, Windows PowerShell can automatically place a connection into the Disconnected state if the connection is interrupted. However, if you manually close the Windows PowerShell host application it won't disconnect from the sessions, it will just close them. Using disconnected sessions is similar to the following process: Use New-PSSession to create the new PSSession. Optionally, use the PSSession to run commands. Run Disconnect-PSSession to disconnect from the PSSession. Pass the PSSession object that you want to disconnect from to the command\u2019s \u2013Session parameter. Optionally, move to another computer and open Windows PowerShell. Run Get-PSSession with the \u2013ComputerName parameter to obtain a list of your PSSessions running on the specified computer. Use Connect-PSSession to reconnect to the desired PSSession. You cannot review or reconnect to another user\u2019s PSSessions on a computer.","title":"Disconnect PSSessions"},{"location":"Advanced/rem_sess/#implicit-remoting","text":"One of the ongoing problems in the Windows management space is version mismatch. For example, Windows servers 2019 and 2022 include many new Windows PowerShell commands. You can make these commands available on Windows 10 or Windows 11 as part of the Remote Server Administration Tools (RSAT). However, you might not be able to use the same approach with older versions of Windows. You must be familiar with another ongoing problem if you recently had to rebuild a workstation. The problem is the sheer amount of time it can take to track down and install administrative tools and Microsoft Management Consoles (MMCs) on a computer. Assuming all of them are compatible with your Windows versions, installation alone can take days. These problems lead administrators to forgo installing tools on workstations, and instead access tools directly on the server through Microsoft Remote Desktop. However, this isn't a good solution because it puts the server in the position of having to be a client, while simultaneously providing services to hundreds or thousands of users. The advent of Server Core, which lacks a graphical user interface (GUI), was in part to make servers perform better and need fewer updates. However, this also means that they can't run GUI tools and MMCs.","title":"Implicit Remoting"},{"location":"Advanced/rem_sess/#implicit-remoting-brings-tools-to-you","text":"Implicit remoting brings a copy of a server\u2019s Windows PowerShell tools to your local computer. In reality, you're not copying the commands at all; you're creating a kind of shortcut, called a proxy function, to the server\u2019s commands. When you run the commands on your local computer, they implicitly run on the server through remoting. Results are then sent back to you. It's exactly as if you ran everything through Invoke-Command, but it's much more convenient. Commands also run quicker, because commands on the server are co-located with the server\u2019s functionality and data.","title":"Implicit remoting brings tools to you"},{"location":"Advanced/rem_sess/#using-implicit-remoting","text":"While implicit remoting became available in Windows PowerShell 2.0, it became much easier to use starting with Windows PowerShell 3.0. All that's required is to create a session to the server containing the module that you want to use. Then, using Import-Module and its \u2013PSSession parameter, you import the desired module. The commands in that module, and even its Help files become available in your local Windows PowerShell session. With implicit remoting, you have the option of adding a prefix to the noun of commands that you import. Doing this can make it easier, for example, to have multiple versions of the same commands loaded simultaneously without causing a naming collision. For example, if you import both Microsoft Exchange Server 2016 and Exchange Server 2019 commands, you might add the 2016 and 2019 prefix to each of them, respectively. This enables you to run both sets of commands. In reality, each would be running on their respective servers, enabling you to run both sets (perhaps in a migration scenario) side-by-side. The Help option also works for commands that are running through implicit remoting. However, the Help files are drawn through the same remoting session as the commands themselves. Therefore, the remote computer must have an updated copy of its Help files. This can be a concern on servers because they might not be used frequently and might not have had Update-Help run on them recently to pull down the latest Help files.","title":"Using implicit remoting"},{"location":"Advanced/rem_wmi_cim/","text":"You can use Windows Management Instrumentation (WMI) and Common Information Model (CIM) cmdlets to query and manage remote computers. When you connect to a remote computer, you can specify alternative credentials for the connection, but alternative credentials are optional. WMI and CIM cmdlets have different capabilities and different syntaxes for remote connections. Using WMI Cmdlets For the WMI commands, use the -ComputerName parameter to specify a remote computer\u2019s name or IP address. You can specify multiple computer names to run the command on multiple computers in a single statement. You can provide the computer names as a comma-separated list, an array containing multiple computer names, or a parenthetical command that produces a collection of computer names as string objects. Use the -Credential parameter to specify an alternative username. If you specify only a username, then you're prompted for the password. If you use the Get-Credential cmdlet to store the username and password in a variable, then you can reference that variable to eliminate the password prompt. In the following example, you'll be prompted for the password: Get-WmiObject -ComputerName LON-DC1 -Credential ADATUM \\ Administrator -Class Win32_BIOS When you specify multiple computer names, Windows PowerShell contacts them one at a time in the order that you specify. If connectivity to one computer fails, the command produces an error message and continues to try the remaining computers. Using CIM Cmdlets The CIM cmdlets also provide support for ad hoc connections to remote computers by using the -ComputerName parameter. However, the CIM cmdlets don't have a -Credential parameter to specify alternate credentials. If you want to use alternate credentials, you need to create a CIM session. You can run the following CIM command to retrieve the same information as the Get-WmiObject command in the previous code example: Get-CimInstance -ComputerName LON-DC1 -Classname Win32_BIOS Remember that CIM commands use the WS-MAN protocol for ad hoc connections. This protocol has specific authentication requirements. When establishing a connection between computers in the same domain or in trusting domains, you typically have to provide a computer\u2019s name as it displays in Active Directory Domain Services (AD DS). You can't provide an alias name or an IP address because that will result in a failure of Kerberos authentication. CIMSession objects A Common Information Model (CIM) session is a persistent configuration object that's used when creating a connection to a remote computer. The connection uses WS-MAN by default, but you can specify the DCOM protocol. After a session is created, you can use it to process multiple queries for that computer. This simplifies connectivity because all of the configuration options are contained in the session. A CIM session also allows you to specify connectivity options that aren't available for an ad hoc connection. Creating session objects When you create a session, you should store it in a variable to reference it later. The basic syntax to create a session and store it in a variable is: $s = New-CimSession -ComputerName LON-DC1 # You can create multiple sessions at the same time: $sessions = New-CimSession -ComputerName LON-CL1 , LON-DC1 When you create a session, PowerShell doesn't establish the connection immediately. When a cmdlet uses the CIM session, PowerShell connects to the specified computer, and then, when the cmdlet finishes, PowerShell terminates the connection. In some cases, it might be beneficial to use PowerShell remoting instead of CIM sessions for remote connectivity. PowerShell remoting opens a connection to the remote computer and keeps it open until explicitly closed. If you're running multiple queries against a computer, this might improve performance. Using Sessions After you've stored the session in a variable, you reference it with CIM cmdlets by using the -CimSession parameter. The following example uses a variable that contains multiple sessions: Get-CimInstance -CimSession $sessions -ClassName Win32_OperatingSystem Remember that sessions are designed to work best in a domain environment, between computers in the same domain or in trusting domains. If you have to create a session to a nondomain computer or to a computer in an untrusted domain, you'll need to do additional configuration. The help information for some cmdlets such as Get-SmbShare states that they support a -CimSession parameter. Those commands use CIM internally. When you use those commands to query a remote computer, you can provide a CIM session object to the -CimSession parameter to connect by using an existing session. Configuring session options A session option object allows you to specify many settings for a session. When you create a new session, you specify the session option object to configure the session. The following example creates a session by using DCOM instead of WS-MAN: $opt = New-CimSessionOption -Protocol Dcom $DcomSession = New-CimSession -ComputerName LON-DC1 -SessionOption $opt Get-CimInstance -ClassName Win32_BIOS -CimSession $DcomSession The first line in the preceding code creates a session option object that specifies that the DCOM protocol should be used for connectivity. The second line creates a new session by using that session option object and stores it in a variable. The final line uses the session to query the remote computer defined in the session and return the requested information. Removing sessions After you create a session, it remains in memory and available for use until the instance of PowerShell is closed. You can manually remove sessions by using the Remove-CimSession cmdlet. The following example removes one or more sessions contained in a variable: $sessions | Remove-CimSession To remove the sessions for a specific remote computer, you can query the sessions for that computer and then remove them, as the following example depicts: Get-CimSession -ComputerName LON-DC1 | Remove-CimSession To remove all sessions, run the following command: Get-CimSession | Remove-CimSession","title":"Using WMI or CIM"},{"location":"Advanced/rem_wmi_cim/#using-wmi-cmdlets","text":"For the WMI commands, use the -ComputerName parameter to specify a remote computer\u2019s name or IP address. You can specify multiple computer names to run the command on multiple computers in a single statement. You can provide the computer names as a comma-separated list, an array containing multiple computer names, or a parenthetical command that produces a collection of computer names as string objects. Use the -Credential parameter to specify an alternative username. If you specify only a username, then you're prompted for the password. If you use the Get-Credential cmdlet to store the username and password in a variable, then you can reference that variable to eliminate the password prompt. In the following example, you'll be prompted for the password: Get-WmiObject -ComputerName LON-DC1 -Credential ADATUM \\ Administrator -Class Win32_BIOS When you specify multiple computer names, Windows PowerShell contacts them one at a time in the order that you specify. If connectivity to one computer fails, the command produces an error message and continues to try the remaining computers.","title":"Using WMI Cmdlets"},{"location":"Advanced/rem_wmi_cim/#using-cim-cmdlets","text":"The CIM cmdlets also provide support for ad hoc connections to remote computers by using the -ComputerName parameter. However, the CIM cmdlets don't have a -Credential parameter to specify alternate credentials. If you want to use alternate credentials, you need to create a CIM session. You can run the following CIM command to retrieve the same information as the Get-WmiObject command in the previous code example: Get-CimInstance -ComputerName LON-DC1 -Classname Win32_BIOS Remember that CIM commands use the WS-MAN protocol for ad hoc connections. This protocol has specific authentication requirements. When establishing a connection between computers in the same domain or in trusting domains, you typically have to provide a computer\u2019s name as it displays in Active Directory Domain Services (AD DS). You can't provide an alias name or an IP address because that will result in a failure of Kerberos authentication.","title":"Using CIM Cmdlets"},{"location":"Advanced/rem_wmi_cim/#cimsession-objects","text":"A Common Information Model (CIM) session is a persistent configuration object that's used when creating a connection to a remote computer. The connection uses WS-MAN by default, but you can specify the DCOM protocol. After a session is created, you can use it to process multiple queries for that computer. This simplifies connectivity because all of the configuration options are contained in the session. A CIM session also allows you to specify connectivity options that aren't available for an ad hoc connection.","title":"CIMSession objects"},{"location":"Advanced/rem_wmi_cim/#creating-session-objects","text":"When you create a session, you should store it in a variable to reference it later. The basic syntax to create a session and store it in a variable is: $s = New-CimSession -ComputerName LON-DC1 # You can create multiple sessions at the same time: $sessions = New-CimSession -ComputerName LON-CL1 , LON-DC1 When you create a session, PowerShell doesn't establish the connection immediately. When a cmdlet uses the CIM session, PowerShell connects to the specified computer, and then, when the cmdlet finishes, PowerShell terminates the connection. In some cases, it might be beneficial to use PowerShell remoting instead of CIM sessions for remote connectivity. PowerShell remoting opens a connection to the remote computer and keeps it open until explicitly closed. If you're running multiple queries against a computer, this might improve performance.","title":"Creating session objects"},{"location":"Advanced/rem_wmi_cim/#using-sessions","text":"After you've stored the session in a variable, you reference it with CIM cmdlets by using the -CimSession parameter. The following example uses a variable that contains multiple sessions: Get-CimInstance -CimSession $sessions -ClassName Win32_OperatingSystem Remember that sessions are designed to work best in a domain environment, between computers in the same domain or in trusting domains. If you have to create a session to a nondomain computer or to a computer in an untrusted domain, you'll need to do additional configuration. The help information for some cmdlets such as Get-SmbShare states that they support a -CimSession parameter. Those commands use CIM internally. When you use those commands to query a remote computer, you can provide a CIM session object to the -CimSession parameter to connect by using an existing session.","title":"Using Sessions"},{"location":"Advanced/rem_wmi_cim/#configuring-session-options","text":"A session option object allows you to specify many settings for a session. When you create a new session, you specify the session option object to configure the session. The following example creates a session by using DCOM instead of WS-MAN: $opt = New-CimSessionOption -Protocol Dcom $DcomSession = New-CimSession -ComputerName LON-DC1 -SessionOption $opt Get-CimInstance -ClassName Win32_BIOS -CimSession $DcomSession The first line in the preceding code creates a session option object that specifies that the DCOM protocol should be used for connectivity. The second line creates a new session by using that session option object and stores it in a variable. The final line uses the session to query the remote computer defined in the session and return the requested information.","title":"Configuring session options"},{"location":"Advanced/rem_wmi_cim/#removing-sessions","text":"After you create a session, it remains in memory and available for use until the instance of PowerShell is closed. You can manually remove sessions by using the Remove-CimSession cmdlet. The following example removes one or more sessions contained in a variable: $sessions | Remove-CimSession To remove the sessions for a specific remote computer, you can query the sessions for that computer and then remove them, as the following example depicts: Get-CimSession -ComputerName LON-DC1 | Remove-CimSession To remove all sessions, run the following command: Get-CimSession | Remove-CimSession","title":"Removing sessions"},{"location":"Advanced/remoting/","text":"You can run commands on one or hundreds of computers with a single PowerShell command. PowerShell supports remote computing by using various technologies, including Windows Management Instrumentation (WMI), remote procedure call (RPC), and Web Services for Management (WS-Management, or WS-MAN). Windows PowerShell remoting uses the WS-Management protocol to let you run any Windows PowerShell command on one or more remote computers. For example, you can establish persistent connections, start interactive sessions, and run scripts on remote computers. Remoting uses an open-standard protocol called Web Services for Management (WS-Management or WS-MAN). As the name implies, this protocol is built on the same HTTP, or HTTPS, protocol that web browsers use to communicate with web servers. This makes the protocol easier to manage and to route through firewalls. Windows operating systems implement the protocol by using the Windows Remote Management (WinRM) service. PowerShell supports WMI, WS-Management, and Secure Shell (SSH) remoting. In PowerShell 6, Remote Procedure Calls (RPC)-based communication is not supported. In PowerShell 7 and newer, RPC is supported only in Windows. You must enable remoting on the computers on which you want to receive incoming connections, although no configuration is necessary on computers that are initiating outgoing connections. PowerShell remoting is enabled by default for incoming connections on all currently supported versions of Windows Server. You can also enable it on any computer that's running Windows PowerShell 3.0 or newer. Remoting Architecture Remoting starts with the WinRM service. It registers one or more listeners, with each listener accepting incoming traffic through either HTTP or HTTPS. Each listener can be bound to a single local IP address or to multiple IP addresses. There is no dependency on Microsoft Internet Information Services (IIS), which means that IIS doesn't have to be installed for WinRM to function. Incoming traffic includes a packet header that indicates the traffic\u2019s intended destination, or endpoint. In Windows PowerShell, these endpoints are also known as session configurations. Each endpoint is associated with a specific application. When traffic is directed to an endpoint, WinRM starts the associated application, hands off the incoming traffic, and then waits for the application to complete its task. The application can pass data back to WinRM, and WinRM transmits the data back to the originating computer. In a Windows PowerShell scenario, you would send commands to WinRM, which then runs the commands. The process is listed as Wsmprovhost in the remote computer\u2019s process list. Windows PowerShell would then run those commands and convert the resulting objects (if there are any) into XML. The XML text stream is then handed back to WinRM, which transmits it to the originating computer. Windows PowerShell on the remote computer translates the XML back into static objects. This enables the command results to behave much like any other objects within the Windows PowerShell pipeline. Windows PowerShell can register multiple endpoints or session configurations with WinRM. In fact, a 64-bit operating system will register an endpoint for both the 64-bit Windows PowerShell host and the 32-bit host, by default. You also can create your own custom endpoints that have highly precise permissions and capabilities assigned to them. Without Configuration Many Windows PowerShell cmdlets have the ComputerName parameter that enables you to collect data and change settings on one or more remote computers. These cmdlets use varying communication protocols and work on all Windows operating systems without any special configuration. These cmdlets include: Restart-Computer Test-Connection Clear-EventLog Get-EventLog Get-HotFix Get-Process Get-Service Set-Service Get-WinEvent Get-WmiObject Typically, cmdlets that support remoting without special configuration have the ComputerName parameter and don't have the Session parameter. To find these cmdlets in your session, enter: Get-Command | where { $_ . parameters . keys -contains \"ComputerName\" -and $_ . parameters . keys -notcontains \"Session\" } Over SSH PowerShell remoting normally uses WinRM for connection negotiation and data transport. SSH is now available for Linux and Windows platforms and allows true multiplatform PowerShell remoting. WinRM provides a robust hosting model for PowerShell remote sessions. SSH-based remoting doesn't currently support remote endpoint configuration and Just Enough Administration (JEA). SSH remoting offers basic PowerShell session remoting between Windows and Linux computers. SSH remoting creates a PowerShell host process on the target computer as an SSH subsystem. Microsoft plans to eventually implement a general hosting model similar to WinRM to support endpoint configuration and JEA. The New-PSSession, Enter-PSSession, and Invoke-Command cmdlets now have a new parameter set to support this new remoting connection. To use PowerShell remoting over SSH, you must install PowerShell 6 or newer and SSH on all computers. Then, you must install both the SSH client (ssh.exe) and server (sshd.exe) executables so that you can remote to and from the computers. OpenSSH for Windows is available starting with Windows 10 build 1809 and Windows Server 2019. For Linux, install the version of SSH (including the sshd.exe server) that's appropriate for your platform. You also need to install the current version of PowerShell from GitHub to ensure that the SSH remoting feature is available. You should configure the SSH server to create an SSH subsystem to host a PowerShell process on the remote computer. You also need to enable either password or key-based authentication. Compare Remoting with Remote Connectivity Remoting is the name of a specific Windows PowerShell feature, not to be confused with the more generic concept of remote connectivity. Remoting is a generalized way to transmit any command to a remote computer so it runs locally on that computer. The command that you run doesn't have to be available on the computer that initiates the connection. Only the remote computers must be able to run it. The purpose of remoting is to reduce or eliminate the need for individual command authors to code their own communications protocols. Many command authors are already required to do this to ship their products. This is why many different protocols and technologies are currently in use. Many commands implement their own communications protocols, although in the future many of them might instead be changed to use remoting. For example, Get-WmiObject uses RPCs, whereas Get-Process communicates with the computer\u2019s Remote Registry service. Microsoft Exchange Server commands have their own communications channels, and Active Directory commands communicate with a specific web service gateway by using their own protocol. All these other forms of communication might have unique firewall requirements and might require specific configurations to be in place to operate. Enabling Remoting It's important to understand that you need to enable Windows PowerShell remoting only on computers that will receive incoming connections. No configuration is necessary to enable outgoing communications, except for making sure that any local firewall will allow the outgoing traffic. Manually PowerShell remoting is enabled by default on Windows Server platforms. You can enable PowerShell remoting on other supported Windows versions, and you can also re-enable remoting if it becomes disabled. To manually enable Windows PowerShell remoting on a computer, run the Windows PowerShell Enable-PSRemoting cmdlet. This is a persistent change that you can disable later by running Disable-PSRemoting. Note that this task requires the privileges granted to local Administrators group. The Enable-PSRemoting cmdlet performs the following operations: Runs the Set-WSManQuickConfig cmdlet, which in turn performs the following tasks: Starts the WinRM service. Sets the startup type on the WinRM service to Automatic. Creates a listener to accept requests on any IP address. Enables a firewall exception for WS-Management communications. Creates the simple-name and long-name session endpoint configurations, if needed. Enables all session configurations. Changes the security descriptor of all session configurations to allow remote access. Restarts the WinRM service to make the preceding changes effective. This command will fail on client computers where one or more network connections are set to Public instead of Work or Home. You can override this failure by adding the \u2013SkipNetworkProfileCheck parameter. However, be aware that Windows Firewall won't allow exceptions when you're connected to a Public network. The Set-WSManQuickConfig cmdlet doesn't affect remote endpoint configurations created by Windows PowerShell. It only affects endpoints created with PowerShell version 6 and newer. To enable and disable PowerShell remoting endpoints that are hosted by Windows PowerShell, run the Enable-PSRemoting cmdlet from within a Windows PowerShell session. By Using a GPO Many organizations will prefer to centrally control Windows PowerShell remoting enablement and settings through GPOs. Microsoft supports this capability. You must set up various settings in a GPO to duplicate the steps taken by Enable-PSRemoting. To enable remoting by using Group Policy, you should configure the Allow Remote Server Management Through WinRM policy setting in the appropriate GPO. This setting also allows you to filter IP addresses from which remote connections can be initiated. In addition to configuring this policy, you should also configure appropriate firewall exceptions, as described earlier. Common Remoting Techniques The Enter-PSSession and Invoke-Command commands support several parameters that you can use to change common connection options. These parameters include: \u2013Port. Specifies an alternate TCP port for the connection. Use this parameter when the computer to which you're connecting is listening on a port other than the default 5985 (HTTP) or 5986 (HTTPS). Be aware that you can, locally or through Group Policy, configure a different port as a permanent new default. \u2013UseSSL. Instructs Windows PowerShell to use HTTPS instead of HTTP. \u2013Credential. Specifies an alternative credential for the connection. This credential will be validated by the remote computer and must have sufficient privileges and permissions to perform whatever tasks you intend to perform on the remote computer. \u2013ConfigurationName. Connects to an endpoint (session configuration) other than the default endpoint. For example, you can specify microsoft.powershell32 to connect to the remote computer\u2019s 32-bit Windows PowerShell endpoint. \u2013Authentication. Specifies an authentication protocol. The default is Kerberos authentication, but other options include Basic, CredSSP, Digest, Negotiate, and NegotiateWithImplicitCredential. The protocol that you specify must be enabled in the WS-Management configuration on both the initiating and receiving computers. You can configure additional session options by using New-PSSessionOption to create a new session option object, and then passing it to the \u2013SessionOption parameter of Enter-PSSession or Invoke-Command. Review the Help file for New-PSSessionOption to learn about its capabilities. You can modify the default values, such as the port number and enabled authentication protocols in the WSMan PowerShell drive.","title":"Basic"},{"location":"Advanced/remoting/#remoting-architecture","text":"Remoting starts with the WinRM service. It registers one or more listeners, with each listener accepting incoming traffic through either HTTP or HTTPS. Each listener can be bound to a single local IP address or to multiple IP addresses. There is no dependency on Microsoft Internet Information Services (IIS), which means that IIS doesn't have to be installed for WinRM to function. Incoming traffic includes a packet header that indicates the traffic\u2019s intended destination, or endpoint. In Windows PowerShell, these endpoints are also known as session configurations. Each endpoint is associated with a specific application. When traffic is directed to an endpoint, WinRM starts the associated application, hands off the incoming traffic, and then waits for the application to complete its task. The application can pass data back to WinRM, and WinRM transmits the data back to the originating computer. In a Windows PowerShell scenario, you would send commands to WinRM, which then runs the commands. The process is listed as Wsmprovhost in the remote computer\u2019s process list. Windows PowerShell would then run those commands and convert the resulting objects (if there are any) into XML. The XML text stream is then handed back to WinRM, which transmits it to the originating computer. Windows PowerShell on the remote computer translates the XML back into static objects. This enables the command results to behave much like any other objects within the Windows PowerShell pipeline. Windows PowerShell can register multiple endpoints or session configurations with WinRM. In fact, a 64-bit operating system will register an endpoint for both the 64-bit Windows PowerShell host and the 32-bit host, by default. You also can create your own custom endpoints that have highly precise permissions and capabilities assigned to them.","title":"Remoting Architecture"},{"location":"Advanced/remoting/#without-configuration","text":"Many Windows PowerShell cmdlets have the ComputerName parameter that enables you to collect data and change settings on one or more remote computers. These cmdlets use varying communication protocols and work on all Windows operating systems without any special configuration. These cmdlets include: Restart-Computer Test-Connection Clear-EventLog Get-EventLog Get-HotFix Get-Process Get-Service Set-Service Get-WinEvent Get-WmiObject Typically, cmdlets that support remoting without special configuration have the ComputerName parameter and don't have the Session parameter. To find these cmdlets in your session, enter: Get-Command | where { $_ . parameters . keys -contains \"ComputerName\" -and $_ . parameters . keys -notcontains \"Session\" }","title":"Without Configuration"},{"location":"Advanced/remoting/#over-ssh","text":"PowerShell remoting normally uses WinRM for connection negotiation and data transport. SSH is now available for Linux and Windows platforms and allows true multiplatform PowerShell remoting. WinRM provides a robust hosting model for PowerShell remote sessions. SSH-based remoting doesn't currently support remote endpoint configuration and Just Enough Administration (JEA). SSH remoting offers basic PowerShell session remoting between Windows and Linux computers. SSH remoting creates a PowerShell host process on the target computer as an SSH subsystem. Microsoft plans to eventually implement a general hosting model similar to WinRM to support endpoint configuration and JEA. The New-PSSession, Enter-PSSession, and Invoke-Command cmdlets now have a new parameter set to support this new remoting connection. To use PowerShell remoting over SSH, you must install PowerShell 6 or newer and SSH on all computers. Then, you must install both the SSH client (ssh.exe) and server (sshd.exe) executables so that you can remote to and from the computers. OpenSSH for Windows is available starting with Windows 10 build 1809 and Windows Server 2019. For Linux, install the version of SSH (including the sshd.exe server) that's appropriate for your platform. You also need to install the current version of PowerShell from GitHub to ensure that the SSH remoting feature is available. You should configure the SSH server to create an SSH subsystem to host a PowerShell process on the remote computer. You also need to enable either password or key-based authentication.","title":"Over SSH"},{"location":"Advanced/remoting/#compare-remoting-with-remote-connectivity","text":"Remoting is the name of a specific Windows PowerShell feature, not to be confused with the more generic concept of remote connectivity. Remoting is a generalized way to transmit any command to a remote computer so it runs locally on that computer. The command that you run doesn't have to be available on the computer that initiates the connection. Only the remote computers must be able to run it. The purpose of remoting is to reduce or eliminate the need for individual command authors to code their own communications protocols. Many command authors are already required to do this to ship their products. This is why many different protocols and technologies are currently in use. Many commands implement their own communications protocols, although in the future many of them might instead be changed to use remoting. For example, Get-WmiObject uses RPCs, whereas Get-Process communicates with the computer\u2019s Remote Registry service. Microsoft Exchange Server commands have their own communications channels, and Active Directory commands communicate with a specific web service gateway by using their own protocol. All these other forms of communication might have unique firewall requirements and might require specific configurations to be in place to operate.","title":"Compare Remoting with Remote Connectivity"},{"location":"Advanced/remoting/#enabling-remoting","text":"It's important to understand that you need to enable Windows PowerShell remoting only on computers that will receive incoming connections. No configuration is necessary to enable outgoing communications, except for making sure that any local firewall will allow the outgoing traffic.","title":"Enabling Remoting"},{"location":"Advanced/remoting/#manually","text":"PowerShell remoting is enabled by default on Windows Server platforms. You can enable PowerShell remoting on other supported Windows versions, and you can also re-enable remoting if it becomes disabled. To manually enable Windows PowerShell remoting on a computer, run the Windows PowerShell Enable-PSRemoting cmdlet. This is a persistent change that you can disable later by running Disable-PSRemoting. Note that this task requires the privileges granted to local Administrators group. The Enable-PSRemoting cmdlet performs the following operations: Runs the Set-WSManQuickConfig cmdlet, which in turn performs the following tasks: Starts the WinRM service. Sets the startup type on the WinRM service to Automatic. Creates a listener to accept requests on any IP address. Enables a firewall exception for WS-Management communications. Creates the simple-name and long-name session endpoint configurations, if needed. Enables all session configurations. Changes the security descriptor of all session configurations to allow remote access. Restarts the WinRM service to make the preceding changes effective. This command will fail on client computers where one or more network connections are set to Public instead of Work or Home. You can override this failure by adding the \u2013SkipNetworkProfileCheck parameter. However, be aware that Windows Firewall won't allow exceptions when you're connected to a Public network. The Set-WSManQuickConfig cmdlet doesn't affect remote endpoint configurations created by Windows PowerShell. It only affects endpoints created with PowerShell version 6 and newer. To enable and disable PowerShell remoting endpoints that are hosted by Windows PowerShell, run the Enable-PSRemoting cmdlet from within a Windows PowerShell session.","title":"Manually"},{"location":"Advanced/remoting/#by-using-a-gpo","text":"Many organizations will prefer to centrally control Windows PowerShell remoting enablement and settings through GPOs. Microsoft supports this capability. You must set up various settings in a GPO to duplicate the steps taken by Enable-PSRemoting. To enable remoting by using Group Policy, you should configure the Allow Remote Server Management Through WinRM policy setting in the appropriate GPO. This setting also allows you to filter IP addresses from which remote connections can be initiated. In addition to configuring this policy, you should also configure appropriate firewall exceptions, as described earlier.","title":"By Using a GPO"},{"location":"Advanced/remoting/#common-remoting-techniques","text":"The Enter-PSSession and Invoke-Command commands support several parameters that you can use to change common connection options. These parameters include: \u2013Port. Specifies an alternate TCP port for the connection. Use this parameter when the computer to which you're connecting is listening on a port other than the default 5985 (HTTP) or 5986 (HTTPS). Be aware that you can, locally or through Group Policy, configure a different port as a permanent new default. \u2013UseSSL. Instructs Windows PowerShell to use HTTPS instead of HTTP. \u2013Credential. Specifies an alternative credential for the connection. This credential will be validated by the remote computer and must have sufficient privileges and permissions to perform whatever tasks you intend to perform on the remote computer. \u2013ConfigurationName. Connects to an endpoint (session configuration) other than the default endpoint. For example, you can specify microsoft.powershell32 to connect to the remote computer\u2019s 32-bit Windows PowerShell endpoint. \u2013Authentication. Specifies an authentication protocol. The default is Kerberos authentication, but other options include Basic, CredSSP, Digest, Negotiate, and NegotiateWithImplicitCredential. The protocol that you specify must be enabled in the WS-Management configuration on both the initiating and receiving computers. You can configure additional session options by using New-PSSessionOption to create a new session option object, and then passing it to the \u2013SessionOption parameter of Enter-PSSession or Invoke-Command. Review the Help file for New-PSSessionOption to learn about its capabilities. You can modify the default values, such as the port number and enabled authentication protocols in the WSMan PowerShell drive.","title":"Common Remoting Techniques"},{"location":"Advanced/st-drives/","text":"A PowerShell drive, or drive, is a connection to a data store. Each PowerShell drive uses a single PowerShell provider to connect to a data store. The PowerShell drive has all the capabilities of the PowerShell provider that it uses to make the connection. Names identify drives in Windows PowerShell. Drives can consist of a single letter. Single-letter drive names typically connect to a FileSystem drive. For example, drive C connects to the physical drive C of a computer. However, names also can consist of more than one character. For example, the drive HKCU connects to the HKEY_CURRENT_USER registry hive. To create a new connection, you use the New-PSDrive cmdlet. You must specify a unique drive name, the root location for the new drive, and the PowerShell provider that will make the connection. Depending on the PowerShell provider's capabilities, you might also specify alternative credentials and other options. Windows PowerShell always starts a new session with the following drives: Registry drives HKLM and HKCU Local hard drives, such as drive C Windows PowerShell storage drives Variable, Function, and Alias Web Services for Management (WS-Management) settings drive WSMan Environment variables drive Env Certificate store drive CERT You can review a list of drives by running the Get-PSDrive cmdlet. Drive names don't include a colon. Drive name examples include Variable and Alias. However, when you want to refer to a drive as a path, include a colon. For example, Variable: refers to the path to the Variable drive, just as C: refers to the path to drive C. Cmdlets such as New-PSDrive require a drive name, but when using these commands, don't include a colon in the drive name. PowerShell Drive Cmdlets Because Windows PowerShell creates PowerShell drives for local drives (such as drive C), you might already be using some of the cmdlets associated with PowerShell drives without realizing it. PowerShell drives contain items that contain child items or item properties. The Windows PowerShell cmdlet names that work with PowerShell drive objects use the nouns Item, ChildItem, and ItemProperty. You can use the Get-Command cmdlet with the -Noun parameter to review a list of commands that work on each PowerShell drive object. You can also use Get-Help to review the help for each command. The following table describes the verbs that are associated with common PSDrive cmdlets. Verb Description New Creates a new item or item property. Set Sets the value of an item or item property. Get Displays properties of an item or child item, or value of an item property. Clear Clears the value of an item or item property. Copy Copies an item or item property from one location to another. Move Moves an item or item property from one location to another. Remove Deletes an item or item property. Rename Renames an item or item property. Invoke Performs the default action that's associated with an item. The items in the various PowerShell drives behave differently. Although these commands work in all PowerShell drives, how the verbs act on the items in each PowerShell drive might vary. Additionally, other commands might work with those items. The other topics in this module describe how to work with specific PowerShell drives. When you use commands that have the Item, ChildItem, and ItemProperty nouns, you typically specify a path to tell the command what item or items you want to manipulate. Most of these commands have two parameters for paths: \u2013Path. This typically interprets the asterisk ( ) and the question mark (?) as wildcard characters. In other words, the path .txt refers to all files ending in \u201c.txt.\u201d This approach works correctly in the file system because the file system doesn't allow item names to contain the asterisk or question mark characters. \u2013LiteralPath. This parameter treats all characters as literals and doesn't interpret any character as a wildcard. The literal path .txt means the item named \u201c.txt.\u201d This approach is useful in drives where the asterisk and question mark characters are allowed in item names, such as in the registry. Working with PowerShell drive locations In addition to the commands for working with PowerShell drive items and item properties, there are also commands for working with PowerShell drive working locations. Working locations are paths within PowerShell drives to items that can have child items, such as a file system folder or registry path. The commands that manage PowerShell drive locations use the Location noun and include those described in the following table. Command Description Get-Location Displays the current working location. Set-Location Sets the current working location. Push-Location Adds a location to the top of a location stack. Pop-Location Changes the current location to the location at the top of a location stack. The Push-Location and Pop-Location cmdlets are the equivalent of the pushd and popd commands in the Windows Commamd Prompt (cmd.exe) console. In PowerShell, pushd and popd are aliases for those cmdlets. Manage the FileSystem Administrators who are familiar with using the Windows Command Prompt (cmd.exe) most likely know commands to manage a file system. Common cmd.exe commands include Dir, Move, Ren, RmDir, Del, Copy, MkDir, and Cd. In Windows PowerShell, these common commands are provided as aliases or functions that map to equivalent PowerShell drive cmdlets. You can use the Get-Alias or Get-Command cmdlets to identify the cmdlets that map to these aliases and functions. Keep in mind that the aliases and functions aren't exact duplicates of the original cmd.exe commands, but instead the syntax of an alias matches the corresponding cmdlet. For example, the Dir command is an alias for the Get-ChildItem cmdlet. To obtain a directory listing that includes subdirectories, you run the Get-ChildItem \u2013Recurse command. The parameters are the same whether you decide to use the cmdlet name or the alias. That means that you can run the Dir \u2013Recurse command, but not Dir /s as you would when using Windows Command Prompt. Because Windows PowerShell accepts a slash (/) or backslash () as a path separator, Windows PowerShell interprets Dir /s to display a directory listing for the folder named s. If a folder named s exists, the command appears to work and doesn't display an error. If no such folder exists, it displays an error. Moving within the file system You can move within the file system by using the Set-Location cmdlet. This cmdlet functions similar to the Windows Command Prompt command Cd. When using it, you can specify either an absolute or a relative path. For example, Set-Location C:\\Users changes to the C:\\Users folder. Set-Location Temp changes to the Temp folder that's one level down from the current directory. Create new files or folders You can create new files and folders by using the New-Item cmdlet. You include the -Path parameter to define the name and location, and the -ItemType parameter to specify whether you want to create a file or directory. Delete files or folders You can remove files or folders with the Remove-Item cmdlet and the positional -Path parameter. To delete folders that contain files, you need to include the -Recurse switch so that the child file items are also deleted. Otherwise, or you'll be asked to confirm the action. Find and enumerate files or folders Use the Get-Item cmdlet and the -Path parameter to retrieve a single file or folder. You can also retrieve the children of an item by including the * wildcard in the path. For example, the Get-Item * command returns all files and folders in the current directory. The Get-Item * command is equivalent to the Get-ChildItem cmdlet, which returns all the children of a specified path. You can use the Get-ChildItem cmdlet with the -Recurse switch to enumerate through child files and folders. The FileSystem provider also supports the -Exclude, -Include, and -Filter parameters. These modify the value of the -Path parameter and specify file and folder names to include or exclude in the retrieval process. Manage The Registry Experienced system administrators are familiar with the graphical Registry Editor, which they can use to manage registry keys, entries, and values. However, you can also manage the registry by using Windows PowerShell and the Registry provider. You can use the New-PSDrive cmdlet to create PowerShell drives for any part of the registry. PowerShell uses the Registry provider to create two PowerShell drives automatically: HKLM. Represents the HKEY_LOCAL_MACHINE registry hive. HKCU. Represents the HKEY_LOCAL_USER registry hive. You access registry keys by using cmdlets with the Item and ChildItem nouns, whereas you access entries and values by using cmdlets with the ItemProperty and ItemPropertyValue nouns. This is because PowerShell considers registry entries to be properties of a key item. To return all the registry keys under the HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion path, run the following command: Get-ChildItem HKLM :\\ SOFTWARE \\ Microsoft \\ Windows \\ CurrentVersion Within the registry, a registry key is equivalent to a folder within a file system that's used to organize information. The information used by apps is stored in registry values. The value name is a unique identifier for the value, and the value data is the information used by apps. For example, to return the registry values under the HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run path, run the following command: Get-ItemProperty HKLM :\\ SOFTWARE \\ Microsoft \\ Windows \\ CurrentVersion \\ Run You can use the Get-ItemPropertyValue cmdlet to obtain the value of a specific registry entry. For example, if you want to return the path to the Windows Defender executable identified by the value WindowsDefender entry, run the following command: Get-ItemPropertyValue HKLM :\\ SOFTWARE \\ Microsoft \\ Windows \\ CurrentVersion \\ Run -Name WindowsDefender The Registry provider doesn't support the Invoke-Item cmdlet. There's no default action for registry keys, entries, or values. The Registry provider supports a dynamic parameter, -Type, for the *-ItemProperty cmdlets that are unique to the Registry provider. The following table lists valid parameter values and their equivalent registry data types. Parameter value Registry data type String REG_SZ ExpandString REG_EXPAND_SZ Binary REG_BINARY DWord REG_DWORD MultiString REG_MULTI_SZ QWord REG_QWORD Unknown Unsupported types such as REG_RESOURCE_LIST The Registry provider supports transactions that allow you to manage multiple commands as a single unit. The commands in a transaction will either all be committed (completed) or the results will be rolled back (undone). This feature allows you to set multiple registry values together without worrying that some of the settings will be updated successfully while others might fail. Use the -UseTransaction parameter to include a command in a transaction. For more information about transactions in Windows PowerShell, refer to the about_Transactions help topic. Remember to back up your registry settings before you attempt to modify registry keys and values. You can export registry settings to a file by using the reg.exe command. Work with certificates If you've reviewed or managed security certificates on a client or server computer, you've probably used the Certificates snap-in for the Microsoft Management Console (MMC). The Certificates snap-in enables you to browse the certificates stores on local or remote computers. The Windows PowerShell Certificates provider also allows you to review and manage security certificates. The Certificates provider creates a PowerShell drive named Cert. The Cert drive always has at least two high-level store locations that group certificates for the users and the local computer. These locations are CurrentUser and LocalMachine. The certificates specific to the user or computer are in the My subfolder, represented by the Cert:\\CurrentUser\\My notation. The Certificates provider supports the Get, Set, Move, New, Remove, and Invoke verbs in combination with the Item and ChildItem nouns. (Note that the ItemProperty noun is not supported.) All *-Location commands are also supported. The Invoke-Item cmdlet in combination with the Certificates provider opens the MMC with the Certificates snap-in automatically loaded. The Get-ChildItem command has various dynamic parameters that are unique to the Certificate provider. These parameters include: -CodeSigningCert. Gets certificates that can be used for code signing. -DocumentEncryptionCert. Gets certificates for document encryption. -DnsName. Gets certificates with the domain name in the DNSNameList property of the certificate. This parameter accepts wildcards. -EKU. Gets certificates with the specified text in the EnhancedKeyUsageList property. This parameter supports wildcards. -ExpiringInDays. Gets certificates that are expiring within the specified number of days. -SSLServerAuthentication. Gets only Secure Sockets Layer (SSL) server certificates. There are also many certificate management cmdlets in the pki module that don't require you to use the Cert drive. For example, to create a self-signed certificate for the server webapp.contoso.com, use the following code: New-SelfSignedCertificate -DnsName \"webapp.contoso.com\" -CertStoreLocation \"Cert:\\LocalMachine\\My\" For a list of certificate management cmdlets in the pki module, run Get-Command -Module pki. Other PowerShell Drives In addition to the file system drives, the registry drives, and the Cert drive, Windows PowerShell includes other drives: Alias. Review and manage Windows PowerShell aliases. Env. Review and manage Windows environment variables. Function. Review and manage Windows PowerShell functions. Variable. Review and manage Windows PowerShell variables. WSMan. Review and manage WS-Management configurations. There are many providers included with other modules that can create PowerShell drives. For example, the process of installing management tools for Windows Server roles often includes additional drives such as: AD. This drive is created by the ActiveDirectory provider, which is part of the ActiveDirectory module included with the Remote Server Administration Tools (RSAT). The ActiveDirectory provider supports reviewing and managing AD DS database contents, such as user and computer accounts. IIS. This drive is created by the WebAdministration provider, which is part of the WebAdministration module that's included with IIS management tools. The WebAdministration provider allows you to review and manage application pools, websites, web applications, and virtual directories. The ActiveDirectory module includes many cmdlets for managing Active Directory objects. To review the cmdlets in the ActiveDirectory module, run Get-Command -Module ActiveDirectory. The WebAdministration module includes many cmdlets for managing IIS. To review the cmdlets in the WebAdministration module, run Get-Command -Module WebAdministration. These additional drives support using most of the standard provider verbs and nouns. There might also be specific cmdlets that can perform the same functions. For instance, you can use the Get-Alias cmdlet or the following provider-based command to return a list of all aliases in the current Windows PowerShell session: In some cases, there are no equivalent cmdlets for a provider-based command. For example, there's no Remove-Alias cmdlet that deletes an alias, but you can use either of the following commands to delete an alias named MyAlias: Get-Item -Path Alias : In some cases, there are no equivalent cmdlets for a provider-based command. For example, there's no Remove-Alias cmdlet that deletes an alias, but you can use either of the following commands to delete an alias named MyAlias: Remove-Item -Path Alias : MyAlias Clear-Item -Path Alias : MyAlias the providers used to create these drives can have dynamic parameters or properties associated with them. The Alias provider, for example, includes the dynamic parameter -Options, which you can use to specify the Options property of an alias. To understand what you can do with an item that's accessible through a drive, you should review the help for the provider that's used to create the drive. In the help, you can identify any dynamic parameters or properties. You can identify the provider used to create a drive by using the Get-PSDrive cmdlet. You can use the Get-Help cmdlet to review the help available for the provider. For example, you could use the command to review help for the Alias provider: Get-Help About_Alias_Provider","title":"Drives"},{"location":"Advanced/st-drives/#powershell-drive-cmdlets","text":"Because Windows PowerShell creates PowerShell drives for local drives (such as drive C), you might already be using some of the cmdlets associated with PowerShell drives without realizing it. PowerShell drives contain items that contain child items or item properties. The Windows PowerShell cmdlet names that work with PowerShell drive objects use the nouns Item, ChildItem, and ItemProperty. You can use the Get-Command cmdlet with the -Noun parameter to review a list of commands that work on each PowerShell drive object. You can also use Get-Help to review the help for each command. The following table describes the verbs that are associated with common PSDrive cmdlets. Verb Description New Creates a new item or item property. Set Sets the value of an item or item property. Get Displays properties of an item or child item, or value of an item property. Clear Clears the value of an item or item property. Copy Copies an item or item property from one location to another. Move Moves an item or item property from one location to another. Remove Deletes an item or item property. Rename Renames an item or item property. Invoke Performs the default action that's associated with an item. The items in the various PowerShell drives behave differently. Although these commands work in all PowerShell drives, how the verbs act on the items in each PowerShell drive might vary. Additionally, other commands might work with those items. The other topics in this module describe how to work with specific PowerShell drives. When you use commands that have the Item, ChildItem, and ItemProperty nouns, you typically specify a path to tell the command what item or items you want to manipulate. Most of these commands have two parameters for paths: \u2013Path. This typically interprets the asterisk ( ) and the question mark (?) as wildcard characters. In other words, the path .txt refers to all files ending in \u201c.txt.\u201d This approach works correctly in the file system because the file system doesn't allow item names to contain the asterisk or question mark characters. \u2013LiteralPath. This parameter treats all characters as literals and doesn't interpret any character as a wildcard. The literal path .txt means the item named \u201c.txt.\u201d This approach is useful in drives where the asterisk and question mark characters are allowed in item names, such as in the registry.","title":"PowerShell Drive Cmdlets"},{"location":"Advanced/st-drives/#working-with-powershell-drive-locations","text":"In addition to the commands for working with PowerShell drive items and item properties, there are also commands for working with PowerShell drive working locations. Working locations are paths within PowerShell drives to items that can have child items, such as a file system folder or registry path. The commands that manage PowerShell drive locations use the Location noun and include those described in the following table. Command Description Get-Location Displays the current working location. Set-Location Sets the current working location. Push-Location Adds a location to the top of a location stack. Pop-Location Changes the current location to the location at the top of a location stack. The Push-Location and Pop-Location cmdlets are the equivalent of the pushd and popd commands in the Windows Commamd Prompt (cmd.exe) console. In PowerShell, pushd and popd are aliases for those cmdlets.","title":"Working with PowerShell drive locations"},{"location":"Advanced/st-drives/#manage-the-filesystem","text":"Administrators who are familiar with using the Windows Command Prompt (cmd.exe) most likely know commands to manage a file system. Common cmd.exe commands include Dir, Move, Ren, RmDir, Del, Copy, MkDir, and Cd. In Windows PowerShell, these common commands are provided as aliases or functions that map to equivalent PowerShell drive cmdlets. You can use the Get-Alias or Get-Command cmdlets to identify the cmdlets that map to these aliases and functions. Keep in mind that the aliases and functions aren't exact duplicates of the original cmd.exe commands, but instead the syntax of an alias matches the corresponding cmdlet. For example, the Dir command is an alias for the Get-ChildItem cmdlet. To obtain a directory listing that includes subdirectories, you run the Get-ChildItem \u2013Recurse command. The parameters are the same whether you decide to use the cmdlet name or the alias. That means that you can run the Dir \u2013Recurse command, but not Dir /s as you would when using Windows Command Prompt. Because Windows PowerShell accepts a slash (/) or backslash () as a path separator, Windows PowerShell interprets Dir /s to display a directory listing for the folder named s. If a folder named s exists, the command appears to work and doesn't display an error. If no such folder exists, it displays an error.","title":"Manage the FileSystem"},{"location":"Advanced/st-drives/#moving-within-the-file-system","text":"You can move within the file system by using the Set-Location cmdlet. This cmdlet functions similar to the Windows Command Prompt command Cd. When using it, you can specify either an absolute or a relative path. For example, Set-Location C:\\Users changes to the C:\\Users folder. Set-Location Temp changes to the Temp folder that's one level down from the current directory.","title":"Moving within the file system"},{"location":"Advanced/st-drives/#create-new-files-or-folders","text":"You can create new files and folders by using the New-Item cmdlet. You include the -Path parameter to define the name and location, and the -ItemType parameter to specify whether you want to create a file or directory.","title":"Create new files or folders"},{"location":"Advanced/st-drives/#delete-files-or-folders","text":"You can remove files or folders with the Remove-Item cmdlet and the positional -Path parameter. To delete folders that contain files, you need to include the -Recurse switch so that the child file items are also deleted. Otherwise, or you'll be asked to confirm the action.","title":"Delete files or folders"},{"location":"Advanced/st-drives/#find-and-enumerate-files-or-folders","text":"Use the Get-Item cmdlet and the -Path parameter to retrieve a single file or folder. You can also retrieve the children of an item by including the * wildcard in the path. For example, the Get-Item * command returns all files and folders in the current directory. The Get-Item * command is equivalent to the Get-ChildItem cmdlet, which returns all the children of a specified path. You can use the Get-ChildItem cmdlet with the -Recurse switch to enumerate through child files and folders. The FileSystem provider also supports the -Exclude, -Include, and -Filter parameters. These modify the value of the -Path parameter and specify file and folder names to include or exclude in the retrieval process.","title":"Find and enumerate files or folders"},{"location":"Advanced/st-drives/#manage-the-registry","text":"Experienced system administrators are familiar with the graphical Registry Editor, which they can use to manage registry keys, entries, and values. However, you can also manage the registry by using Windows PowerShell and the Registry provider. You can use the New-PSDrive cmdlet to create PowerShell drives for any part of the registry. PowerShell uses the Registry provider to create two PowerShell drives automatically: HKLM. Represents the HKEY_LOCAL_MACHINE registry hive. HKCU. Represents the HKEY_LOCAL_USER registry hive. You access registry keys by using cmdlets with the Item and ChildItem nouns, whereas you access entries and values by using cmdlets with the ItemProperty and ItemPropertyValue nouns. This is because PowerShell considers registry entries to be properties of a key item. To return all the registry keys under the HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion path, run the following command: Get-ChildItem HKLM :\\ SOFTWARE \\ Microsoft \\ Windows \\ CurrentVersion Within the registry, a registry key is equivalent to a folder within a file system that's used to organize information. The information used by apps is stored in registry values. The value name is a unique identifier for the value, and the value data is the information used by apps. For example, to return the registry values under the HKLM\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run path, run the following command: Get-ItemProperty HKLM :\\ SOFTWARE \\ Microsoft \\ Windows \\ CurrentVersion \\ Run You can use the Get-ItemPropertyValue cmdlet to obtain the value of a specific registry entry. For example, if you want to return the path to the Windows Defender executable identified by the value WindowsDefender entry, run the following command: Get-ItemPropertyValue HKLM :\\ SOFTWARE \\ Microsoft \\ Windows \\ CurrentVersion \\ Run -Name WindowsDefender The Registry provider doesn't support the Invoke-Item cmdlet. There's no default action for registry keys, entries, or values. The Registry provider supports a dynamic parameter, -Type, for the *-ItemProperty cmdlets that are unique to the Registry provider. The following table lists valid parameter values and their equivalent registry data types. Parameter value Registry data type String REG_SZ ExpandString REG_EXPAND_SZ Binary REG_BINARY DWord REG_DWORD MultiString REG_MULTI_SZ QWord REG_QWORD Unknown Unsupported types such as REG_RESOURCE_LIST The Registry provider supports transactions that allow you to manage multiple commands as a single unit. The commands in a transaction will either all be committed (completed) or the results will be rolled back (undone). This feature allows you to set multiple registry values together without worrying that some of the settings will be updated successfully while others might fail. Use the -UseTransaction parameter to include a command in a transaction. For more information about transactions in Windows PowerShell, refer to the about_Transactions help topic. Remember to back up your registry settings before you attempt to modify registry keys and values. You can export registry settings to a file by using the reg.exe command.","title":"Manage The Registry"},{"location":"Advanced/st-drives/#work-with-certificates","text":"If you've reviewed or managed security certificates on a client or server computer, you've probably used the Certificates snap-in for the Microsoft Management Console (MMC). The Certificates snap-in enables you to browse the certificates stores on local or remote computers. The Windows PowerShell Certificates provider also allows you to review and manage security certificates. The Certificates provider creates a PowerShell drive named Cert. The Cert drive always has at least two high-level store locations that group certificates for the users and the local computer. These locations are CurrentUser and LocalMachine. The certificates specific to the user or computer are in the My subfolder, represented by the Cert:\\CurrentUser\\My notation. The Certificates provider supports the Get, Set, Move, New, Remove, and Invoke verbs in combination with the Item and ChildItem nouns. (Note that the ItemProperty noun is not supported.) All *-Location commands are also supported. The Invoke-Item cmdlet in combination with the Certificates provider opens the MMC with the Certificates snap-in automatically loaded. The Get-ChildItem command has various dynamic parameters that are unique to the Certificate provider. These parameters include: -CodeSigningCert. Gets certificates that can be used for code signing. -DocumentEncryptionCert. Gets certificates for document encryption. -DnsName. Gets certificates with the domain name in the DNSNameList property of the certificate. This parameter accepts wildcards. -EKU. Gets certificates with the specified text in the EnhancedKeyUsageList property. This parameter supports wildcards. -ExpiringInDays. Gets certificates that are expiring within the specified number of days. -SSLServerAuthentication. Gets only Secure Sockets Layer (SSL) server certificates. There are also many certificate management cmdlets in the pki module that don't require you to use the Cert drive. For example, to create a self-signed certificate for the server webapp.contoso.com, use the following code: New-SelfSignedCertificate -DnsName \"webapp.contoso.com\" -CertStoreLocation \"Cert:\\LocalMachine\\My\" For a list of certificate management cmdlets in the pki module, run Get-Command -Module pki.","title":"Work with certificates"},{"location":"Advanced/st-drives/#other-powershell-drives","text":"In addition to the file system drives, the registry drives, and the Cert drive, Windows PowerShell includes other drives: Alias. Review and manage Windows PowerShell aliases. Env. Review and manage Windows environment variables. Function. Review and manage Windows PowerShell functions. Variable. Review and manage Windows PowerShell variables. WSMan. Review and manage WS-Management configurations. There are many providers included with other modules that can create PowerShell drives. For example, the process of installing management tools for Windows Server roles often includes additional drives such as: AD. This drive is created by the ActiveDirectory provider, which is part of the ActiveDirectory module included with the Remote Server Administration Tools (RSAT). The ActiveDirectory provider supports reviewing and managing AD DS database contents, such as user and computer accounts. IIS. This drive is created by the WebAdministration provider, which is part of the WebAdministration module that's included with IIS management tools. The WebAdministration provider allows you to review and manage application pools, websites, web applications, and virtual directories. The ActiveDirectory module includes many cmdlets for managing Active Directory objects. To review the cmdlets in the ActiveDirectory module, run Get-Command -Module ActiveDirectory. The WebAdministration module includes many cmdlets for managing IIS. To review the cmdlets in the WebAdministration module, run Get-Command -Module WebAdministration. These additional drives support using most of the standard provider verbs and nouns. There might also be specific cmdlets that can perform the same functions. For instance, you can use the Get-Alias cmdlet or the following provider-based command to return a list of all aliases in the current Windows PowerShell session: In some cases, there are no equivalent cmdlets for a provider-based command. For example, there's no Remove-Alias cmdlet that deletes an alias, but you can use either of the following commands to delete an alias named MyAlias: Get-Item -Path Alias : In some cases, there are no equivalent cmdlets for a provider-based command. For example, there's no Remove-Alias cmdlet that deletes an alias, but you can use either of the following commands to delete an alias named MyAlias: Remove-Item -Path Alias : MyAlias Clear-Item -Path Alias : MyAlias the providers used to create these drives can have dynamic parameters or properties associated with them. The Alias provider, for example, includes the dynamic parameter -Options, which you can use to specify the Options property of an alias. To understand what you can do with an item that's accessible through a drive, you should review the help for the provider that's used to create the drive. In the help, you can identify any dynamic parameters or properties. You can identify the provider used to create a drive by using the Get-PSDrive cmdlet. You can use the Get-Help cmdlet to review the help available for the provider. For example, you could use the command to review help for the Alias provider: Get-Help About_Alias_Provider","title":"Other PowerShell Drives"},{"location":"Advanced/st-provide/","text":"PowerShell providers are adapters that connect Windows PowerShell to data stores. They offer an easier-to-understand and consistent interface for working with data stores. A PowerShell provider, or just provider, is an adapter that makes some data stores resemble hard drives within Windows PowerShell. Because most administrators are already familiar with managing hard drives using command-line commands, PowerShell providers help those administrators manage other forms of data storage using the same familiar commands. A provider presents data as a hierarchical store. For example, items such as folders can have sub-items that appear as subfolders. Items can also have properties, and providers let you manipulate both items and their properties by using a specific set of commands. Managing a technology by using a provider is more difficult than managing it by using technology-specific commands. Individual commands perform specific actions, and the command name describes what the command does. For example, in Internet Information Services (IIS), the Get-WebSite command retrieves IIS sites. When you use the IIS provider, you run the Get-ChildItem IIS:\\Sites command instead. The advantage of a PowerShell provider is that it's dynamic, which makes it suitable for technologies that are subject to frequent changes. For example, when managing IIS, its provider can accommodate newly introduced Microsoft and third-party IIS add-ins. Even though using a provider to manage dynamic and extensible technologies tends to be more complex, it offers a more consistent approach due to its extensibility. Some common providers include: Registry. Provides access to the registry keys and values. Alias. Provides access to aliases for Windows PowerShell cmdlets. Environment. Provides access to Windows environment variables and their values. FileSystem. Provides access to the files and folders in the file system. Function. Provides access to Windows PowerShell functions loaded into memory. Variable. Provides access to Windows PowerShell variables and their values loaded into memory. Built-in Providers The generic commands that you use to work with providers offer a superset of every feature that a provider might support. For example, the Get-ChildItem command includes the \u2013UseTransaction parameter. However, the only built-in provider that supports the Transactions capability is the Registry provider. If you try to use the -UseTransaction parameter in any other provider, you'll receive an error message. You'll also receive an error message whenever you use a common parameter that the provider doesn't support. Running the Get-PSProvider cmdlet lists the capabilities of each provider that loads into Windows PowerShell. The capabilities of each provider will be different because each provider connects to a different underlying technology. Some important capabilities include: ShouldProcess for providers that can support the \u2013WhatIf and \u2013Confirm parameters. Filter for providers that support filtering. Include for providers that can include items in the data store based on the name. Supports using wildcards. Exclude for providers that can exclude items in the data store based on the name. Supports using wildcards. ExpandWildcards for providers that support wildcards in their paths. Credentials for providers that support alternative credentials. Transactions for providers that support transacted operations. You should always review the capabilities of a provider before you work with it. This helps you avoid unexpected errors when you try to use unsupported capabilities. Access Provider Help ou can display a list of available providers by using the Get-PSProvider cmdlet. Be aware that providers can be added into Windows PowerShell when you load modules, and they don't display until loaded. For example, when you run the Import-Module ActiveDirectory command to load the ActiveDirectory module or use module autoloading when running an Active Directory cmdlet, a PowerShell provider for Active Directory is included. Some providers include help files that you can review. Help files use the naming format about_ProviderName_Provider. For example, the help file for the FileSystem provider is about_FileSystem_Provider. You can review this help file's contents by running the following command: Get-Help about_FileSystem_Provider Cmdlets that work with providers use the nouns Item and ItemProperty. To list cmdlets that work with providers, run the following cmdlets: Get-Command * -Item ,* -ItemProperty Examples for every scenario might not be in commands\u2019 help, because the commands are designed to work with any provider. The intent of provider help is to supplement command help with more specific descriptions and examples.","title":"Providers"},{"location":"Advanced/st-provide/#built-in-providers","text":"The generic commands that you use to work with providers offer a superset of every feature that a provider might support. For example, the Get-ChildItem command includes the \u2013UseTransaction parameter. However, the only built-in provider that supports the Transactions capability is the Registry provider. If you try to use the -UseTransaction parameter in any other provider, you'll receive an error message. You'll also receive an error message whenever you use a common parameter that the provider doesn't support. Running the Get-PSProvider cmdlet lists the capabilities of each provider that loads into Windows PowerShell. The capabilities of each provider will be different because each provider connects to a different underlying technology. Some important capabilities include: ShouldProcess for providers that can support the \u2013WhatIf and \u2013Confirm parameters. Filter for providers that support filtering. Include for providers that can include items in the data store based on the name. Supports using wildcards. Exclude for providers that can exclude items in the data store based on the name. Supports using wildcards. ExpandWildcards for providers that support wildcards in their paths. Credentials for providers that support alternative credentials. Transactions for providers that support transacted operations. You should always review the capabilities of a provider before you work with it. This helps you avoid unexpected errors when you try to use unsupported capabilities.","title":"Built-in Providers"},{"location":"Advanced/st-provide/#access-provider-help","text":"ou can display a list of available providers by using the Get-PSProvider cmdlet. Be aware that providers can be added into Windows PowerShell when you load modules, and they don't display until loaded. For example, when you run the Import-Module ActiveDirectory command to load the ActiveDirectory module or use module autoloading when running an Active Directory cmdlet, a PowerShell provider for Active Directory is included. Some providers include help files that you can review. Help files use the naming format about_ProviderName_Provider. For example, the help file for the FileSystem provider is about_FileSystem_Provider. You can review this help file's contents by running the following command: Get-Help about_FileSystem_Provider Cmdlets that work with providers use the nouns Item and ItemProperty. To list cmdlets that work with providers, run the following cmdlets: Get-Command * -Item ,* -ItemProperty Examples for every scenario might not be in commands\u2019 help, because the commands are designed to work with any provider. The intent of provider help is to supplement command help with more specific descriptions and examples.","title":"Access Provider Help"},{"location":"Exercises/Exercises1/","text":"Exercises on Get-Help usage Verify if there are cmdlets that allow converting the output of another cmdlet to HTML format. Click me for proposed solution help * html * Verify which cmdlets allow directing output to a printer or a file. Click me for proposed solution Out-Printer Out-File Verify how many cmdlets are used to manage processes. Click me for proposed solution help * Process * Which cmdlet can be used to write an entry to an event log? Click me for proposed solution Write-EventLog Which cmdlets can be used to manage aliases? Click me for proposed solution help * alias * Is there a way to keep a transcript of a PowerShell session and save it to a file? Click me for proposed solution Start-Transcript -Path \"C:\\transcripts\\transcript0.txt\" -NoClobber How can you get the 100 most recent records from the SECURITY event log on a system? Click me for proposed solution Get-EventLog -LogName SECURITY -Newest 100 Is there a way to obtain the list of services that are running on a remote computer? Click me for proposed solution Answer: Yes, you can use the Get-Service cmdlet with the -ComputerName parameter followed by the name of the remote computer to obtain the list of services running on that computer. Example: Get-Service -ComputerName RemoteComputerName Is there a way to obtain the list of services that are running on a remote computer? Click me for proposed solution Answer: Yes, you can use the Get-Process cmdlet with the -ComputerName parameter followed by the name of the remote computer to obtain the list of processes running on that computer. Example: Get-Process -ComputerName RemoteComputerName Review the help of the Out-File cmdlet. What is the line size used by this cmdlet by default? Is there a parameter that allows you to change this size? Click me for proposed solution Answer: The line size used by default by the Out-File cmdlet is 80 characters. You can change this size using the -Width parameter followed by the desired width. Example: Get-Process | Out-File -FilePath C :\\ Processes . txt -Width 120 By default, Out-File overwrites the output file if it already exists. Is there a parameter that prevents the overwriting of an existing file? Click me for proposed solution Answer: Yes, the -NoClobber parameter can be used to prevent the overwriting of an existing file. If this parameter is used and the output file already exists, Out-File will not overwrite the file and will instead display an error message. Example: Get-Process | Out-File -FilePath C :\\ Processes . txt -NoClobber","title":"Exercise 1"},{"location":"Exercises/Exercises1/#exercises-on-get-help-usage","text":"Verify if there are cmdlets that allow converting the output of another cmdlet to HTML format. Click me for proposed solution help * html * Verify which cmdlets allow directing output to a printer or a file. Click me for proposed solution Out-Printer Out-File Verify how many cmdlets are used to manage processes. Click me for proposed solution help * Process * Which cmdlet can be used to write an entry to an event log? Click me for proposed solution Write-EventLog Which cmdlets can be used to manage aliases? Click me for proposed solution help * alias * Is there a way to keep a transcript of a PowerShell session and save it to a file? Click me for proposed solution Start-Transcript -Path \"C:\\transcripts\\transcript0.txt\" -NoClobber How can you get the 100 most recent records from the SECURITY event log on a system? Click me for proposed solution Get-EventLog -LogName SECURITY -Newest 100 Is there a way to obtain the list of services that are running on a remote computer? Click me for proposed solution Answer: Yes, you can use the Get-Service cmdlet with the -ComputerName parameter followed by the name of the remote computer to obtain the list of services running on that computer. Example: Get-Service -ComputerName RemoteComputerName Is there a way to obtain the list of services that are running on a remote computer? Click me for proposed solution Answer: Yes, you can use the Get-Process cmdlet with the -ComputerName parameter followed by the name of the remote computer to obtain the list of processes running on that computer. Example: Get-Process -ComputerName RemoteComputerName Review the help of the Out-File cmdlet. What is the line size used by this cmdlet by default? Is there a parameter that allows you to change this size? Click me for proposed solution Answer: The line size used by default by the Out-File cmdlet is 80 characters. You can change this size using the -Width parameter followed by the desired width. Example: Get-Process | Out-File -FilePath C :\\ Processes . txt -Width 120 By default, Out-File overwrites the output file if it already exists. Is there a parameter that prevents the overwriting of an existing file? Click me for proposed solution Answer: Yes, the -NoClobber parameter can be used to prevent the overwriting of an existing file. If this parameter is used and the output file already exists, Out-File will not overwrite the file and will instead display an error message. Example: Get-Process | Out-File -FilePath C :\\ Processes . txt -NoClobber","title":"Exercises on Get-Help usage"},{"location":"Exercises/Exercises2/","text":"Create two similar text files (with one or two different lines). Compare them using diff. Click me for proposed solution ##Create 1st file New-Item -Path . -Name \"file1.txt\" -ItemType \"file\" -Value \"Hello World.\\nBonjour Monde!\" -Force ##Create 2nd file New-Item -Path . -Name \"file2.txt\" -ItemType \"file\" -Value \"Hello World!\\nBonjour Monde.\" -Force ##Find the difference between two files diff -ReferenceObject ( cat file1 . txt ) -DifferenceObject ( cat file2 . txt ) InputObject SideIndicator ----------- ------------- Hello World! => Bonjour Monde. => Hello World. <= Bonjour Monde! <= What happens if you run: get-service | export-csv servicios . csv | out-file Why? Click me for proposed solution The output of the above command is: out-file: Cannot process argument because the value of the \"path\" argument is NULL. Change the value of the \"path\" argument to a non-null value. At line:1 char:42 + get-service | export-csv servicios.csv | out-file + ~~~~~~~~ + CategoryInfo : InvalidArgument: (:) [Out-File], PSArgumentNullException + FullyQualifiedErrorId : ArgumentNull,Microsoft.PowerShell.Commands.OutFileCommand This is because export-csv servicios.csv creates the csv file and has null output, therefore out-file is not necessary. How would you create a file delimited by semicolons (;)? HINT: Use export-csv, but with an additional parameter. Click me for proposed solution ps | epcsv -delimiter \";\" example . csv ##Same as Get-Process | Export-Csv -delimiter \";\" example . csv Export-cliXML and Export-CSV modify the system, because they can create and overwrite files. Is there a parameter that prevents overwriting an existing file? Is there a parameter that allows the command to ask before overwriting a file? Click me for proposed solution To prevent overwriting the file if it already exists, the -NoClobber attribute can be used. Example: The following command will not overwrite the result from point 3 ps | epcsv example . csv -NoClobber To ask for confirmation, use the -Confirm parameter. ps | epcsv -delimiter \";\" example . csv -Confirm Windows uses regional settings, which includes the list separator. In English Windows, the list separator is a comma (,). How do you tell Export-CSV to use the system separator instead of the comma? Click me for proposed solution The cmdlet get-culture obtains system configuration information, such as language and writing information. ps | epcsv test2 . csv -Delimiter (( get-culture ). textInfo . listSeparator ) Using cat (alias of Get-Content), we can see that the output uses ';' as the Spanish list separator. cat .\\ test2 . csv Identify a cmdlet that allows generating a random number. Click me for proposed solution The cmdlet get-random returns a pseudo-random 32-bit integer. Identify a cmdlet that displays the current date and time. Click me for proposed solution The cmdlet get-date returns an object that represents the current date and time, which can be represented in various formats such as Windows or UNIX. What type of object does the cmdlet in question 7 produce? Click me for proposed solution Using the cmdlet gm, we can obtain the elements that make up the object and the type. As seen below, the object is part of the System package and its type is DateTime. Get-Date | gm TypeName : System . DateTime Using the cmdlet in question 7 and select-object, display only the day of the week as follows: DayOfWeek --------- Thursday Click me for proposed solution get-date | select -property \"dayofweek\" DayOfWeek --------- Friday Identify a cmdlet that displays information about patches (hotfixes) installed on the system. Click me for proposed solution The cmdlet that returns a list of system patches is: get-hotfix Using the cmdlet from question 10, display a list of installed patches. Then extend the expression to sort the list by installation date, and display on the screen only the installation date, the user who installed the patch, and the patch ID. Remember to examine the property names. Click me for proposed solution The cmdlet that returns a list of system patches is: get-hotfix | sort -property installedon | select -property installedon , installedby , hotfixid Complement the solution to question 11 so that the system sorts the results by the patch description, and includes the description, patch ID, and installation date in the listing. Write the results to an HTML file. Click me for proposed solution The cmdlet that returns a list of system patches is: get-hotFix | sort -property description | select -property hotfixid , description , installedon | convertto-html | Out-File hotfix . html Display a list of the 50 newest entries from the System event log. Sort the list so that the oldest entries appear first, and entries produced at the same time should be sorted by index number. Show the index number, time, and source for each entry. Write this information to a plain text file. Click me for proposed solution The cmdlet that returns a list of system patches is: get-eventlog -newest 50 -logname system | sort -property index | sort -property timegenerated -descending | select -property index , timegenerated , source > exercise13 . txt","title":"Exercise 2"},{"location":"Exercises/Exercises3/","text":"Show a table that includes only the names of the processes, their IDs, and whether they are responding to Windows (the Responding property shows that). Make the table take up a minimum of horizontal space, but don't allow the information to be truncated. Click me for proposed solution ps | ft -Property name , id , responding -Wrap Display a table that includes the names of the processes and their IDs. Also include columns for physical and virtual memory usage; Express those values \u200b\u200bin megabytes (MB). Click me for proposed solution ps | ft -Property name , id , @{ n = 'vm [MB]' ; e ={ $_ . vm / 1MB -as [INT] }}, @{ n = 'pm [MB]' ; e ={ $_ . pm / 1MB -as [INT] }} Use the cmdlet Get-EventLog to display a list of available event logs (check the help to find the parameter that will allow you to get that information). Format the output as a table that includes the log display name and the retention period. Column headers must be LogName and Per-Retention. Click me for proposed solution get-eventlog -list | ft -property @{ n = 'NombreLog' ; e ={ $_ . log }}, @{ n = 'Per-Retencion' ; e ={ $_ . MinimumRetentionDays }} Display a list of services, so that the services that are started and those that are stopped are grouped together. Those who are initiated must appear first. Click me for proposed solution gsv | sort -property status -descending | ft -groupby status Display a four-column list of all directories that are at the root of drive C: Click me for proposed solution ls 'C:/' | format-wide name -col 4 Create a formatted list of all .exe files in the C:\\Windows directory. The name, version information, and size of the file should be displayed. The size property is called length in Powershell, but for clarity, the column should be called Size in your listing. Click me for proposed solution ls 'C:\\Windows/*.exe' | ft name , @{ n = 'Size' ; e ={ $_ . Length }}, versionInfo -Wrap Import the NetAdapter module (using the Import-Module NetAdapter command). Using the Get-NetAdapter cmdlet, display a list of non-virtual adapters (adapters whose Virtual property is false. The boolean false is represented by Powershell as $False). Click me for proposed solution Get-NetAdapter | ? { $_ . Virtual -eq $False } | fl Import the DnsClient module. Using the Get-DnsClientCache cmdlet, list the A and AAAA records that are in the cache. Tip: If the cache is empty, visit some websites to populate it. Click me for proposed solution Get-DnsClientCache -type 'A' , 'AAAA' | fl Display a list of all .exe files in the C:\\Windows\\System32 directory that are larger than 5 MB. Click me for proposed solution ls 'C:\\Windows\\System32/*.exe' | ? { $_ . length -gt 5MB } | fl Display a list of patches that are security updates. Click me for proposed solution Get-HotFix | ? { $_ . description -eq \"Security Update\" } | fl Display a list of patches that have been installed by the Administrator user, which are updates. If you don't have any, look for user-installed patches System. Click me for proposed solution Get-HotFix | ? { $_ . Description -like \"*Update*\" -and $_ . InstalledBy -like \"*System*\" } | fl Generate a list of all running processes with the name Conhost or Svchost. Click me for proposed solution ps | ? { $_ . Name -eq 'conhost' -or $_ . Name -eq 'svchost' } | fl","title":"Exercise 3"},{"location":"Exercises/Exercises4/","text":"Which class can be used to query the IP address of a network adapter? Does that class have a method to release a DHCP address lease? Click me for proposed solution Get-WmiObject -List | where name -like ' * networkadapter * ## Method to release a DHCP address gwmi Win32_NetworkAdapter | gm | ? { $_ . membertype -like \"method\" } gwmi Win32_NetworkAdapterConfiguration | gm | ? { $_ . membertype -like \"method\" } Display a list of patches using WMI (Microsoft refers to patches as quick-fix engineering). Is the listing different from the one produced by the Get-Hotfix cmdlet? Click me for proposed solution gwmi Win32_QuickFixEngineering ## No difference with get-hotfix cmdlet diff -ReferenceObject ( gwmi Win32_QuickFixEngineering ) -DifferenceObject ( Get-Hotfix ) Using WMI, display a list of services, including their current status, their startup mode, and the accounts they use to login. Click me for proposed solution gwmi win32_service | fl status , startmode , startname Using CIM cmdlets, list all classes in the SecurityCenter2 namespace, which have product as part of the name. Click me for proposed solution get-cimclass -names root \\ SecurityCenter2 | ? cimclassname -like '*product*' Using CIM cmdlets, and the results of the previous exercise, display the names of the antispyware applications installed on the system. You can also check if there are antivirus products installed on the system. Click me for proposed solution ## Antivirus get-ciminstance -names root \\ SecurityCenter2 -class AntiVirusProduct ## Antispyware get-ciminstance -names root \\ SecurityCenter2 -class AntiSpywareProduct","title":"Exercise 4"},{"location":"Install/differences/","text":"Powershell 5 and Powershell ISE PowerShell 5 is a major version of the Windows PowerShell command-line shell and scripting language that was released in February 2016. It was designed primarily for Windows operating systems and provides a powerful tool for automating administrative tasks and managing systems. Some of the key features of PowerShell 5 include: Classes and enums for creating custom types Enhanced debugging support, including the ability to step through scripts and inspect variables Improved security with the introduction of Just Enough Administration (JEA) and PowerShell Scriptblock Logging PowerShell ISE (Integrated Scripting Environment) is an integrated development environment (IDE) that is included with PowerShell 5. It provides a graphical user interface (GUI) for developing, testing, and debugging PowerShell scripts and modules. Some of the key features of PowerShell ISE include: A code editor with syntax highlighting, code folding, and IntelliSense A console pane for executing PowerShell commands and scripts Debugging tools, including breakpoints and variable inspection Integration with version control systems like Git and Team Foundation Server PowerShell ISE was designed to make it easier for developers and system administrators to work with PowerShell scripts and modules, but it has been deprecated in favor of the new PowerShell 7 Integrated Console. The PowerShell 7 Integrated Console provides many of the same features as PowerShell ISE, but in a more modern and flexible interface that can be used on Windows, Linux, and macOS. Key Differences between Powershell 7 and 5 Cross-Platform Support One of the biggest differences between PowerShell 7 and 5 is cross-platform support. While PowerShell 5 was primarily designed for Windows operating systems, PowerShell 7 is designed to work on Windows, Linux, and macOS. This means that you can use PowerShell 7 to manage and automate tasks on a wide variety of systems, making it a more versatile tool. Improved Performance PowerShell 7 is also faster and more efficient than PowerShell 5. This is due in part to the fact that PowerShell 7 uses .NET Core 3.x, which provides better performance than the .NET Framework used by PowerShell 5. In addition, PowerShell 7 includes a number of performance optimizations that make it faster and more responsive. New Features PowerShell 7 includes many new features and improvements over PowerShell 5. Some of the most notable new features include: Pipeline Parallelization : PowerShell 7 can execute commands in parallel on multi-core CPUs, improving performance for certain operations. Ternary Operators : PowerShell 7 introduces a new ternary operator (condition ? true : false) that makes it easier to write concise code. New Data Types : PowerShell 7 adds support for new data types like System.Text.Json.JsonDocument, making it easier to work with JSON data. New cmdlets : PowerShell 7 includes many new cmdlets for managing systems and applications, as well as improved versions of existing cmdlets. Compatibility Finally, it's worth noting that PowerShell 7 is not fully backwards-compatible with PowerShell 5. While most scripts and modules written for PowerShell 5 should work fine in PowerShell 7, there may be some compatibility issues with certain scripts or modules. It's always a good idea to test your scripts and modules in PowerShell 7 before deploying them to production systems. PowerShell 7 Integrated Console in VSCode PowerShell 7 Integrated Console is a new feature in PowerShell 7 that provides many of the same features as PowerShell ISE, but in a more modern and flexible interface that can be used on Windows, Linux, and macOS. Here are some of the key differences between the two: Cross-Platform Support One of the biggest differences between PowerShell 7 Integrated Console and PowerShell ISE is cross-platform support. While PowerShell ISE was primarily designed for Windows operating systems, PowerShell 7 Integrated Console is designed to work on Windows, Linux, and macOS. This means that you can use PowerShell 7 Integrated Console to manage and automate tasks on a wide variety of systems, making it a more versatile tool. Improved Performance PowerShell 7 Integrated Console is also faster and more efficient than PowerShell ISE. This is due in part to the fact that PowerShell 7 uses .NET Core 3.x, which provides better performance than the .NET Framework used by PowerShell ISE. In addition, PowerShell 7 Integrated Console includes a number of performance optimizations that make it faster and more responsive. Features PowerShell 7 Integrated Console includes many of the same features as PowerShell ISE, such as a code editor with syntax highlighting, code folding, and IntelliSense, a console pane for executing PowerShell commands and scripts, and debugging tools like breakpoints and variable inspection. However, PowerShell 7 Integrated Console also includes some new features, such as: Interactive Notebooks : PowerShell 7 Integrated Console includes a new feature called Interactive Notebooks, which provides a way to create and share rich documents that combine text, code, and output. This feature is similar to Jupyter Notebooks in the Python world. Multiple Tabs : PowerShell 7 Integrated Console supports multiple tabs, so you can work on multiple scripts or tasks at the same time within the same window. Improved UI : PowerShell 7 Integrated Console has a modern and flexible user interface that can be customized to suit your needs. Deprecation Finally, it's worth noting that PowerShell ISE has been deprecated in favor of PowerShell 7 Integrated Console. Microsoft has stated that PowerShell ISE will not receive any new features or updates, and it will be removed in future versions of Windows. While PowerShell ISE will still be available in older versions of Windows that include PowerShell 5, it's recommended that you switch to PowerShell 7 Integrated Console for new development and management tasks. Additional Features of VSCode Powershell Extension The PowerShell extension for VSCode includes a number of additional features that aren't available in PowerShell 7 Integrated Console, such as: Code Snippets : The extension provides a library of code snippets that you can use to quickly insert common PowerShell commands and structures into your code. Task Runner : You can use the extension's Task Runner to automate repetitive tasks like running tests, building modules, or deploying scripts. Integrated Source Control : The extension includes support for integrated source control, so you can use Git or another version control system directly from within the VSCode editor. Overall, the PowerShell extension for VSCode provide powerful tools for working with PowerShell scripts and modules.","title":"Versions"},{"location":"Install/differences/#powershell-5-and-powershell-ise","text":"PowerShell 5 is a major version of the Windows PowerShell command-line shell and scripting language that was released in February 2016. It was designed primarily for Windows operating systems and provides a powerful tool for automating administrative tasks and managing systems. Some of the key features of PowerShell 5 include: Classes and enums for creating custom types Enhanced debugging support, including the ability to step through scripts and inspect variables Improved security with the introduction of Just Enough Administration (JEA) and PowerShell Scriptblock Logging PowerShell ISE (Integrated Scripting Environment) is an integrated development environment (IDE) that is included with PowerShell 5. It provides a graphical user interface (GUI) for developing, testing, and debugging PowerShell scripts and modules. Some of the key features of PowerShell ISE include: A code editor with syntax highlighting, code folding, and IntelliSense A console pane for executing PowerShell commands and scripts Debugging tools, including breakpoints and variable inspection Integration with version control systems like Git and Team Foundation Server PowerShell ISE was designed to make it easier for developers and system administrators to work with PowerShell scripts and modules, but it has been deprecated in favor of the new PowerShell 7 Integrated Console. The PowerShell 7 Integrated Console provides many of the same features as PowerShell ISE, but in a more modern and flexible interface that can be used on Windows, Linux, and macOS.","title":"Powershell 5 and Powershell ISE"},{"location":"Install/differences/#key-differences-between-powershell-7-and-5","text":"","title":"Key Differences between Powershell 7 and 5"},{"location":"Install/differences/#cross-platform-support","text":"One of the biggest differences between PowerShell 7 and 5 is cross-platform support. While PowerShell 5 was primarily designed for Windows operating systems, PowerShell 7 is designed to work on Windows, Linux, and macOS. This means that you can use PowerShell 7 to manage and automate tasks on a wide variety of systems, making it a more versatile tool.","title":"Cross-Platform Support"},{"location":"Install/differences/#improved-performance","text":"PowerShell 7 is also faster and more efficient than PowerShell 5. This is due in part to the fact that PowerShell 7 uses .NET Core 3.x, which provides better performance than the .NET Framework used by PowerShell 5. In addition, PowerShell 7 includes a number of performance optimizations that make it faster and more responsive.","title":"Improved Performance"},{"location":"Install/differences/#new-features","text":"PowerShell 7 includes many new features and improvements over PowerShell 5. Some of the most notable new features include: Pipeline Parallelization : PowerShell 7 can execute commands in parallel on multi-core CPUs, improving performance for certain operations. Ternary Operators : PowerShell 7 introduces a new ternary operator (condition ? true : false) that makes it easier to write concise code. New Data Types : PowerShell 7 adds support for new data types like System.Text.Json.JsonDocument, making it easier to work with JSON data. New cmdlets : PowerShell 7 includes many new cmdlets for managing systems and applications, as well as improved versions of existing cmdlets.","title":"New Features"},{"location":"Install/differences/#compatibility","text":"Finally, it's worth noting that PowerShell 7 is not fully backwards-compatible with PowerShell 5. While most scripts and modules written for PowerShell 5 should work fine in PowerShell 7, there may be some compatibility issues with certain scripts or modules. It's always a good idea to test your scripts and modules in PowerShell 7 before deploying them to production systems.","title":"Compatibility"},{"location":"Install/differences/#powershell-7-integrated-console-in-vscode","text":"PowerShell 7 Integrated Console is a new feature in PowerShell 7 that provides many of the same features as PowerShell ISE, but in a more modern and flexible interface that can be used on Windows, Linux, and macOS. Here are some of the key differences between the two:","title":"PowerShell 7 Integrated Console in VSCode"},{"location":"Install/differences/#cross-platform-support_1","text":"One of the biggest differences between PowerShell 7 Integrated Console and PowerShell ISE is cross-platform support. While PowerShell ISE was primarily designed for Windows operating systems, PowerShell 7 Integrated Console is designed to work on Windows, Linux, and macOS. This means that you can use PowerShell 7 Integrated Console to manage and automate tasks on a wide variety of systems, making it a more versatile tool.","title":"Cross-Platform Support"},{"location":"Install/differences/#improved-performance_1","text":"PowerShell 7 Integrated Console is also faster and more efficient than PowerShell ISE. This is due in part to the fact that PowerShell 7 uses .NET Core 3.x, which provides better performance than the .NET Framework used by PowerShell ISE. In addition, PowerShell 7 Integrated Console includes a number of performance optimizations that make it faster and more responsive.","title":"Improved Performance"},{"location":"Install/differences/#features","text":"PowerShell 7 Integrated Console includes many of the same features as PowerShell ISE, such as a code editor with syntax highlighting, code folding, and IntelliSense, a console pane for executing PowerShell commands and scripts, and debugging tools like breakpoints and variable inspection. However, PowerShell 7 Integrated Console also includes some new features, such as: Interactive Notebooks : PowerShell 7 Integrated Console includes a new feature called Interactive Notebooks, which provides a way to create and share rich documents that combine text, code, and output. This feature is similar to Jupyter Notebooks in the Python world. Multiple Tabs : PowerShell 7 Integrated Console supports multiple tabs, so you can work on multiple scripts or tasks at the same time within the same window. Improved UI : PowerShell 7 Integrated Console has a modern and flexible user interface that can be customized to suit your needs.","title":"Features"},{"location":"Install/differences/#deprecation","text":"Finally, it's worth noting that PowerShell ISE has been deprecated in favor of PowerShell 7 Integrated Console. Microsoft has stated that PowerShell ISE will not receive any new features or updates, and it will be removed in future versions of Windows. While PowerShell ISE will still be available in older versions of Windows that include PowerShell 5, it's recommended that you switch to PowerShell 7 Integrated Console for new development and management tasks.","title":"Deprecation"},{"location":"Install/differences/#additional-features-of-vscode-powershell-extension","text":"The PowerShell extension for VSCode includes a number of additional features that aren't available in PowerShell 7 Integrated Console, such as: Code Snippets : The extension provides a library of code snippets that you can use to quickly insert common PowerShell commands and structures into your code. Task Runner : You can use the extension's Task Runner to automate repetitive tasks like running tests, building modules, or deploying scripts. Integrated Source Control : The extension includes support for integrated source control, so you can use Git or another version control system directly from within the VSCode editor. Overall, the PowerShell extension for VSCode provide powerful tools for working with PowerShell scripts and modules.","title":"Additional Features of VSCode Powershell Extension"},{"location":"Install/installation/","text":"PowerShell 7 is the latest major release of PowerShell, and it provides many new features and improvements over previous versions. Here's how to install it on various operating systems: Windows On Windows, you can download the PowerShell 7 installer from the official PowerShell GitHub repository. Choose the MSI installer for your architecture (either x86 or x64) and download the file. Once the installer is downloaded, double-click on the file to start the installation wizard. Follow the on-screen instructions to complete the installation process. After installation is complete, you can open PowerShell 7 from the Start menu or by typing pwsh in the command prompt. Linux On Linux, you can install PowerShell 7 using your distribution's package manager. Here are the commands for some popular distributions: Ubuntu 18.04 and later, and Debian 10 and later: Run the following commands in the terminal: # Update the list of packages sudo apt - get update # Install pre - requisite packages . sudo apt - get install - y wget apt - transport - https software - properties - common # Download the Microsoft repository GPG keys wget - q \"https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/packages-microsoft-prod.deb\" # Register the Microsoft repository GPG keys sudo dpkg - i packages - microsoft - prod . deb # Update the list of packages after we added packages . microsoft . com sudo apt - get update # Install PowerShell sudo apt - get install - y powershell # Start PowerShell pwsh macOS On macOS, you can install PowerShell 7 using Homebrew, a popular package manager for macOS. Run the following command in the terminal: brew install -- cask powershell After installation is complete, you can open PowerShell 7 from the Launchpad or by typing pwsh in the terminal.","title":"Multiplatform"},{"location":"Install/installation/#windows","text":"On Windows, you can download the PowerShell 7 installer from the official PowerShell GitHub repository. Choose the MSI installer for your architecture (either x86 or x64) and download the file. Once the installer is downloaded, double-click on the file to start the installation wizard. Follow the on-screen instructions to complete the installation process. After installation is complete, you can open PowerShell 7 from the Start menu or by typing pwsh in the command prompt.","title":"Windows"},{"location":"Install/installation/#linux","text":"On Linux, you can install PowerShell 7 using your distribution's package manager. Here are the commands for some popular distributions: Ubuntu 18.04 and later, and Debian 10 and later: Run the following commands in the terminal: # Update the list of packages sudo apt - get update # Install pre - requisite packages . sudo apt - get install - y wget apt - transport - https software - properties - common # Download the Microsoft repository GPG keys wget - q \"https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/packages-microsoft-prod.deb\" # Register the Microsoft repository GPG keys sudo dpkg - i packages - microsoft - prod . deb # Update the list of packages after we added packages . microsoft . com sudo apt - get update # Install PowerShell sudo apt - get install - y powershell # Start PowerShell pwsh","title":"Linux"},{"location":"Install/installation/#macos","text":"On macOS, you can install PowerShell 7 using Homebrew, a popular package manager for macOS. Run the following command in the terminal: brew install -- cask powershell After installation is complete, you can open PowerShell 7 from the Launchpad or by typing pwsh in the terminal.","title":"macOS"},{"location":"Install/recommendations/","text":"When it comes to setting up your environment for programming in PowerShell, there are a few key tools and configurations that can help make your workflow more efficient and effective. Here are some recommendations for the best setup for programming in PowerShell: 1. Install PowerShell 7 PowerShell 7 is the latest version of PowerShell and includes many new features and improvements over previous versions. It's recommended that you install PowerShell 7 to take advantage of these new features and to ensure compatibility with the latest PowerShell modules and scripts. 2. Install an IDE Using a dedicated Text Editor or Integrated Development Environment IDE can help make your workflow more efficient and productive. Popular options for PowerShell development include Visual Studio Code, PowerShell ISE, and the PowerShell extension for Visual Studio. 3. Install the PowerShell Extension for Your IDE If you're using a text editor or IDE, it's recommended that you install the PowerShell extension for that editor or IDE. This extension provides additional tools and features for working with PowerShell scripts and modules, such as syntax highlighting, IntelliSense, debugging, and code formatting. 4. Install PowerShell Modules PowerShell modules are collections of PowerShell commands and scripts that you can use to extend the functionality of PowerShell. Many modules are available through the PowerShell Gallery, which is a repository of PowerShell modules that you can download and install using the Install-Module command. 5. Configure Your Profile PowerShell allows you to configure your profile to set up your environment with your preferred settings and modules every time you start a new session. You can use your profile to set environment variables, define aliases, and load modules automatically. Your profile is stored in a PowerShell script file named $PROFILE, which you can edit using a text editor or IDE. By following these recommendations, you can set up a powerful and efficient environment for programming in PowerShell. Whether you're a beginner or an experienced developer, having the right tools and configurations can help you write better PowerShell code and automate your tasks more effectively.","title":"Recommendations"},{"location":"Install/recommendations/#1-install-powershell-7","text":"PowerShell 7 is the latest version of PowerShell and includes many new features and improvements over previous versions. It's recommended that you install PowerShell 7 to take advantage of these new features and to ensure compatibility with the latest PowerShell modules and scripts.","title":"1. Install PowerShell 7"},{"location":"Install/recommendations/#2-install-an-ide","text":"Using a dedicated Text Editor or Integrated Development Environment IDE can help make your workflow more efficient and productive. Popular options for PowerShell development include Visual Studio Code, PowerShell ISE, and the PowerShell extension for Visual Studio.","title":"2. Install an IDE"},{"location":"Install/recommendations/#3-install-the-powershell-extension-for-your-ide","text":"If you're using a text editor or IDE, it's recommended that you install the PowerShell extension for that editor or IDE. This extension provides additional tools and features for working with PowerShell scripts and modules, such as syntax highlighting, IntelliSense, debugging, and code formatting.","title":"3. Install the PowerShell Extension for Your IDE"},{"location":"Install/recommendations/#4-install-powershell-modules","text":"PowerShell modules are collections of PowerShell commands and scripts that you can use to extend the functionality of PowerShell. Many modules are available through the PowerShell Gallery, which is a repository of PowerShell modules that you can download and install using the Install-Module command.","title":"4. Install PowerShell Modules"},{"location":"Install/recommendations/#5-configure-your-profile","text":"PowerShell allows you to configure your profile to set up your environment with your preferred settings and modules every time you start a new session. You can use your profile to set environment variables, define aliases, and load modules automatically. Your profile is stored in a PowerShell script file named $PROFILE, which you can edit using a text editor or IDE. By following these recommendations, you can set up a powerful and efficient environment for programming in PowerShell. Whether you're a beginner or an experienced developer, having the right tools and configurations can help you write better PowerShell code and automate your tasks more effectively.","title":"5. Configure Your Profile"},{"location":"Net/365-basic/","text":"The Microsoft 365 admin center is a web-based console that you can use to manage users, groups, licensing, and other tenant-level configuration settings. When you manage users and groups from here, the properties you modify might be part of Azure AD, Exchange Online, or another service. This console provides a unified interface for some common management tasks. Links to service-specific, web-based consoles enable you to perform more detailed configuration of Microsoft 365 services. You can use these links to manage services such as Azure AD, Exchange Online, Microsoft Teams, and SharePoint Online. With the service-specific consoles, you can perform tasks such as: Creating users and group. Modifying email addresses. Setting organizational defaults for Teams. Configuring external sharing settings for SharePoint Online. You can access the Microsoft 365 admin console at https://admin.microsoft.com . The service-specific, web-based consoles are intuitive and easy to use, but they don't provide access to all possible configuration options. There are many useful configuration options that you can review and configure only by using PowerShell cmdlets. For example, in Exchange Online you can use PowerShell to review the permissions assigned to and configured on a calendar in a mailbox. In the web-based console, you can only review mailbox-level permissions. Using PowerShell to manage Microsoft 365 services also provides many of the same benefits as using PowerShell to manage local resources. You can: Use a query for objects matching certain criteria, and then generate reports. Use the pipeline to perform complex operations. Automate bulk processes. Manage multiple services simultaneously. Connection You can manage Microsoft 365 by using the Azure AD PowerShell for Graph (AzureAD) module or the Microsoft Azure Active Directory Module for Windows PowerShell (MSOnline) module. The Azure AD PowerShell for Graph module is the newer module and is generally preferred over the Azure Active Directory Module for Windows PowerShell module. However, some functionality in the Azure Active Directory Module for Windows PowerShell module isn't replicated in the Azure AD PowerShell for Graph module. Depending on your task, you might need to install and use both modules. Azure AD PowerShell for Graph Azure AD PowerShell for Graph is the newest PowerShell module for managing Microsoft 365 and has some features that aren't available in the older Azure Active Directory Module for Windows PowerShell module. As a result, when using PowerShell to manage Microsoft 365, the Azure AD module is preferred. All cmdlets provided by the Azure AD PowerShell for Graph module have AzureAD in the name of the cmdlet. For example, Get-AzureADUser. The AzureAD cmdlets use the Azure AD Graph API to access and modify data. The Azure AD Graph API is a REST API that can be accessed directly by web requests. The AzureAD cmdlets simplify this process for you. You can install the Azure AD PowerShell for Graph module from the PowerShell Gallery by running the following command: Install-Module AzureAD After the Azure AD PowerShell for Graph module is installed, you can connect to Microsoft 365 by running the following command: Connect-AzureAD When you connect to Microsoft 365, you're prompted for a username and password to sign in. You need to sign in with a user account that has sufficient privileges to perform the actions. You might also be prompted for multifactor authentication. Microsoft Graph PowerShell SDK Microsoft has announced that future management interface development will be focused on the Microsoft Graph API. This is a web-based API that's separate from the Azure AD Graph API used by the Azure AD PowerShell for Graph module. The Azure AD Graph API will cease updates after June 2022. All future development will be in the Microsoft Graph API. To access the Microsoft Graph API, you can use Invoke-WebRequest, but this process is difficult. To simplify the process of using Microsoft Graph API, you can use the Microsoft Graph PowerShell SDK (Microsoft.Graph). You can install the Microsoft.Graph module from the PowerShell Gallery by running the following command: Install-Module Microsoft . Graph After the Microsoft.Graph module is installed, you can connect to Microsoft 365 by running the following command: Connect-MgGraph -Scopes \"User.ReadWrite.All\" When you connect by using Microsoft.Graph, the scope specifies the permissions required. If your user account hasn't been assigned the necessary permissions already, an administrator needs to grant the permissions. There are many permission scopes available based on the type of object to be managed and the actions allowed. The Microsoft.Graph module creates cmdlets for the available Microsoft Graph options. This avoids much of the complexity that's typically required when using web-based APIs where you need to understand which URL to use and send data in a specific format. The Microsoft.Graph module provides you with cmdlets and parameters as the user interface. Cmdlets provided by the Microsoft.Graph module have Mg in the name of the cmdlet. For example, Get-MgUser. Additional reading: The remainder of this module focuses on using the AzureAD and Azure Active Directory Module for Windows PowerShell modules. For more information about using the Microsoft.Graph module, refer to Get started with the Microsoft Graph PowerShell SDK . Azure Cloud Shell As an alternative to installing and maintaining the AzureAD and Azure Active Directory Module for Windows PowerShell modules in multiple locations, you can use Azure Cloud Shell. Cloud Shell is a prompt with PowerShell functionality that you can access through a web browser. The Microsoft 365 admin center provides a link to open Cloud Shell. Many PowerShell modules that are used to manage Microsoft 365 services are automatically installed in the shell. You must have an Azure subscription to use Cloud Shell. Additional reading: For more information about Cloud Shell, see Overview of Azure Cloud Shell .","title":"Basic"},{"location":"Net/365-basic/#connection","text":"You can manage Microsoft 365 by using the Azure AD PowerShell for Graph (AzureAD) module or the Microsoft Azure Active Directory Module for Windows PowerShell (MSOnline) module. The Azure AD PowerShell for Graph module is the newer module and is generally preferred over the Azure Active Directory Module for Windows PowerShell module. However, some functionality in the Azure Active Directory Module for Windows PowerShell module isn't replicated in the Azure AD PowerShell for Graph module. Depending on your task, you might need to install and use both modules.","title":"Connection"},{"location":"Net/365-basic/#azure-ad-powershell-for-graph","text":"Azure AD PowerShell for Graph is the newest PowerShell module for managing Microsoft 365 and has some features that aren't available in the older Azure Active Directory Module for Windows PowerShell module. As a result, when using PowerShell to manage Microsoft 365, the Azure AD module is preferred. All cmdlets provided by the Azure AD PowerShell for Graph module have AzureAD in the name of the cmdlet. For example, Get-AzureADUser. The AzureAD cmdlets use the Azure AD Graph API to access and modify data. The Azure AD Graph API is a REST API that can be accessed directly by web requests. The AzureAD cmdlets simplify this process for you. You can install the Azure AD PowerShell for Graph module from the PowerShell Gallery by running the following command: Install-Module AzureAD After the Azure AD PowerShell for Graph module is installed, you can connect to Microsoft 365 by running the following command: Connect-AzureAD When you connect to Microsoft 365, you're prompted for a username and password to sign in. You need to sign in with a user account that has sufficient privileges to perform the actions. You might also be prompted for multifactor authentication.","title":"Azure AD PowerShell for Graph"},{"location":"Net/365-basic/#microsoft-graph-powershell-sdk","text":"Microsoft has announced that future management interface development will be focused on the Microsoft Graph API. This is a web-based API that's separate from the Azure AD Graph API used by the Azure AD PowerShell for Graph module. The Azure AD Graph API will cease updates after June 2022. All future development will be in the Microsoft Graph API. To access the Microsoft Graph API, you can use Invoke-WebRequest, but this process is difficult. To simplify the process of using Microsoft Graph API, you can use the Microsoft Graph PowerShell SDK (Microsoft.Graph). You can install the Microsoft.Graph module from the PowerShell Gallery by running the following command: Install-Module Microsoft . Graph After the Microsoft.Graph module is installed, you can connect to Microsoft 365 by running the following command: Connect-MgGraph -Scopes \"User.ReadWrite.All\" When you connect by using Microsoft.Graph, the scope specifies the permissions required. If your user account hasn't been assigned the necessary permissions already, an administrator needs to grant the permissions. There are many permission scopes available based on the type of object to be managed and the actions allowed. The Microsoft.Graph module creates cmdlets for the available Microsoft Graph options. This avoids much of the complexity that's typically required when using web-based APIs where you need to understand which URL to use and send data in a specific format. The Microsoft.Graph module provides you with cmdlets and parameters as the user interface. Cmdlets provided by the Microsoft.Graph module have Mg in the name of the cmdlet. For example, Get-MgUser. Additional reading: The remainder of this module focuses on using the AzureAD and Azure Active Directory Module for Windows PowerShell modules. For more information about using the Microsoft.Graph module, refer to Get started with the Microsoft Graph PowerShell SDK .","title":"Microsoft Graph PowerShell SDK"},{"location":"Net/365-basic/#azure-cloud-shell","text":"As an alternative to installing and maintaining the AzureAD and Azure Active Directory Module for Windows PowerShell modules in multiple locations, you can use Azure Cloud Shell. Cloud Shell is a prompt with PowerShell functionality that you can access through a web browser. The Microsoft 365 admin center provides a link to open Cloud Shell. Many PowerShell modules that are used to manage Microsoft 365 services are automatically installed in the shell. You must have an Azure subscription to use Cloud Shell. Additional reading: For more information about Cloud Shell, see Overview of Azure Cloud Shell .","title":"Azure Cloud Shell"},{"location":"Net/365-eo/","text":"Exchange Online is one of the most commonly used services in Microsoft 365. You can use PowerShell cmdlets to efficiently manage bulk operations and perform tasks that aren't possible through the web-based administrative interface. You can be a better administrator if you're adept at managing Exchange Online with PowerShell. Connection Exchange Online PowerShell is the module that you can use to manage mail-related objects in Exchange Online, such as mailboxes, contacts, and distribution. Some of the information that you can review and manage by using Exchange Online PowerShell, such as email addresses, you can also review in the properties of user objects with AzureAD cmdlets. However, you can only manage mail-related properties by using Exchange Online PowerShell. The EXO v2 module includes all of the original cmdlets for managing Exchange Online, and several additional cmdlets that include EXO in the cmdlet name. These EXO cmdlets, such as Get-EXOMailbox, are more efficient than the original cmdlets. Installing the EXO v2 module The EXO v2 module is supported in Windows PowerShell 5.1 and PowerShell 7. Because it's supported in PowerShell 7, it's considered multiplatform. You can use the EXO v2 module in Windows, macOS, and Linux. To install the EXO v2 module, run the following command: Install-Module -Name ExchangeOnlineManagement Preparing to connect To use the EXO v2 module, you need to allow scripts. You can set the execution policy to RemoteSigned or Unrestricted. If you don't allow scripts, you'll notice the error Files cannot be loaded because running scripts is disabled on this system. You also need to allow basic authentication for the WinRM client. This is enabled by default in Windows 10, but some organizations have disabled basic authentication for WinRM as part of security hardening. If Basic authentication isn't enabled, you'll notice the error The WinRM client cannot process the request. Basic authentication is currently disabled in the client configuration. To review the authentication configuration for the Windows Remote Management (WinRM) client, run the following command: winrm get winrm / config / client / auth # To enable basic authentication for the WinRM client winrm set winrm / config / client / auth '@{Basic=\"true\"}' If you run this command from a command prompt instead of a PowerShell prompt, don't include the single quotes around @{Basic=\"true\"}. Even though you need to enable Basic authentication in the WinRM client, the EXO v2 module authenticates to Exchange Online by using Modern authentication. In some rare cases, Modern authentication might not be enabled for Exchange Online and you'll need to enable it. All Exchange Online deployments should be using Modern authentication. This is because it has significant security enhancements over Basic authentication. Connecting to Exchange Online You can connect to Exchange Online by using the Connect-ExchangeOnline cmdlet with no additional parameters. When you connect to Exchange Online, you're prompted for a username and password to sign in. You need to sign in with a user account that has sufficient privileges to complete the actions you want to perform. You might also be prompted for multifactor authentication. If you're behind a proxy server, you might need to provide proxy options as part of connecting. To do this, provide a PSSessionOption object the proxy configuration information. The following example depicts how to create a new PSSessionOption object and then use it when connecting to Exchange Online: $ProxyOptions = New-PSSessionOption -ProxyAccessType IEConfig Connect-ExchangeOnline -PsSessionOption $ProxyOptions Manage mailboxes Mailboxes are created automatically for users who are assigned a license that includes an Exchange Online service plan. As such, there's no need to manually create mailboxes for users. Mailboxes are also deleted automatically when the license is removed or the Exchange Online service plan is disabled. You can also create specialized mailboxes such as: Room mailboxes. These are scheduled when you book meetings. Equipment mailboxes. These are scheduled to help ensure that users have access to equipment such as cars or portable display units. Shared mailboxes. These are used for generic email addresses, such as info@adatum.com, where multiple users need access to the mailbox and respond to the messages. Creating mailboxes When you use the New-Mailbox cmdlet to create a mailbox, it creates a user account at the same time. For resource mailboxes and shared mailboxes, the user account is disabled and doesn't require a license. When you create one of these mailboxes, you only need to indicate which type of mailbox you're creating and the name of the mailbox. The following example creates a room mailbox: New-Mailbox -Room -Name BoardRoom After creating a resource or shared mailbox, you still need configured permissions. By default, no one has access to those mailboxes. Configuring permissions is covered later in this unit. Configuring calendar booking for resources is covered in the next unit, Managing resources in Exchange Online. Modifying mailboxes To modify a mailbox's configuration, you use the Set-Mailbox cmdlet. There are some mailbox properties that you can configure using Set-Mailbox, which you can't configure using the web-based administrative tool. When you review the help information for Set-Mailbox, pay careful attention to the parameter descriptions. Some parameters aren't available for managing mailboxes in Exchange Online. Parameter Description -AuditDelegate Specifies actions on a mailbox that are audited when a delegate performs them, such as SendOnBehalf or UpdateInboxRules. -AuditEnabled Turns on auditing for a mailbox. This is disabled by default. -AuditOwner Specifies actions on a mailbox that are audited when the user performs them, such as SendOnBehalf or UpdateInboxRules. -DeliverToMailboxAndForward When a forwarding SMTP address is configured and this parameter is $true, this parameter configures the mailbox to both retain and forward a copy of the messages. -EmailAddresses Configures email addresses for a mailbox. The email addresses are stored as an array and typically start with smtp:. The primary email address will have the prefix capitalized as SMTP:. -ForwardingSmtpAddress Specifies an SMTP address for forwarding. To stop forwarding messages, set this value to $null. -GroupMailbox Required to modify the mailbox associated with a Microsoft 365 group. -HiddenFromAddressListsEnabled Specifies whether the mailbox is available in address lists. -MailboxRegion Specifies the geographic region in which the mailbox should be stored. Used by organizations with a worldwide presence. -Type Changes the type of mailbox. Specifies whether a mailbox is regular or used for a special purpose. Special-purpose mailboxes include both shared and resource mailboxes. The following syntax configures forwarding on a mailbox: Set-Mailbox AbbieP @adatum . com -ForwardingSmtpAddress DoraM @adatum . com -DeliverToMailboxAndForward $true Querying mailboxes in Exchange Online To query a list of mailboxes, you can use the Get-Mailbox or Get-EXOMailbox cmdlets. The primary difference between them is how the data is returned. The Get-Mailbox cmdlet returns all properties for the mailboxes. The Get-EXOMailbox cmdlet returns only a small set of properties, although you can specify additional properties. This makes Get-EXOMailbox much more efficient when working with large data sets. To obtain additional properties when using the Get-EXOMailbox cmdlet, you can use either the -Properties parameter or the -PropertySets parameter. When using the -Properties parameter, you provide a list of properties to return. When you use the -PropertySets parameter, you provide a list of predefined property groups that pertain to a specific category. Some property sets that you can specify are: All Minimum (default value) Audit Delivery Moderation Resource Both cmdlets support using the -Filter parameter to select mailboxes matching specific criteria. There are also additional specific parameters that you can use. The following table list some parameters that are available for both cmdlets. Parameter Description -Archive Returns mailboxes with an archive enabled. -GroupMailbox Returns only mailboxes associated with Microsoft 365 groups. -Identity Identifies a specific mailbox to return properties for. -RecipientTypeDetails Returns mailboxes of a specific type such as UserMailbox, TeamMailbox, or RoomMailbox. -SoftDeletedMailbox Returns soft-deleted mailboxes that are still available for recovery. The following syntax queries all of the room mailboxes and returns resource-related properties: Get-EXOMailbox -RecipientTypeDetails RoomMailbox -PropertySets Resource Managing mailbox permissions You can configure permissions to provide users with access to other mailboxes or individual folders within a mailbox. For example, you might want to give users full mailbox permission to a shared mailbox. Or you might want to change the default permissions assigned to the Calendar folder of a specific user mailbox. The following table lists cmdlets that you can use to manage mailbox and mailbox folder permissions. Cmdlet Description Add-MailboxPermission Adds permissions for a user to a mailbox. Get-MailboxPermission Lists user permissions that are assigned to a mailbox. Remove-MailboxPermission Removes a user's permissions assignment from a mailbox. Get-EXOMailboxPermission Lists user permissions that are assigned to a mailbox. Add-MailboxFolderPermission Adds permissions for a user to a folder in a mailbox. Get-MailboxFolderPermission Lists user permissions that are assigned to a folder in a mailbox. Remove-MailboxFolderPermission Removes a user's permissions assignment from a folder in a mailbox. Set-MailboxFolderPermission Sets permissions on a folder in a mailbox and overwrites all exiting permissions. Get-EXOMailboxFolderPermission Lists user permissions that are assigned to folder in a mailbox. The following example assigns full mailbox permissions for a user to the Info shared mailbox: Add-MailboxPermission -Identity Info -User AbbieP @adatum . com -AccessRights FullAccess -InheritanceType All Resource Mailboxes Room and equipment mailboxes are known as resource mailboxes. The primary purpose of resource mailboxes is to allow bookings and ensure that the resource isn't scheduled for multiple events or users simultaneously. You configure the scheduling process for resource mailboxes by using the Set-CalendarProcessing cmdlet. You can use the Get-CalendarProcessing cmdlet to review the current configuration. Delegates One of the options for managing resource scheduling is delegates. Delegates are users that can accept or reject booking attempts for the resource. For example, if a room resource is included in a meeting request, the delegate receives a message asking to allow or deny the request. The following example depicts a user being configured as a delegate for a room mailbox: Set-CalendarProcessing -Identity BoardRoom -ResourceDelegates AbbieP @adatum . com Automated booking Most organizations want to automate the resource booking process so that delegates only need to mediate conflicts. The -AutomateProcessing parameter set to AutoAccept is used to indicate that booking should be automated. However, there are other parameters that you can use to define when automated booking is allowed. The following table lists parameters that you can use to control automated resource booking. Parameter Description -AllBookInPolicy When set to $true, requests that meet booking rules are automatically accepted. -AllowConflicts When a resource is booked for a recurring meeting request, you can define whether the entire recurring series is declined whenever there are conflicts. You use this parameter with the -ConflictPercentageAllowed or -MaximumConflictInstances parameters. -AllRequestInPolicy When set to $true, all users are allowed to submit requests that meet the rules. The default configuration is $false. -AllRequestOutOfPolicy When set to $true, all users are allowed to submit requests that don't meet the rules. The default configuration is $false. -AutomateProcessing The default value of AutoAccept allows requests to be accepted automatically. A value of AutoUpdate marks requests as tentative and require a delegate to approve them. A value of None means no action is taken until a delegate approves or denies the request. -BookInPolicy Specifies users or groups for which bookings that meet the rules are automatically accepted. -EnforceCapacity When enabled, the capacity configured for the room is enforced. -MaximumDurationInMinutes Specifies the maximum allowed duration for meetings. -RequestInPolicy Specifies users or group that can submit requests that meet the booking rules. -RequestOutOfPolicy Specifies users or group that can submit requests that don't meet the booking rules. -ScheduleOnlyDuringWorkHours When enabled, requests outside of work hours don't meet the booking rules. Admin Roles Just as there are varying roles that you can use to control management permissions for Microsoft 365, there are roles in Exchange Online as well. In Exchange Online, the preconfigured management roles are referred to a role group, because a group has been assigned the permissions. The following table lists some of the default role groups. Table 1: Role groups in Exchange Online Role group Description Organization Management Performs all Exchange Online management tasks. Recipient Management Manages recipients such as mailboxes and distribution groups. View-only Management Reviews the configuration of all Exchange Online components but doesn't modify them. Records Management Manages retention, journaling, and transport rules. Discovery Management Manages legal holds and mailbox searches. You can review information about role groups by using the Get-RoleGroup cmdlet. You can modify membership in role groups by using the Add-RoleGroupMember and Remove-RoleGroupMember cmdlets. The following example depicts how to add a user to the Recipient Management role group: Add-RoleGroupMember -Identity \"Recipient Management\" -Member AbbieP @adatum . com The default roles groups are sufficient for many organizations. However, you can create customized role groups that allow you to define granular permissions, down to specific cmdlets that users are allowed to run. You can also define scopes that control which users or groups that administrators are allowed to manage. Takeaways Some of the information that you can review and manage by using Exchange Online PowerShell, such as email addresses, you can also review in the properties of user objects with AzureAD cmdlets. However, you can manage mail-related properties only by using Exchange Online PowerShell. Mailboxes are created automatically for users who are assigned a license that includes an Exchange Online service plan. One can also create specialized mailboxes such as room mailboxes, equipment mailboxes, and shared mailboxes. Room and equipment mailboxes are known as resource mailboxes. There are cmdlets that you can run to configure the scheduling process for resource mailboxes and review the current configuration. In Exchange Online, the preconfigured management roles are referred to as a role group, because a group has been assigned the permissions. There are default role groups that are sufficient for many organizations. However, you can create customized role groups that allow you to define granular permissions, down to specific cmdlets that users are allowed to run.","title":"Exchange Online"},{"location":"Net/365-eo/#connection","text":"Exchange Online PowerShell is the module that you can use to manage mail-related objects in Exchange Online, such as mailboxes, contacts, and distribution. Some of the information that you can review and manage by using Exchange Online PowerShell, such as email addresses, you can also review in the properties of user objects with AzureAD cmdlets. However, you can only manage mail-related properties by using Exchange Online PowerShell. The EXO v2 module includes all of the original cmdlets for managing Exchange Online, and several additional cmdlets that include EXO in the cmdlet name. These EXO cmdlets, such as Get-EXOMailbox, are more efficient than the original cmdlets.","title":"Connection"},{"location":"Net/365-eo/#installing-the-exo-v2-module","text":"The EXO v2 module is supported in Windows PowerShell 5.1 and PowerShell 7. Because it's supported in PowerShell 7, it's considered multiplatform. You can use the EXO v2 module in Windows, macOS, and Linux. To install the EXO v2 module, run the following command: Install-Module -Name ExchangeOnlineManagement","title":"Installing the EXO v2 module"},{"location":"Net/365-eo/#preparing-to-connect","text":"To use the EXO v2 module, you need to allow scripts. You can set the execution policy to RemoteSigned or Unrestricted. If you don't allow scripts, you'll notice the error Files cannot be loaded because running scripts is disabled on this system. You also need to allow basic authentication for the WinRM client. This is enabled by default in Windows 10, but some organizations have disabled basic authentication for WinRM as part of security hardening. If Basic authentication isn't enabled, you'll notice the error The WinRM client cannot process the request. Basic authentication is currently disabled in the client configuration. To review the authentication configuration for the Windows Remote Management (WinRM) client, run the following command: winrm get winrm / config / client / auth # To enable basic authentication for the WinRM client winrm set winrm / config / client / auth '@{Basic=\"true\"}' If you run this command from a command prompt instead of a PowerShell prompt, don't include the single quotes around @{Basic=\"true\"}. Even though you need to enable Basic authentication in the WinRM client, the EXO v2 module authenticates to Exchange Online by using Modern authentication. In some rare cases, Modern authentication might not be enabled for Exchange Online and you'll need to enable it. All Exchange Online deployments should be using Modern authentication. This is because it has significant security enhancements over Basic authentication.","title":"Preparing to connect"},{"location":"Net/365-eo/#connecting-to-exchange-online","text":"You can connect to Exchange Online by using the Connect-ExchangeOnline cmdlet with no additional parameters. When you connect to Exchange Online, you're prompted for a username and password to sign in. You need to sign in with a user account that has sufficient privileges to complete the actions you want to perform. You might also be prompted for multifactor authentication. If you're behind a proxy server, you might need to provide proxy options as part of connecting. To do this, provide a PSSessionOption object the proxy configuration information. The following example depicts how to create a new PSSessionOption object and then use it when connecting to Exchange Online: $ProxyOptions = New-PSSessionOption -ProxyAccessType IEConfig Connect-ExchangeOnline -PsSessionOption $ProxyOptions","title":"Connecting to Exchange Online"},{"location":"Net/365-eo/#manage-mailboxes","text":"Mailboxes are created automatically for users who are assigned a license that includes an Exchange Online service plan. As such, there's no need to manually create mailboxes for users. Mailboxes are also deleted automatically when the license is removed or the Exchange Online service plan is disabled. You can also create specialized mailboxes such as: Room mailboxes. These are scheduled when you book meetings. Equipment mailboxes. These are scheduled to help ensure that users have access to equipment such as cars or portable display units. Shared mailboxes. These are used for generic email addresses, such as info@adatum.com, where multiple users need access to the mailbox and respond to the messages.","title":"Manage mailboxes"},{"location":"Net/365-eo/#creating-mailboxes","text":"When you use the New-Mailbox cmdlet to create a mailbox, it creates a user account at the same time. For resource mailboxes and shared mailboxes, the user account is disabled and doesn't require a license. When you create one of these mailboxes, you only need to indicate which type of mailbox you're creating and the name of the mailbox. The following example creates a room mailbox: New-Mailbox -Room -Name BoardRoom After creating a resource or shared mailbox, you still need configured permissions. By default, no one has access to those mailboxes. Configuring permissions is covered later in this unit. Configuring calendar booking for resources is covered in the next unit, Managing resources in Exchange Online.","title":"Creating mailboxes"},{"location":"Net/365-eo/#modifying-mailboxes","text":"To modify a mailbox's configuration, you use the Set-Mailbox cmdlet. There are some mailbox properties that you can configure using Set-Mailbox, which you can't configure using the web-based administrative tool. When you review the help information for Set-Mailbox, pay careful attention to the parameter descriptions. Some parameters aren't available for managing mailboxes in Exchange Online. Parameter Description -AuditDelegate Specifies actions on a mailbox that are audited when a delegate performs them, such as SendOnBehalf or UpdateInboxRules. -AuditEnabled Turns on auditing for a mailbox. This is disabled by default. -AuditOwner Specifies actions on a mailbox that are audited when the user performs them, such as SendOnBehalf or UpdateInboxRules. -DeliverToMailboxAndForward When a forwarding SMTP address is configured and this parameter is $true, this parameter configures the mailbox to both retain and forward a copy of the messages. -EmailAddresses Configures email addresses for a mailbox. The email addresses are stored as an array and typically start with smtp:. The primary email address will have the prefix capitalized as SMTP:. -ForwardingSmtpAddress Specifies an SMTP address for forwarding. To stop forwarding messages, set this value to $null. -GroupMailbox Required to modify the mailbox associated with a Microsoft 365 group. -HiddenFromAddressListsEnabled Specifies whether the mailbox is available in address lists. -MailboxRegion Specifies the geographic region in which the mailbox should be stored. Used by organizations with a worldwide presence. -Type Changes the type of mailbox. Specifies whether a mailbox is regular or used for a special purpose. Special-purpose mailboxes include both shared and resource mailboxes. The following syntax configures forwarding on a mailbox: Set-Mailbox AbbieP @adatum . com -ForwardingSmtpAddress DoraM @adatum . com -DeliverToMailboxAndForward $true","title":"Modifying mailboxes"},{"location":"Net/365-eo/#querying-mailboxes-in-exchange-online","text":"To query a list of mailboxes, you can use the Get-Mailbox or Get-EXOMailbox cmdlets. The primary difference between them is how the data is returned. The Get-Mailbox cmdlet returns all properties for the mailboxes. The Get-EXOMailbox cmdlet returns only a small set of properties, although you can specify additional properties. This makes Get-EXOMailbox much more efficient when working with large data sets. To obtain additional properties when using the Get-EXOMailbox cmdlet, you can use either the -Properties parameter or the -PropertySets parameter. When using the -Properties parameter, you provide a list of properties to return. When you use the -PropertySets parameter, you provide a list of predefined property groups that pertain to a specific category. Some property sets that you can specify are: All Minimum (default value) Audit Delivery Moderation Resource Both cmdlets support using the -Filter parameter to select mailboxes matching specific criteria. There are also additional specific parameters that you can use. The following table list some parameters that are available for both cmdlets. Parameter Description -Archive Returns mailboxes with an archive enabled. -GroupMailbox Returns only mailboxes associated with Microsoft 365 groups. -Identity Identifies a specific mailbox to return properties for. -RecipientTypeDetails Returns mailboxes of a specific type such as UserMailbox, TeamMailbox, or RoomMailbox. -SoftDeletedMailbox Returns soft-deleted mailboxes that are still available for recovery. The following syntax queries all of the room mailboxes and returns resource-related properties: Get-EXOMailbox -RecipientTypeDetails RoomMailbox -PropertySets Resource","title":"Querying mailboxes in Exchange Online"},{"location":"Net/365-eo/#managing-mailbox-permissions","text":"You can configure permissions to provide users with access to other mailboxes or individual folders within a mailbox. For example, you might want to give users full mailbox permission to a shared mailbox. Or you might want to change the default permissions assigned to the Calendar folder of a specific user mailbox. The following table lists cmdlets that you can use to manage mailbox and mailbox folder permissions. Cmdlet Description Add-MailboxPermission Adds permissions for a user to a mailbox. Get-MailboxPermission Lists user permissions that are assigned to a mailbox. Remove-MailboxPermission Removes a user's permissions assignment from a mailbox. Get-EXOMailboxPermission Lists user permissions that are assigned to a mailbox. Add-MailboxFolderPermission Adds permissions for a user to a folder in a mailbox. Get-MailboxFolderPermission Lists user permissions that are assigned to a folder in a mailbox. Remove-MailboxFolderPermission Removes a user's permissions assignment from a folder in a mailbox. Set-MailboxFolderPermission Sets permissions on a folder in a mailbox and overwrites all exiting permissions. Get-EXOMailboxFolderPermission Lists user permissions that are assigned to folder in a mailbox. The following example assigns full mailbox permissions for a user to the Info shared mailbox: Add-MailboxPermission -Identity Info -User AbbieP @adatum . com -AccessRights FullAccess -InheritanceType All","title":"Managing mailbox permissions"},{"location":"Net/365-eo/#resource-mailboxes","text":"Room and equipment mailboxes are known as resource mailboxes. The primary purpose of resource mailboxes is to allow bookings and ensure that the resource isn't scheduled for multiple events or users simultaneously. You configure the scheduling process for resource mailboxes by using the Set-CalendarProcessing cmdlet. You can use the Get-CalendarProcessing cmdlet to review the current configuration.","title":"Resource Mailboxes"},{"location":"Net/365-eo/#delegates","text":"One of the options for managing resource scheduling is delegates. Delegates are users that can accept or reject booking attempts for the resource. For example, if a room resource is included in a meeting request, the delegate receives a message asking to allow or deny the request. The following example depicts a user being configured as a delegate for a room mailbox: Set-CalendarProcessing -Identity BoardRoom -ResourceDelegates AbbieP @adatum . com Automated booking Most organizations want to automate the resource booking process so that delegates only need to mediate conflicts. The -AutomateProcessing parameter set to AutoAccept is used to indicate that booking should be automated. However, there are other parameters that you can use to define when automated booking is allowed. The following table lists parameters that you can use to control automated resource booking. Parameter Description -AllBookInPolicy When set to $true, requests that meet booking rules are automatically accepted. -AllowConflicts When a resource is booked for a recurring meeting request, you can define whether the entire recurring series is declined whenever there are conflicts. You use this parameter with the -ConflictPercentageAllowed or -MaximumConflictInstances parameters. -AllRequestInPolicy When set to $true, all users are allowed to submit requests that meet the rules. The default configuration is $false. -AllRequestOutOfPolicy When set to $true, all users are allowed to submit requests that don't meet the rules. The default configuration is $false. -AutomateProcessing The default value of AutoAccept allows requests to be accepted automatically. A value of AutoUpdate marks requests as tentative and require a delegate to approve them. A value of None means no action is taken until a delegate approves or denies the request. -BookInPolicy Specifies users or groups for which bookings that meet the rules are automatically accepted. -EnforceCapacity When enabled, the capacity configured for the room is enforced. -MaximumDurationInMinutes Specifies the maximum allowed duration for meetings. -RequestInPolicy Specifies users or group that can submit requests that meet the booking rules. -RequestOutOfPolicy Specifies users or group that can submit requests that don't meet the booking rules. -ScheduleOnlyDuringWorkHours When enabled, requests outside of work hours don't meet the booking rules.","title":"Delegates"},{"location":"Net/365-eo/#admin-roles","text":"Just as there are varying roles that you can use to control management permissions for Microsoft 365, there are roles in Exchange Online as well. In Exchange Online, the preconfigured management roles are referred to a role group, because a group has been assigned the permissions. The following table lists some of the default role groups. Table 1: Role groups in Exchange Online Role group Description Organization Management Performs all Exchange Online management tasks. Recipient Management Manages recipients such as mailboxes and distribution groups. View-only Management Reviews the configuration of all Exchange Online components but doesn't modify them. Records Management Manages retention, journaling, and transport rules. Discovery Management Manages legal holds and mailbox searches. You can review information about role groups by using the Get-RoleGroup cmdlet. You can modify membership in role groups by using the Add-RoleGroupMember and Remove-RoleGroupMember cmdlets. The following example depicts how to add a user to the Recipient Management role group: Add-RoleGroupMember -Identity \"Recipient Management\" -Member AbbieP @adatum . com The default roles groups are sufficient for many organizations. However, you can create customized role groups that allow you to define granular permissions, down to specific cmdlets that users are allowed to run. You can also define scopes that control which users or groups that administrators are allowed to manage.","title":"Admin Roles"},{"location":"Net/365-eo/#takeaways","text":"Some of the information that you can review and manage by using Exchange Online PowerShell, such as email addresses, you can also review in the properties of user objects with AzureAD cmdlets. However, you can manage mail-related properties only by using Exchange Online PowerShell. Mailboxes are created automatically for users who are assigned a license that includes an Exchange Online service plan. One can also create specialized mailboxes such as room mailboxes, equipment mailboxes, and shared mailboxes. Room and equipment mailboxes are known as resource mailboxes. There are cmdlets that you can run to configure the scheduling process for resource mailboxes and review the current configuration. In Exchange Online, the preconfigured management roles are referred to as a role group, because a group has been assigned the permissions. There are default role groups that are sufficient for many organizations. However, you can create customized role groups that allow you to define granular permissions, down to specific cmdlets that users are allowed to run.","title":"Takeaways"},{"location":"Net/365-groups/","text":"Microsoft 365 has multiple types of groups that you can use to provide access to resources or send email. Each group type serves a different purpose, and you should select the correct type for your needs. The group types available in Microsoft 365 are listed in the following table. Group type Description Microsoft 365 group Microsoft 365 groups are used for collaboration between users, both inside and outside your company. With each Microsoft 365 group, members get a group email and shared workspace for conversations, files, and calendar events, Microsoft Stream, and Microsoft Planner. Distribution group Distribution groups are used for sending notifications to a group of people. They can receive external email if enabled by the administrator. Security group Security groups are used for granting access to Microsoft 365 resources, such as SharePoint. They can make administration easier because you only need to administer the group rather than adding users to each resource individually. Mail-enabled security group A mail-enabled security group has the same functionality as a security group for assigning permissions, but it can also be used to send email messages just as you can with a distribution group. There are no AzureAD or Msol cmdlets for managing Microsoft 365 groups. The cmdlets for managing Microsoft 365 groups are part of Exchange Online, because these groups include a mailbox. In the Exchange Online cmdlets, Microsoft 365 groups are referred to as unified groups. Managing groups with AzureAD cmdlets You can create distribution groups, security groups, and mail-enabled security groups by using the New-AzureADGroup cmdlet. The type of group created depends on how you use the -MailEnabled and -SecurityEnabled parameters. The following example creates a mail-enabled security group: New-AzureADGroup -DisplayName \"Marketing Group\" -MailEnabled $true -SecurityEnabled $true -MailNickname MarketingGrp When you create a new group, the group is assigned an ObjectID. The ObjectID is a unique identifier for the group. You need to use the ObjectID for the group with management cmdlets. You can't use a display name to refer to a group because it isn't guaranteed to be unique. Use the Get-AzureADGroup cmdlet to identify the ObjectID for a group that you want to manage. Other AzureAD cmdlets that you can use to manage groups are listed in the following table. Cmdlet Description Get-AzureADGroup Queries for distribution groups, security groups, and mail-enabled security groups. This cmdlet supports using a filter or search string. Set-AzureADGroup Modifies the properties of distribution groups, security groups, and mail-enabled security groups. Remove-AzureADGroup Deletes distribution groups, security groups, and mail-enabled security groups. Get-AzureADGroupMember Queries the membership of distribution groups, security groups, and mail-enabled security groups. Add-AzureADGroupMember Adds a member to distribution groups, security groups, and mail-enabled security groups. Remove-AzureADGroupMember Removes a member from distribution groups, security groups, and mail-enabled security groups. Get-AzureADGroupOwner Queries the owners of distribution groups, security groups, and mail-enabled security groups. Add-AzureADGroupOwner Adds an owner to distribution groups, security groups, and mail-enabled security groups. Remove-AzureADGroupOwner Removes an owner from distribution groups, security groups, and mail-enabled security groups. Synchronized groups Groups that you create in Microsoft 365 with Windows PowerShell are cloud groups. Many organizations use Azure AD Connect to synchronize users and groups from on-premises AD DS to Microsoft 365. These users and groups are created by Azure AD Connect, and you can't them delete directly in Microsoft 365. Instead, you need to delete the object in AD DS, and the deletion is synchronized to Microsoft 365. When objects are synchronized from AD DS to Microsoft 365, the value of some attributes in AD DS is authoritative. This means you can't modify the attribute value in Microsoft 365. Instead, you need to modify the value in AD DS, and the modified value synchronizes to Microsoft 365. If you attempt to modify these attributes in Microsoft 365, an error is generated. Group membership from on-premises AD DS is authoritative. You can't edit the membership of a synchronized group. Instead, you need to modify the membership in the on-premises AD DS group.","title":"Groups"},{"location":"Net/365-groups/#managing-groups-with-azuread-cmdlets","text":"You can create distribution groups, security groups, and mail-enabled security groups by using the New-AzureADGroup cmdlet. The type of group created depends on how you use the -MailEnabled and -SecurityEnabled parameters. The following example creates a mail-enabled security group: New-AzureADGroup -DisplayName \"Marketing Group\" -MailEnabled $true -SecurityEnabled $true -MailNickname MarketingGrp When you create a new group, the group is assigned an ObjectID. The ObjectID is a unique identifier for the group. You need to use the ObjectID for the group with management cmdlets. You can't use a display name to refer to a group because it isn't guaranteed to be unique. Use the Get-AzureADGroup cmdlet to identify the ObjectID for a group that you want to manage. Other AzureAD cmdlets that you can use to manage groups are listed in the following table. Cmdlet Description Get-AzureADGroup Queries for distribution groups, security groups, and mail-enabled security groups. This cmdlet supports using a filter or search string. Set-AzureADGroup Modifies the properties of distribution groups, security groups, and mail-enabled security groups. Remove-AzureADGroup Deletes distribution groups, security groups, and mail-enabled security groups. Get-AzureADGroupMember Queries the membership of distribution groups, security groups, and mail-enabled security groups. Add-AzureADGroupMember Adds a member to distribution groups, security groups, and mail-enabled security groups. Remove-AzureADGroupMember Removes a member from distribution groups, security groups, and mail-enabled security groups. Get-AzureADGroupOwner Queries the owners of distribution groups, security groups, and mail-enabled security groups. Add-AzureADGroupOwner Adds an owner to distribution groups, security groups, and mail-enabled security groups. Remove-AzureADGroupOwner Removes an owner from distribution groups, security groups, and mail-enabled security groups.","title":"Managing groups with AzureAD cmdlets"},{"location":"Net/365-groups/#synchronized-groups","text":"Groups that you create in Microsoft 365 with Windows PowerShell are cloud groups. Many organizations use Azure AD Connect to synchronize users and groups from on-premises AD DS to Microsoft 365. These users and groups are created by Azure AD Connect, and you can't them delete directly in Microsoft 365. Instead, you need to delete the object in AD DS, and the deletion is synchronized to Microsoft 365. When objects are synchronized from AD DS to Microsoft 365, the value of some attributes in AD DS is authoritative. This means you can't modify the attribute value in Microsoft 365. Instead, you need to modify the value in AD DS, and the modified value synchronizes to Microsoft 365. If you attempt to modify these attributes in Microsoft 365, an error is generated. Group membership from on-premises AD DS is authoritative. You can't edit the membership of a synchronized group. Instead, you need to modify the membership in the on-premises AD DS group.","title":"Synchronized groups"},{"location":"Net/365-licenses/","text":"After you create user accounts, you need to assign a license to the user account. The license determines which Microsoft 365 services the user has access to. The licenses in the tenant vary depending on which licenses you've purchased. Some of the common enterprise licenses are: Microsoft Office 365 E3 Office 365 E5 Microsoft 365 E3 Microsoft 365 E5 Each license includes multiple services that can be enabled or disabled. For example, an Office 365 E3 license includes access to Exchange Online, Microsoft Teams, SharePoint Online, and others. All services in a license are enabled by default. When you configure licensing by using Windows PowerShell, you need to refer to the license and service plans by either a string ID or a globally unique identifier (GUID). For example, the Microsoft 365 E3 license has a string ID of SPE_E3 and a GUID of 05e9a617-0261-4cee-bb44-138d3ef5d965. The AzureAD cmdlets for licensing use the GUID, and the Msol cmdlets use the string ID. Additional reading: It's possible to query the string ID or GUID from your tenant, but you can also find a list of licenses and service plans on Product names and service plan identifiers for licensing . Some organizations use group-based licensing, which assigns licenses to user accounts automatically, based on group membership. If a license has been assigned by group-based licensing, you can't modify that license assignment by using PowerShell. Reviewing licenses by using AzureAD cmdlets You can use the Get-AzureADSubscribedSku cmdlet to review the licenses available in your Microsoft 365 tenant. The following example retrieves licenses and displays information about them. The SkuId property is the GUID for the license: Get-AzureADSubscribedSku | Select-Object -Property Sku *, ConsumedUnits -ExpandProperty PrepaidUnits The service plans for a license are stored in the ServicePlans property. The following example places all licenses in a variable and then displays the service plans for the first item in the array. The provisioning status for the service plan indicates whether it's enabled or disabled for that user: $sku = Get-AzureADSubscribedSku $sku [ 0 ]. ServicePlans Managing licenses by using Azure AD cmdlets You can use the Set-AzureADUserLicense cmdlet to assign a license to a user. Licenses to be added are contained in an AssignedLicenses object that you create. For each license that you want to add, you create an AssignedLicense object and add it to the AddLicenses property of the AssignedLicenses object. After the AssignedLicenses object is configured, you apply it to the user account. The following example creates a license object for Microsoft 365 E3, and then assigns it to a user: $License = New-Object -TypeName Microsoft . Open . AzureAD . Model . AssignedLicense $License . SkuId = '05e9a617-0261-4cee-bb44-138d3ef5d965' $LicensesToAssign = New-Object -TypeName Microsoft . Open . AzureAD . Model . AssignedLicenses $LicensesToAssign . AddLicenses = $License Set-AzureADUserLicense -ObjectId AbbieP @adatum . com -AssignedLicenses $LicensesToAssign If you want to disable service plans for a user, you need to add the GUID for the service plans to the DisabledPlans property of the license object. The following example depicts how to disable the YAMMER_ENTERPRISE and SWAY service plans in a license: $License . DisabledPlans = '7547a3fe-08ee-4ccb-b430-5077c5041653' $License . DisabledPlans . Add ( 'a23b959c-7ce8-4e57-9140-b90eb88a9e97' ) To remove a license, you add a license to the RemoveLicenses property of an AssignedLicenses object. The following example removes a Microsoft 365 E3 license from a user account: $License = New-Object -TypeName Microsoft . Open . AzureAD . Model . AssignedLicense $License . SkuId = '05e9a617-0261-4cee-bb44-138d3ef5d965' $LicensesToAssign = New-Object -TypeName Microsoft . Open . AzureAD . Model . AssignedLicenses $LicensesToAssign . RemoveLicenses = $License Set-AzureADUserLicense -ObjectId AbbieP @adatum . com -AssignedLicenses $LicensesToAssign You can't add multiple licenses to a user that has conflicting components. For example, you can't assign a Microsoft 365 E5 license to a user that already has a Microsoft 365 E3 license. However, you can create an AssignedLicenses object that removes the Microsoft 365 E3 license and adds the Microsoft 365 E5 license at the same time.","title":"Licenses"},{"location":"Net/365-licenses/#reviewing-licenses-by-using-azuread-cmdlets","text":"You can use the Get-AzureADSubscribedSku cmdlet to review the licenses available in your Microsoft 365 tenant. The following example retrieves licenses and displays information about them. The SkuId property is the GUID for the license: Get-AzureADSubscribedSku | Select-Object -Property Sku *, ConsumedUnits -ExpandProperty PrepaidUnits The service plans for a license are stored in the ServicePlans property. The following example places all licenses in a variable and then displays the service plans for the first item in the array. The provisioning status for the service plan indicates whether it's enabled or disabled for that user: $sku = Get-AzureADSubscribedSku $sku [ 0 ]. ServicePlans","title":"Reviewing licenses by using AzureAD cmdlets"},{"location":"Net/365-licenses/#managing-licenses-by-using-azure-ad-cmdlets","text":"You can use the Set-AzureADUserLicense cmdlet to assign a license to a user. Licenses to be added are contained in an AssignedLicenses object that you create. For each license that you want to add, you create an AssignedLicense object and add it to the AddLicenses property of the AssignedLicenses object. After the AssignedLicenses object is configured, you apply it to the user account. The following example creates a license object for Microsoft 365 E3, and then assigns it to a user: $License = New-Object -TypeName Microsoft . Open . AzureAD . Model . AssignedLicense $License . SkuId = '05e9a617-0261-4cee-bb44-138d3ef5d965' $LicensesToAssign = New-Object -TypeName Microsoft . Open . AzureAD . Model . AssignedLicenses $LicensesToAssign . AddLicenses = $License Set-AzureADUserLicense -ObjectId AbbieP @adatum . com -AssignedLicenses $LicensesToAssign If you want to disable service plans for a user, you need to add the GUID for the service plans to the DisabledPlans property of the license object. The following example depicts how to disable the YAMMER_ENTERPRISE and SWAY service plans in a license: $License . DisabledPlans = '7547a3fe-08ee-4ccb-b430-5077c5041653' $License . DisabledPlans . Add ( 'a23b959c-7ce8-4e57-9140-b90eb88a9e97' ) To remove a license, you add a license to the RemoveLicenses property of an AssignedLicenses object. The following example removes a Microsoft 365 E3 license from a user account: $License = New-Object -TypeName Microsoft . Open . AzureAD . Model . AssignedLicense $License . SkuId = '05e9a617-0261-4cee-bb44-138d3ef5d965' $LicensesToAssign = New-Object -TypeName Microsoft . Open . AzureAD . Model . AssignedLicenses $LicensesToAssign . RemoveLicenses = $License Set-AzureADUserLicense -ObjectId AbbieP @adatum . com -AssignedLicenses $LicensesToAssign You can't add multiple licenses to a user that has conflicting components. For example, you can't assign a Microsoft 365 E5 license to a user that already has a Microsoft 365 E3 license. However, you can create an AssignedLicenses object that removes the Microsoft 365 E3 license and adds the Microsoft 365 E5 license at the same time.","title":"Managing licenses by using Azure AD cmdlets"},{"location":"Net/365-roles/","text":"In Microsoft 365, roles are used to assign administrative permissions to user accounts. The Global Administrator role gives users permission to manage all aspects of Microsoft 365. Other roles allow users to manage only a subset of Microsoft 365 features. The following table lists some of the Microsoft 365 roles that can be assigned to users. Role Description Global Reader Can review settings for all aspects of Microsoft 365. Exchange Administrator Can review and manage settings for Exchange Online. Helpdesk admin Can reset passwords for non-administrative accounts, force non-administrative users to sign out, manage service requests, and monitor service health. Service support admin Can open and manage service requests, review and share message center posts, and monitor service health. SharePoint Administrator Can review and manage settings for SharePoint Online. Teams Administrator Can review and manage settings for Microsoft Teams. User Administrator Can review and manage user accounts. Role names can vary depending on whether you review them in the web-based admin consoles, AzureAD cmdlets, or Msol cmdlets. Managing roles with AzureAD cmdlets AzureAD cmdlets require you to identify whether a role is already in use before you can assign it to a user. If no users have been assigned to a role, then it exists only as a template, and you need to enable the role before you can add users to it. You can use the Get-AzureADDirectoryRole cmdlet to review the roles that are enabled. Use the Get-AzureADDirectoryRoleTemplate cmdlet to review the roles that aren't yet enabled. The following example depicts how to enable the User Administrator role. When you enable the role, you need to refer to the object ID of the template: $roleTemplate = Get-AzureADDirectoryRoleTemplate | Where { $_ . displayName -eq 'User Administrator' } Enable-AzureADDirectoryRole -RoleTemplateId $roleTemplate . ObjectId After you enable the role, you can add a role member to assign administrative permissions by using the Add-AzureADDirectoryRoleMember cmdlet. The following example depicts how to add an account to the User Administrator role. The -ObjectId parameter refers to the ObjectID of the role. The -RefObjectId parameter refers to the ObjectID of the user account: $user = Get-AzureADUser -ObjectID AbbieP @adatum . com $role = Get-AzureADDirectoryRole | Where { $_ . displayName -eq 'User Administrator' } Add-AzureADDirectoryRoleMember -ObjectId $role . ObjectId -RefObjectId $user . ObjectID To list existing members of a role, use Get-AzureADDirectoryRoleMember. To remove a member from a role, use Remove-AzureADDirectoryRoleMember.","title":"Roles"},{"location":"Net/365-roles/#managing-roles-with-azuread-cmdlets","text":"AzureAD cmdlets require you to identify whether a role is already in use before you can assign it to a user. If no users have been assigned to a role, then it exists only as a template, and you need to enable the role before you can add users to it. You can use the Get-AzureADDirectoryRole cmdlet to review the roles that are enabled. Use the Get-AzureADDirectoryRoleTemplate cmdlet to review the roles that aren't yet enabled. The following example depicts how to enable the User Administrator role. When you enable the role, you need to refer to the object ID of the template: $roleTemplate = Get-AzureADDirectoryRoleTemplate | Where { $_ . displayName -eq 'User Administrator' } Enable-AzureADDirectoryRole -RoleTemplateId $roleTemplate . ObjectId After you enable the role, you can add a role member to assign administrative permissions by using the Add-AzureADDirectoryRoleMember cmdlet. The following example depicts how to add an account to the User Administrator role. The -ObjectId parameter refers to the ObjectID of the role. The -RefObjectId parameter refers to the ObjectID of the user account: $user = Get-AzureADUser -ObjectID AbbieP @adatum . com $role = Get-AzureADDirectoryRole | Where { $_ . displayName -eq 'User Administrator' } Add-AzureADDirectoryRoleMember -ObjectId $role . ObjectId -RefObjectId $user . ObjectID To list existing members of a role, use Get-AzureADDirectoryRoleMember. To remove a member from a role, use Remove-AzureADDirectoryRoleMember.","title":"Managing roles with AzureAD cmdlets"},{"location":"Net/365-sp/","text":"SharePoint Online is a collaboration service that allows you to store and share information through a web-based interface. Many organizations use SharePoint sites to build web portals for departments. To provide users with access to SharePoint Online, you need to understand how permissions are assigned. Additionally, you need to understand how external sharing is configured to help ensure that sensitive information isn't shared when it shouldn't be. You can manage many SharePoint Online features by using the web-based SharePoint admin center. However, it doesn't provide full management access to SharePoint Online. For some advanced operations, you need to use SharePoint Online Management Shell. The SharePoint Online Management Shell is a Windows PowerShell module that you can install. Installation You install the SharePoint Online Management Shell from the PowerShell Gallery by running the following command: Install-Module -Name Microsoft . Online . SharePoint . PowerShell The SharePoint Online Management Shell doesn't update automatically. To update the module, run the following command: Update-Module -Name Microsoft . Online . SharePoint . PowerShell Connection All of the cmdlet nouns in the SharePoint Online Management Shell begin with SPO. You can connect to SharePoint Online by using the Connect-SPOService cmdlet as in the following example: Connect-SPOService -Url https :// adatum-admin . sharepoint . com When you connect to SharePoint Online, you need to provide the URL for your SharePoint Online instance. This URL is based on your Microsoft 365 tenant name. For example, if your Microsoft 365 tenant name is adatum.onmicrosoft.com, then the URL for administering SharePoint Online is adatum-admin.sharepoint.com. You can also find this URL when you sign in to SharePoint admin center. To sign in by using Connect-SPOService, you need a user account with either SharePoint Admin or Global Administrator permissions for the Microsoft 365 tenant. Users and Groups To provide access to a SharePoint site, you can assign users and groups varying levels of site permissions. Some of the permissions available by default are: Full Control Design Edit Approve Contribute Read You can create customized permission levels by using SharePoint admin center. There are no cmdlets in SharePoint Online Management Shell for creating or modifying customized permission levels. SharePoint groups To assign permissions in SharePoint Online by using PowerShell, you create SharePoint groups. SharePoint groups exist only in SharePoint Online and are specific to the site in which you create them. The following example depicts how to use the New-SPOSiteGroup cmdlet to create a SharePoint Online group and assign permissions for a site: New-SPOSiteGroup -Group MarketingUsers -PermissionLevels Read -Site https :// adatum . sharepoint . com / sites / Marketing You can use the Get-SPOSiteGroup cmdlet to identify the SharePoint groups that have been created for a site and assigned permissions. The results also contain the group membership. You need to specify the site URL with the request as depicted in the following example: Get-SPOSiteGroup -Site https :// adatum . sharepoint . com / sites / Marketing You can modify the permissions assigned to a SharePoint group by using the Set-SPOSiteGroup cmdlet. You need to specify the name of the group and the site URL in addition to the permissions to be modified. To add permissions, use the -PermissionLevelsToAdd parameter. To remove permissions, use the -PermissionLevelsToRemove parameter. The following example uses the -PermissionLevelsToAdd parameter: Set-SPOSiteGroup -Site https :// adatum . sharepoint . com / sites / Marketing -Group MarketingUsers -PermissionLevelsToAdd Contribute Managing site users To give permissions to Azure AD users, you must make them members of a SharePoint group. You can add members to a SharePoint group by using the Add-SPOUser cmdlet as depicted in the following example. You need to specify the site URL along with the group name: Add-SPOUser -Site https :// adatum . sharepoint . com / sites / Marketing -Group MarketingUsers -LoginName AbbieP @adatum . com You can also add security groups from Azure AD as members of SharePoint groups by using the Add-SPOUser cmdlet. The Remove-SPOUser cmdlet has similar syntax to the Add-SPOUser cmdlet but removes a user from the specified SharePoint group. If you don't specify a group, then the user is removed from all SharePoint groups in the site. To review the users who are members of SharePoint groups, you can use the Get-SPOUser cmdlet. You need to specify the site URL from which to retrieve users, but the group is optional. If you don't specify the group, you'll receive a list of all users in the site and the SharePoint groups that they are members of. There is also a Set-SPOUser cmdlet but its only purpose is to set whether a user is an administrator for the site. The following example depicts how to configure a user as a site administrator: Set-SPOUser -Site https :// adatum . sharepoint . com / sites / Marketing -LoginName AbbieP @adatum . com -IsSiteCollectionAdmin $true SP Sites In SharePoint Online, you can have multiple sites that contain different content. There's a default site designed for collaboration that's created automatically when you create your tenant. There are also sites created automatically for each Microsoft 365 group or Microsoft Team and OneDrive users. Additionally, you can create your own SharePoint sites and customize them. Creating sites You can use the New-SPOSite cmdlet to create new sites in SharePoint online. When you create a new site, the parameters in the following table are required. Parameter Description -Url The URL for the site, which needs to be with your SharePoint Online namespace. For example, if the default URL for your SharePoint Online tenant is https://adatum.sharepoint.com, then the URL for the site could be https://adatum.sharepoint.com/sites/Marketing. -Owner The owner of the site that can manage it. -StorageQuota The maximum size of the site in megabytes (MB). This must be less than the quota available in the tenant. The following example creates a new site with AbbieP@adatum.com as the owner and a 256 MB storage quota: New-SPOSite -Url https :// adatum . sharepoint . com / sites / Marketing -Owner AbbieP @adatum . com -StorageQuota 256 Most of the time when you create a site, you'll want to base it on a template. A template defines components that are automatically included in a site. There are templates included in SharePoint Online by default and you can also make your own. To review the template in your SharePoint Online tenant, use the Get-SPOWebTemplate cmdlet. To use a template when creating a site with the New-SPOSite cmdlet, use the -Template parameter. Modifying sites You can use the Set-SPOSite cmdlet to modify existing sites. To define which site you want to modify, use the -Identity parameter and provide the URL for the site. The URL for a site is a unique identifier for the site, and you cannot modify it by using Set-SPOSite. The following table lists some parameters you can use with Set-SPOSite. Parameter Description -Title Sets the title for the site. The title typically displays when users sign in to the site. For example, a title might be Marketing Portal. -StorageQuotaWarningLevel Sends a warning message to the site owner when the warning level is reached. This value should be less than the -StorageQuota. -AllowEditing Controls whether users are allowed to edit Office files in the browser, and copy and paste Office file content out of the browser window. -LockState Sets the lock state on a site. Valid values are: NoAccess, ReadOnly, and Unlock. The following example sets the title for a site: Set-SPOSite -Identity https :// adatum . sharepoint . com / sites / Marketing -Title \"Marketing Portal\" Listing and reviewing sites You can use the Get-SPOSite cmdlet to review the sites created in your SharePoint Online tenant and their configurations. To list all sites in your tenant, don't include any parameters. To list the specific site's properties, you use the -Identity parameter and specify the site's URL. The following example depicts how to list a specific site's properties: Get-SPOSite -Identity https :// adatum . sharepoint . com / sites / Marketing | Format-List Removing sites You use Remove-SPOSite to remove a site. The following example depicts how to use this cmdlet to remove a site: Remove-SPOSite -Identity https :// adatum . sharepoint . com / sites / Marketing When you remove a site, it's placed in the SharePoint Recycle Bin. You can use the Restore-SPODeletedSite cmdlet to restore a site from the SharePoint Recycle Bin. To purge a deleted site from the SharePoint Recycle Bin, you can use the Remove-SPODeletedSite cmdlet. SharePoint Online terminology The SharePoint admin center uses the site and sub-site terminology to describe how to nest content. When you create a sub-site, it inherits some of the settings from the site, such as the owner. If you're familiar with the on-premises version of SharePoint, it uses the terminology site collections and sites instead. When reviewing documentation for SharePoint Online cmdlets, you might notice that it often uses the on-premises site collections terminology. There are no cmdlets for managing sites within site collections (or sub-sites). External Users SharePoint Online content can be shared with external users. Because Microsoft OneDrive storage is part of SharePoint Online, there are similar settings for both. When you configure settings for external sharing, the OneDrive settings must be the same or more restrictive than the SharePoint Online settings. The commonly used external sharing settings for SharePoint Online are listed in the following table. Permission level Description Anyone Allows users to share files and folders by using links that let anyone who has the link access the files or folders without authenticating. This setting also allows users to share sites with new and existing guests who authenticate. If you select this setting, you can restrict the Anyone links so that they expire within a specific number of days, or so that they provide only View permission. New and existing guests Requires people who have received invitations to sign in with their work or school account (if their organization uses Microsoft 365). Alternatively, they can use a Microsoft account, or provide a code to verify their identity. Users can share with guests already in your organization's directory, and they can send invitations to people who will be added to the directory if they sign in. Existing guests Allows sharing only with guests who are already in the directory. These guests might exist in your directory because they previously accepted sharing invitations or because they were added manually, such as through Azure business-to-business (B2B) collaboration. Only people in your organization Doesn't allow external sharing. Managing sharing To configure these permissions for a site, you use the Set-SPOSite cmdlet with the -SharingCapability parameter. Valid values for the -SharingCapability parameter are: ExternalUserAndGuestSharing ExternalUserSharingOnly ExistingExternalUserSharingOnly Disabled The following example disables external sharing for a site: Set-SPOSite -https :// adatum . sharepoint . com / sites / Marketing -SharingCapability Disabled When you allow sharing with external users, you can restrict sharing based on the user domain by using the -SharingDomainRestrictionMode parameter. The following table describes the valid values. Value Description None Doesn't restrict sharing by domain (default). AllowList Allows sharing only with external users that have an account on domains specified by using the -SharingAllowedDomainList parameter. BlockList Allows Sharing with external users in all domains except in domains specified by using the -SharingBlockedDomainList parameter. Managing sharing links When a user shares content from a SharePoint site, a sharing link is sent to the recipient. This link is unique and includes information, such as permissions, to edit the file and who can use it. You can use the -DefaultLinkSharingType parameter to specify the default value for the users who can use the sharing link. Users that are sharing can still select the option that they prefer. The following table lists the valid values. Value Description None Uses the value set at the tenant level. AnonymousAccess Sets the default sharing link for this site to an Anonymous Access or Anyone link. Internal Sets the default sharing link for this site to the organization link or company shareable link. Direct Sets the default sharing link for this site to the Specific people link. You can use the -DefaultLinkPermission parameter to specify the default value for what users can do to the content via the sharing link. Users that are sharing can still select the option that they prefer. The following table lists the valid values. Value Description None Uses the value set at the tenant level. View Set the default value to View permissions. Edit Sets the default value to Edit permissions. You can configure an expiration time for external sharing links. After a link expires, it can no longer be used to access the linked content. The expiration time can be set independently for anonymous and external users. The following table lists parameters that you can use to configure link expiration for a site. Parameter Description -OverrideTenantAnonymousLinkExpirationPolicy To set an expiration time for anonymous links at the site level, set this value to $true. When set to $false, anonymous link expiration settings from the tenant level are used. -AnonymousLinkExpirationInDays This sets the number of days that an anonymous link is valid. -OverrideTenantExternalUserExpirationPolicy To set an expiration time for external user links at the site level, set this value to $true. When set to $false, external user link expiration settings from the tenant level are used. -ExternalUserExpirationInDays This sets the number of days that an external user link is valid. You can configure some sharing settings at the tenant level by using the Set-SPOTenant cmdlet. Takeaways SharePoint Online is used to create sites for user collaboration and file storage in addition to being used as storage for other Microsoft 365 services. You can use the web-based SharePoint admin center to manage many SharePoint Online features. However, for certain advanced operations, you will need the SharePoint Online Management Shell, a Windows PowerShell module. To provide access to a SharePoint site, you can assign users and groups varying levels of site permissions. To assign permissions in SharePoint Online by using PowerShell, you create SharePoint groups. To give permissions to Azure AD users, you must make them members of a SharePoint group. In SharePoint Online, you can have multiple sites that contain different content. There's a default site designed for collaboration that's created automatically when you create your tenant. There are also sites created automatically for each Microsoft 365 group or Microsoft Team and OneDrive users. Additionally, you can create your own SharePoint sites and customize them. Microsoft OneDrive storage is part of SharePoint Online, because of which there are similar settings for both. When you configure settings for external sharing, the OneDrive settings must be the same or more restrictive than the SharePoint Online settings.","title":"SharePoint"},{"location":"Net/365-sp/#installation","text":"You install the SharePoint Online Management Shell from the PowerShell Gallery by running the following command: Install-Module -Name Microsoft . Online . SharePoint . PowerShell The SharePoint Online Management Shell doesn't update automatically. To update the module, run the following command: Update-Module -Name Microsoft . Online . SharePoint . PowerShell","title":"Installation"},{"location":"Net/365-sp/#connection","text":"All of the cmdlet nouns in the SharePoint Online Management Shell begin with SPO. You can connect to SharePoint Online by using the Connect-SPOService cmdlet as in the following example: Connect-SPOService -Url https :// adatum-admin . sharepoint . com When you connect to SharePoint Online, you need to provide the URL for your SharePoint Online instance. This URL is based on your Microsoft 365 tenant name. For example, if your Microsoft 365 tenant name is adatum.onmicrosoft.com, then the URL for administering SharePoint Online is adatum-admin.sharepoint.com. You can also find this URL when you sign in to SharePoint admin center. To sign in by using Connect-SPOService, you need a user account with either SharePoint Admin or Global Administrator permissions for the Microsoft 365 tenant.","title":"Connection"},{"location":"Net/365-sp/#users-and-groups","text":"To provide access to a SharePoint site, you can assign users and groups varying levels of site permissions. Some of the permissions available by default are: Full Control Design Edit Approve Contribute Read You can create customized permission levels by using SharePoint admin center. There are no cmdlets in SharePoint Online Management Shell for creating or modifying customized permission levels.","title":"Users and Groups"},{"location":"Net/365-sp/#sharepoint-groups","text":"To assign permissions in SharePoint Online by using PowerShell, you create SharePoint groups. SharePoint groups exist only in SharePoint Online and are specific to the site in which you create them. The following example depicts how to use the New-SPOSiteGroup cmdlet to create a SharePoint Online group and assign permissions for a site: New-SPOSiteGroup -Group MarketingUsers -PermissionLevels Read -Site https :// adatum . sharepoint . com / sites / Marketing You can use the Get-SPOSiteGroup cmdlet to identify the SharePoint groups that have been created for a site and assigned permissions. The results also contain the group membership. You need to specify the site URL with the request as depicted in the following example: Get-SPOSiteGroup -Site https :// adatum . sharepoint . com / sites / Marketing You can modify the permissions assigned to a SharePoint group by using the Set-SPOSiteGroup cmdlet. You need to specify the name of the group and the site URL in addition to the permissions to be modified. To add permissions, use the -PermissionLevelsToAdd parameter. To remove permissions, use the -PermissionLevelsToRemove parameter. The following example uses the -PermissionLevelsToAdd parameter: Set-SPOSiteGroup -Site https :// adatum . sharepoint . com / sites / Marketing -Group MarketingUsers -PermissionLevelsToAdd Contribute","title":"SharePoint groups"},{"location":"Net/365-sp/#managing-site-users","text":"To give permissions to Azure AD users, you must make them members of a SharePoint group. You can add members to a SharePoint group by using the Add-SPOUser cmdlet as depicted in the following example. You need to specify the site URL along with the group name: Add-SPOUser -Site https :// adatum . sharepoint . com / sites / Marketing -Group MarketingUsers -LoginName AbbieP @adatum . com You can also add security groups from Azure AD as members of SharePoint groups by using the Add-SPOUser cmdlet. The Remove-SPOUser cmdlet has similar syntax to the Add-SPOUser cmdlet but removes a user from the specified SharePoint group. If you don't specify a group, then the user is removed from all SharePoint groups in the site. To review the users who are members of SharePoint groups, you can use the Get-SPOUser cmdlet. You need to specify the site URL from which to retrieve users, but the group is optional. If you don't specify the group, you'll receive a list of all users in the site and the SharePoint groups that they are members of. There is also a Set-SPOUser cmdlet but its only purpose is to set whether a user is an administrator for the site. The following example depicts how to configure a user as a site administrator: Set-SPOUser -Site https :// adatum . sharepoint . com / sites / Marketing -LoginName AbbieP @adatum . com -IsSiteCollectionAdmin $true","title":"Managing site users"},{"location":"Net/365-sp/#sp-sites","text":"In SharePoint Online, you can have multiple sites that contain different content. There's a default site designed for collaboration that's created automatically when you create your tenant. There are also sites created automatically for each Microsoft 365 group or Microsoft Team and OneDrive users. Additionally, you can create your own SharePoint sites and customize them.","title":"SP Sites"},{"location":"Net/365-sp/#creating-sites","text":"You can use the New-SPOSite cmdlet to create new sites in SharePoint online. When you create a new site, the parameters in the following table are required. Parameter Description -Url The URL for the site, which needs to be with your SharePoint Online namespace. For example, if the default URL for your SharePoint Online tenant is https://adatum.sharepoint.com, then the URL for the site could be https://adatum.sharepoint.com/sites/Marketing. -Owner The owner of the site that can manage it. -StorageQuota The maximum size of the site in megabytes (MB). This must be less than the quota available in the tenant. The following example creates a new site with AbbieP@adatum.com as the owner and a 256 MB storage quota: New-SPOSite -Url https :// adatum . sharepoint . com / sites / Marketing -Owner AbbieP @adatum . com -StorageQuota 256 Most of the time when you create a site, you'll want to base it on a template. A template defines components that are automatically included in a site. There are templates included in SharePoint Online by default and you can also make your own. To review the template in your SharePoint Online tenant, use the Get-SPOWebTemplate cmdlet. To use a template when creating a site with the New-SPOSite cmdlet, use the -Template parameter.","title":"Creating sites"},{"location":"Net/365-sp/#modifying-sites","text":"You can use the Set-SPOSite cmdlet to modify existing sites. To define which site you want to modify, use the -Identity parameter and provide the URL for the site. The URL for a site is a unique identifier for the site, and you cannot modify it by using Set-SPOSite. The following table lists some parameters you can use with Set-SPOSite. Parameter Description -Title Sets the title for the site. The title typically displays when users sign in to the site. For example, a title might be Marketing Portal. -StorageQuotaWarningLevel Sends a warning message to the site owner when the warning level is reached. This value should be less than the -StorageQuota. -AllowEditing Controls whether users are allowed to edit Office files in the browser, and copy and paste Office file content out of the browser window. -LockState Sets the lock state on a site. Valid values are: NoAccess, ReadOnly, and Unlock. The following example sets the title for a site: Set-SPOSite -Identity https :// adatum . sharepoint . com / sites / Marketing -Title \"Marketing Portal\"","title":"Modifying sites"},{"location":"Net/365-sp/#listing-and-reviewing-sites","text":"You can use the Get-SPOSite cmdlet to review the sites created in your SharePoint Online tenant and their configurations. To list all sites in your tenant, don't include any parameters. To list the specific site's properties, you use the -Identity parameter and specify the site's URL. The following example depicts how to list a specific site's properties: Get-SPOSite -Identity https :// adatum . sharepoint . com / sites / Marketing | Format-List","title":"Listing and reviewing sites"},{"location":"Net/365-sp/#removing-sites","text":"You use Remove-SPOSite to remove a site. The following example depicts how to use this cmdlet to remove a site: Remove-SPOSite -Identity https :// adatum . sharepoint . com / sites / Marketing When you remove a site, it's placed in the SharePoint Recycle Bin. You can use the Restore-SPODeletedSite cmdlet to restore a site from the SharePoint Recycle Bin. To purge a deleted site from the SharePoint Recycle Bin, you can use the Remove-SPODeletedSite cmdlet.","title":"Removing sites"},{"location":"Net/365-sp/#sharepoint-online-terminology","text":"The SharePoint admin center uses the site and sub-site terminology to describe how to nest content. When you create a sub-site, it inherits some of the settings from the site, such as the owner. If you're familiar with the on-premises version of SharePoint, it uses the terminology site collections and sites instead. When reviewing documentation for SharePoint Online cmdlets, you might notice that it often uses the on-premises site collections terminology. There are no cmdlets for managing sites within site collections (or sub-sites).","title":"SharePoint Online terminology"},{"location":"Net/365-sp/#external-users","text":"SharePoint Online content can be shared with external users. Because Microsoft OneDrive storage is part of SharePoint Online, there are similar settings for both. When you configure settings for external sharing, the OneDrive settings must be the same or more restrictive than the SharePoint Online settings. The commonly used external sharing settings for SharePoint Online are listed in the following table. Permission level Description Anyone Allows users to share files and folders by using links that let anyone who has the link access the files or folders without authenticating. This setting also allows users to share sites with new and existing guests who authenticate. If you select this setting, you can restrict the Anyone links so that they expire within a specific number of days, or so that they provide only View permission. New and existing guests Requires people who have received invitations to sign in with their work or school account (if their organization uses Microsoft 365). Alternatively, they can use a Microsoft account, or provide a code to verify their identity. Users can share with guests already in your organization's directory, and they can send invitations to people who will be added to the directory if they sign in. Existing guests Allows sharing only with guests who are already in the directory. These guests might exist in your directory because they previously accepted sharing invitations or because they were added manually, such as through Azure business-to-business (B2B) collaboration. Only people in your organization Doesn't allow external sharing.","title":"External Users"},{"location":"Net/365-sp/#managing-sharing","text":"To configure these permissions for a site, you use the Set-SPOSite cmdlet with the -SharingCapability parameter. Valid values for the -SharingCapability parameter are: ExternalUserAndGuestSharing ExternalUserSharingOnly ExistingExternalUserSharingOnly Disabled The following example disables external sharing for a site: Set-SPOSite -https :// adatum . sharepoint . com / sites / Marketing -SharingCapability Disabled When you allow sharing with external users, you can restrict sharing based on the user domain by using the -SharingDomainRestrictionMode parameter. The following table describes the valid values. Value Description None Doesn't restrict sharing by domain (default). AllowList Allows sharing only with external users that have an account on domains specified by using the -SharingAllowedDomainList parameter. BlockList Allows Sharing with external users in all domains except in domains specified by using the -SharingBlockedDomainList parameter.","title":"Managing sharing"},{"location":"Net/365-sp/#managing-sharing-links","text":"When a user shares content from a SharePoint site, a sharing link is sent to the recipient. This link is unique and includes information, such as permissions, to edit the file and who can use it. You can use the -DefaultLinkSharingType parameter to specify the default value for the users who can use the sharing link. Users that are sharing can still select the option that they prefer. The following table lists the valid values. Value Description None Uses the value set at the tenant level. AnonymousAccess Sets the default sharing link for this site to an Anonymous Access or Anyone link. Internal Sets the default sharing link for this site to the organization link or company shareable link. Direct Sets the default sharing link for this site to the Specific people link. You can use the -DefaultLinkPermission parameter to specify the default value for what users can do to the content via the sharing link. Users that are sharing can still select the option that they prefer. The following table lists the valid values. Value Description None Uses the value set at the tenant level. View Set the default value to View permissions. Edit Sets the default value to Edit permissions. You can configure an expiration time for external sharing links. After a link expires, it can no longer be used to access the linked content. The expiration time can be set independently for anonymous and external users. The following table lists parameters that you can use to configure link expiration for a site. Parameter Description -OverrideTenantAnonymousLinkExpirationPolicy To set an expiration time for anonymous links at the site level, set this value to $true. When set to $false, anonymous link expiration settings from the tenant level are used. -AnonymousLinkExpirationInDays This sets the number of days that an anonymous link is valid. -OverrideTenantExternalUserExpirationPolicy To set an expiration time for external user links at the site level, set this value to $true. When set to $false, external user link expiration settings from the tenant level are used. -ExternalUserExpirationInDays This sets the number of days that an external user link is valid. You can configure some sharing settings at the tenant level by using the Set-SPOTenant cmdlet.","title":"Managing sharing links"},{"location":"Net/365-sp/#takeaways","text":"SharePoint Online is used to create sites for user collaboration and file storage in addition to being used as storage for other Microsoft 365 services. You can use the web-based SharePoint admin center to manage many SharePoint Online features. However, for certain advanced operations, you will need the SharePoint Online Management Shell, a Windows PowerShell module. To provide access to a SharePoint site, you can assign users and groups varying levels of site permissions. To assign permissions in SharePoint Online by using PowerShell, you create SharePoint groups. To give permissions to Azure AD users, you must make them members of a SharePoint group. In SharePoint Online, you can have multiple sites that contain different content. There's a default site designed for collaboration that's created automatically when you create your tenant. There are also sites created automatically for each Microsoft 365 group or Microsoft Team and OneDrive users. Additionally, you can create your own SharePoint sites and customize them. Microsoft OneDrive storage is part of SharePoint Online, because of which there are similar settings for both. When you configure settings for external sharing, the OneDrive settings must be the same or more restrictive than the SharePoint Online settings.","title":"Takeaways"},{"location":"Net/365-teams/","text":"Microsoft Teams is a collaboration service that combines multiple Microsoft 365 services into a single interface. It's a user-friendly service that users with limited training can manage. As a result, it's a useful tool for workgroups and projects. You can use the Microsoft Teams PowerShell module to perform tasks such as creating teams and managing user permissions. Microsoft Teams combines many elements of Microsoft 365\u2014such as Microsoft 365 groups, Exchange Online, and SharePoint storage\u2014into a single location for collaboration. You can install the Microsoft Teams module to manage Microsoft Teams by using Windows PowerShell. You can create and configure Microsoft Teams by using cmdlets with a noun that starts with Team, such as the following cmdlets: Get-Team Add-TeamUser New-TeamsApp The Microsoft Teams module also includes many functions. These functions have the same verb-noun naming format as other cmdlets, but with a noun that starts with CsTeam. For example, the following cmdlets are included in the Microsoft Teams module: Set-CsTeamsMeetingPolicy Remove-CsTeamTemplate New-CsTeamsEmergencyCallingPolicy Get-CsTeamsMessagingPolicy The functions in the Microsoft Teams module are for configuring of the overall service, but not individual Teams. Also included are commands that you can use to create and configure user policies, and to control and manage communications. Installation You can install the Microsoft Teams module from the PowerShell Gallery. To install the Microsoft Teams module, run the following command: Install-Module -Name MicrosoftTeams The Microsoft Teams module doesn't update automatically. To update the SharePoint Online Management Shell, run the following command: Update-Module -Name MicrosoftTeams You can connect to Microsoft Teams by using the Connect-MicrosoftTeams cmdlet with no additional parameters. When you connect to Microsoft Teams, you're prompted for a username and password to sign in. You might also be prompted for multifactor authentication. Be sure to sign in with a user account that has sufficient privileges to perform the actions you want to complete. Teams Microsoft Teams is a collaboration tool. Within a Microsoft Team, you can create multiple channels to organize data and apps. When there are multiple channels, you can restrict access to channels based on the user. You can use the Microsoft Teams PowerShell module to create, configure, and manage teams, user settings, and channels. Creating teams To create a new team, you use the New-Team cmdlet as depicted in the following example: New-Team -DisplayName \"Marketing Team\" When you create a new team by using PowerShell, you can't specify a template unless you're an education customer. When you create a team from within the Microsoft Teams client, you can specify a template or copy an existing team. You have the same options when creating a team by using Graph API. To get a list of available templates, use the Get-CsTeamTemplateList cmdlet. You can also create your own templates. You can convert an existing Microsoft 365 group to a team by using the -GroupId parameter when creating a new team. If you don't specify an owner when you create a team, then by default you become the owner of the team. If your administrative user doesn't have a Microsoft Teams license, you need to specify an owner with a Microsoft Teams license. Otherwise, the team creation fails. Configuring teams When you create a new team, a new Microsoft 365 group is created as part of the team. When you manage an existing team, you need to refer to the Microsoft 365 group ID as the unique identifier for the team. The group ID displays when you create the group. You can also obtain the group ID by using the Get-Team cmdlet. You can modify team settings by using the Set-Team cmdlet. Some parameters that you can use are listed in the following table. Parameter Description -Description Provides a description of the team (1,024 characters or less) to make it easier for users to identify the team's purpose. -MailNickName Specifies the alias for the associated Microsoft 365 group that's used when creating the PrimarySmtpAddress. -Visibility Determines whether the team is public or private. Public teams are noticeable to everyone in the team gallery, and anyone can join without team owner approval. Whereas private teams can only be joined if the team owner adds someone to them. -AllowAddRemoveApps Determines whether or not members (and not just owners) are allowed to add apps to the team. -AllowCreateUpdateChannels Determines whether or not members (and not just owners) are allowed to create channels. -AllowUserEditMessages Determines whether or not users can edit messages that they've posted. You can also use these same parameters when you create the team. The following example depicts how to specify the mail nickname: Set-Team -GroupId 26be526d - 201a - 4af6 - 9918 - 2fdbf6306916 -MailNickName \"MarketingTeam\" Managing team members After you create a team, you can manage team members by using the Add-TeamUser and Remove-TeamUser cmdlets. You can add users as members or owners. When you use these cmdlets, you need to specify the GroupId associated with the team as in the following example: Add-TeamUser -GroupId 26be526d - 201a - 4af6 - 9918 - 2fdbf6306916 -User AbbieP @adatum . com -Role Member Creating and configuring team channels A team can have multiple channels that contain content. The following table depicts some of the cmdlets that you can use to create and manage channels. Cmdlet Description New-TeamChannel Creates a new channel in a team. Get-TeamChannel Lists the channels in a set. Set-TeamChannel Modifies the display name or description for a channel. Add-TeamChannelUser Adds a user as a member or owner of a channel. Remove-TeamChannelUser Removes a user from a channel.","title":"Teams"},{"location":"Net/365-teams/#installation","text":"You can install the Microsoft Teams module from the PowerShell Gallery. To install the Microsoft Teams module, run the following command: Install-Module -Name MicrosoftTeams The Microsoft Teams module doesn't update automatically. To update the SharePoint Online Management Shell, run the following command: Update-Module -Name MicrosoftTeams You can connect to Microsoft Teams by using the Connect-MicrosoftTeams cmdlet with no additional parameters. When you connect to Microsoft Teams, you're prompted for a username and password to sign in. You might also be prompted for multifactor authentication. Be sure to sign in with a user account that has sufficient privileges to perform the actions you want to complete.","title":"Installation"},{"location":"Net/365-teams/#teams","text":"Microsoft Teams is a collaboration tool. Within a Microsoft Team, you can create multiple channels to organize data and apps. When there are multiple channels, you can restrict access to channels based on the user. You can use the Microsoft Teams PowerShell module to create, configure, and manage teams, user settings, and channels.","title":"Teams"},{"location":"Net/365-teams/#creating-teams","text":"To create a new team, you use the New-Team cmdlet as depicted in the following example: New-Team -DisplayName \"Marketing Team\" When you create a new team by using PowerShell, you can't specify a template unless you're an education customer. When you create a team from within the Microsoft Teams client, you can specify a template or copy an existing team. You have the same options when creating a team by using Graph API. To get a list of available templates, use the Get-CsTeamTemplateList cmdlet. You can also create your own templates. You can convert an existing Microsoft 365 group to a team by using the -GroupId parameter when creating a new team. If you don't specify an owner when you create a team, then by default you become the owner of the team. If your administrative user doesn't have a Microsoft Teams license, you need to specify an owner with a Microsoft Teams license. Otherwise, the team creation fails.","title":"Creating teams"},{"location":"Net/365-teams/#configuring-teams","text":"When you create a new team, a new Microsoft 365 group is created as part of the team. When you manage an existing team, you need to refer to the Microsoft 365 group ID as the unique identifier for the team. The group ID displays when you create the group. You can also obtain the group ID by using the Get-Team cmdlet. You can modify team settings by using the Set-Team cmdlet. Some parameters that you can use are listed in the following table. Parameter Description -Description Provides a description of the team (1,024 characters or less) to make it easier for users to identify the team's purpose. -MailNickName Specifies the alias for the associated Microsoft 365 group that's used when creating the PrimarySmtpAddress. -Visibility Determines whether the team is public or private. Public teams are noticeable to everyone in the team gallery, and anyone can join without team owner approval. Whereas private teams can only be joined if the team owner adds someone to them. -AllowAddRemoveApps Determines whether or not members (and not just owners) are allowed to add apps to the team. -AllowCreateUpdateChannels Determines whether or not members (and not just owners) are allowed to create channels. -AllowUserEditMessages Determines whether or not users can edit messages that they've posted. You can also use these same parameters when you create the team. The following example depicts how to specify the mail nickname: Set-Team -GroupId 26be526d - 201a - 4af6 - 9918 - 2fdbf6306916 -MailNickName \"MarketingTeam\"","title":"Configuring teams"},{"location":"Net/365-teams/#managing-team-members","text":"After you create a team, you can manage team members by using the Add-TeamUser and Remove-TeamUser cmdlets. You can add users as members or owners. When you use these cmdlets, you need to specify the GroupId associated with the team as in the following example: Add-TeamUser -GroupId 26be526d - 201a - 4af6 - 9918 - 2fdbf6306916 -User AbbieP @adatum . com -Role Member Creating and configuring team channels A team can have multiple channels that contain content. The following table depicts some of the cmdlets that you can use to create and manage channels. Cmdlet Description New-TeamChannel Creates a new channel in a team. Get-TeamChannel Lists the channels in a set. Set-TeamChannel Modifies the display name or description for a channel. Add-TeamChannelUser Adds a user as a member or owner of a channel. Remove-TeamChannelUser Removes a user from a channel.","title":"Managing team members"},{"location":"Net/365-users/","text":"Before users can sign in and begin using Microsoft 365 services, you need to create user accounts for them. After you create the accounts, you might need to modify them. You can manage users in Microsoft 365 by using both Msol and AzureAD cmdlets. In both cases, you need to connect to Microsoft 365 before you can create and manage user accounts. The following table lists the user attributes that you need to consider when creating user accounts. Property Required Description DisplayName Yes This is the name that displays for users in the web-based management tools. UserPrincipalName Yes This is the name that people use to sign in to Microsoft 365. This is also a unique identifier that you use when performing management tasks with PowerShell cmdlets. GivenName/FirstName No This property can be used by various Microsoft 365 services such as the Exchange Online address book. SurName/LastName No This property can be used by various Microsoft 365 services such as the Exchange Online address book. Password No A password is required to enable a user account. When you create a user with the New-AzureADUser cmdlet, you must set a password. LicenseAssignment No This property specifies the licensing plan for the user, which in turn determines which Microsoft 365 services the user can access. You can assign licenses after you create the user. UsageLocation No The usage location is a two-character country code. You can't assign a license if you haven't set a usage location. You can create user accounts in Microsoft 365 by using the New-AzureADUser cmdlet. The following code block depicts how you can use this cmdlet to create a new user account and set a password. The password is stored in an object required for that purpose. In this example, the -AccountEnabled parameter is set to $true to enable the account and allow the user to sign in. The -PasswordProfile and -AccountEnabled parameters are required: $UserPassword = New-Object -TypeName Microsoft . Open . AzureAD . Model . PasswordProfile $UserPassword . Password = \"Pa55w.rd\" New-AzureADUser -DisplayName \"Abbie Parsons\" -GivenName \"Abbie\" -SurName \"Parsons\" -UserPrincipalName AbbieP @adatum . com -UsageLocation US -PasswordProfile $UserPassword -AccountEnabled $true You can query a list of user accounts in Microsoft 365 by using the Get-AzureADUser cmdlet. The following table lists commonly used parameters for this cmdlet. Parameter Description -ObjectID Specifies the user principle name (UPN) or ObjectID of a specific user account to retrieve. Both properties are unique identifiers for a user account in Microsoft 365. -Filter Specifies a filter in oPath format that you can use to query a specific set of user accounts. -SearchString Specifies a string that is matched against the start of the DisplayName and UserPrincipalName attributes. -All By default, Get-AzureADUser returns only 100 results. If you set the -All parameter to $true, then all results are returned. The default value for this parameter is $false. -Top When the -All parameter is $false, you can use -Top to specify the maximum number of results to return. The oPath format used for filters doesn't support using wildcards. If you need to perform a wildcard search of user accounts, you need to retrieve all the user accounts and then filter them by using the Where-Object cmdlet. The following example depicts how to query a single Microsoft 365 user account: Get-AzureADUser -ObjectId AbbieP @adatum . com The following example depicts how to query all the user accounts in a Microsoft 365 tenant: Get-AzureADUser -All $true AzureAD cmdlets for user account management Cmdlet Description Set-AzureADUser Modifies the properties of a user account. Remove-AzureADUser Deletes a user account. Set-AzureADUserPassword Sets the password for a user account. Get-AzureADMSDeletedDirectoryObject Lists soft-deleted user accounts. Synchronized users Users that you create in Microsoft 365 with Windows PowerShell are cloud users. Many organizations use Azure AD Connect to synchronize users and groups from on-premises AD DS to Microsoft 365. These users and groups are created by Azure AD Connect. and as such you can't delete them directly in Microsoft 365. Instead, you need to delete the object in AD DS, and the deletion is synchronized to Microsoft 365. When objects are synchronized from AD DS to Microsoft 365, the value of some attributes in AD DS is authoritative. This means you can't modify the attribute's value in Microsoft 365. Instead, you need to modify the value in AD DS, and then the modified value synchronizes to Microsoft 365. Attempting to modify these attributes in Microsoft 365 will generate an error. The following list is some of the common attributes for which AD DS is authoritative: UserPrincipalName DisplayName AccountEnabled ProxyAddresses (email addresses)","title":"Users"},{"location":"Net/365-users/#synchronized-users","text":"Users that you create in Microsoft 365 with Windows PowerShell are cloud users. Many organizations use Azure AD Connect to synchronize users and groups from on-premises AD DS to Microsoft 365. These users and groups are created by Azure AD Connect. and as such you can't delete them directly in Microsoft 365. Instead, you need to delete the object in AD DS, and the deletion is synchronized to Microsoft 365. When objects are synchronized from AD DS to Microsoft 365, the value of some attributes in AD DS is authoritative. This means you can't modify the attribute's value in Microsoft 365. Instead, you need to modify the value in AD DS, and then the modified value synchronizes to Microsoft 365. Attempting to modify these attributes in Microsoft 365 will generate an error. The following list is some of the common attributes for which AD DS is authoritative: UserPrincipalName DisplayName AccountEnabled ProxyAddresses (email addresses)","title":"Synchronized users"},{"location":"Net/az-mod/","text":"Azure PowerShell is a module that you add to Windows PowerShell or PowerShell Core to let you connect to your Azure subscription and manage resources. It provides a set of cmdlets that you can use to manage and administer Azure resources directly from the PowerShell command line. Azure PowerShell makes it easier to interact with Azure, but also provides powerful features for automation. PowerShell provides powerful features for automation that you can use to manage your Azure resources; for example, in the context of a continuous integration and continuous delivery (CI/CD) pipeline. The Az PowerShell module is the replacement for AzureRM and is the recommended version to use for interacting with Azure. To keep up with the latest Azure features in PowerShell, you should migrate to the Az PowerShell module. Benefits of the Az PowerShell module The Az PowerShell module features the following benefits: Security and stability: Token cache encryption Prevention of man-in-the-middle attack type Support for authentication with Active Directory Federation Services (AD FS) in Windows Server 2019 Username and password authentication in PowerShell 7 Support for features such as continuous access evaluation Support for all Azure services: All generally available Azure services have a corresponding supported PowerShell module Multiple bug fixes and API version upgrades since AzureRM New capabilities: Support in Cloud Shell and cross-platform Ability to get and use access tokens to access Azure resources Cmdlets for advanced Representational State Transfer (REST) operations with Azure resources The Az PowerShell module is based on the .NET Standard library and works with PowerShell 7 and newer on all platforms including Windows, macOS, and Linux. It's also compatible with Windows PowerShell 5.1. Installation The Azure Az PowerShell module is a rollup module. Installing it downloads the available Az PowerShell modules and makes their cmdlets available for use. The Azure Az PowerShell module works with PowerShell 7.x and newer versions on all platforms. Azure PowerShell has no additional requirements when you run it on PowerShell 7.x and newer versions. To check your PowerShell version, run the following command from within a PowerShell session: $PSVersionTable . PSVersion Before installing the Azure Az PowerShell module, you should set your PowerShell script execution policy to RemoteSigned. You can do this by running the following command: Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser You can install the Azure Az PowerShell module by using one of the following methods: The Install-Module cmdlet Azure PowerShell MSI Az PowerShell Docker container The Azure Az PowerShell module is preinstalled in Azure Cloud Shell. You can use it directly from the browser, without installing anything locally on your machine. The Install-Module cmdlet Using the Install-Module cmdlet is the preferred installation method for the Azure Az PowerShell module. You should install this module for the current user only. This is the recommended installation scope. This method works the same on Windows, macOS, and Linux platforms. To install the Az module, run the following command from a local PowerShell session: Install-Module -Name Az -Scope CurrentUser -Repository PSGallery -Force Although PowerShell 7.x is the recommended version of PowerShell, and Install-Module is the recommended installation option, you can also install the Az module within PowerShell 5.1 environment on Windows. If you're on Windows 10 version 1607 or higher, you already have PowerShell 5.1 installed. You should also make sure that you have .NET Framework 4.7.2 or newer installed and the latest version of PowerShellGet. To install the latest version of the PowerShellGet module within PowerShell 5.1, run the following command: Install-Module -Name PowerShellGet -Force You can then install the Az module by using the same command you use in PowerShell 7.1. Azure PowerShell MSI In some environments, it isn't possible to connect to the PowerShell Gallery. In such situations, you can install the Az PowerShell module offline, by downloading the Azure PowerShell MSI package. Keep in mind that the MSI installer only works for PowerShell 5.1 on Windows. To update any PowerShell module, you should use the same method used to install the module. For example, if you originally used Install-Module, then you should use Update-Module to get the latest version. If you originally used the MSI package, then you should download and install the new MSI package. Az PowerShell Docker container It's also possible to run Azure PowerShell inside a Docker image. Microsoft provides Docker images with Azure PowerShell preinstalled. The released images require Docker 17.05 or newer. The latest container image contains the latest version of PowerShell and the latest Azure PowerShell modules supported with the Az module. To download the image and start an interactive PowerShell session, you should run the following commands: docker pull mcr . microsoft . com / azure-powershell docker run -it mcr . microsoft . com / azure-powershell pwsh Start To start working in the Azure PowerShell environment, you should first sign in with your Azure credentials. This step is different from working in pure PowerShell. Your Azure credentials are the same credentials you use to sign in to the Azure portal or other Azure-based resources. To sign in to Azure from Azure PowerShell, run the following command: Connect-AzAccount After running this command, you'll be prompted to sign in with your Azure credentials. After you successfully authenticate to Azure, you can start using commands from the Az module to manage your Azure resources. Azure AD The Azure Active Directory Module for Windows PowerShell provides cmdlets that you can use for Azure Active Directory (Azure AD) administrative tasks. These tasks include user management, domain management, and configuring single sign-on. This topic includes information about how to install these cmdlets for use with your directory. You mostly need the Azure Active Directory Module for Windows PowerShell when you manage users, groups, and services such as Microsoft 365. However, Microsoft is replacing the Azure Active Directory Module for Windows PowerShell with Azure Active Directory PowerShell for Graph. The Azure Active Directory Module for Windows PowerShell cmdlets include Msol in their names, while the Azure Active Directory PowerShell for Graph cmdlets use AzureAD in their names. Azure Active Directory Module for Windows PowerShell The following Windows operating systems support the Azure Active Directory Module for Windows PowerShell, with the default version of Microsoft .NET Framework and Windows PowerShell: Windows 8.1 Windows 8 Windows 7 Windows Server 2012 R2 Windows Server 2012 Windows Server 2008 R2 The easiest way to install the module is from the PowerShell Gallery. You can install the module with the Install-Module cmdlet by running the following command: Install-Module MSOnline Azure Active Directory PowerShell for Graph Currently, the Azure Active Directory PowerShell for Graph module doesn't completely replace the functionality of the Azure Active Directory Module for Windows PowerShell module for user, group, and license administration. In some cases, you need to use both versions. You can safely install both versions on the same computer. The Azure AD PowerShell for Graph module has two versions: a Public Preview version and a General Availability version. It isn't recommended to use the Public Preview version for production scenarios. Connecting to Azure AD If you want to connect to the Azure AD service with the Azure Active Directory Module for Windows PowerShell, run the following command: Connect-MsolService If you use the Azure AD PowerShell for Graph module, and want to connect to Azure AD, run the following command: Connect-AzureAD After running either of the previous commands, you'll be prompted for your Azure AD credentials. You should use the credentials that you use to sign in to Microsoft 365 or your Azure services. After you authenticate, you'll be able to use the cmdlets available for Azure AD management. Additional reading: For more information about the Azure Active Directory PowerShell for Graph cmdlets, refer to AzureAD . Additional reading: For more information about the Azure Active Directory Module for Windows PowerShell cmdlets, refer to MSOnline .","title":"Azure Powershell"},{"location":"Net/az-mod/#benefits-of-the-az-powershell-module","text":"The Az PowerShell module features the following benefits: Security and stability: Token cache encryption Prevention of man-in-the-middle attack type Support for authentication with Active Directory Federation Services (AD FS) in Windows Server 2019 Username and password authentication in PowerShell 7 Support for features such as continuous access evaluation Support for all Azure services: All generally available Azure services have a corresponding supported PowerShell module Multiple bug fixes and API version upgrades since AzureRM New capabilities: Support in Cloud Shell and cross-platform Ability to get and use access tokens to access Azure resources Cmdlets for advanced Representational State Transfer (REST) operations with Azure resources The Az PowerShell module is based on the .NET Standard library and works with PowerShell 7 and newer on all platforms including Windows, macOS, and Linux. It's also compatible with Windows PowerShell 5.1.","title":"Benefits of the Az PowerShell module"},{"location":"Net/az-mod/#installation","text":"The Azure Az PowerShell module is a rollup module. Installing it downloads the available Az PowerShell modules and makes their cmdlets available for use. The Azure Az PowerShell module works with PowerShell 7.x and newer versions on all platforms. Azure PowerShell has no additional requirements when you run it on PowerShell 7.x and newer versions. To check your PowerShell version, run the following command from within a PowerShell session: $PSVersionTable . PSVersion Before installing the Azure Az PowerShell module, you should set your PowerShell script execution policy to RemoteSigned. You can do this by running the following command: Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser You can install the Azure Az PowerShell module by using one of the following methods: The Install-Module cmdlet Azure PowerShell MSI Az PowerShell Docker container The Azure Az PowerShell module is preinstalled in Azure Cloud Shell. You can use it directly from the browser, without installing anything locally on your machine.","title":"Installation"},{"location":"Net/az-mod/#the-install-module-cmdlet","text":"Using the Install-Module cmdlet is the preferred installation method for the Azure Az PowerShell module. You should install this module for the current user only. This is the recommended installation scope. This method works the same on Windows, macOS, and Linux platforms. To install the Az module, run the following command from a local PowerShell session: Install-Module -Name Az -Scope CurrentUser -Repository PSGallery -Force Although PowerShell 7.x is the recommended version of PowerShell, and Install-Module is the recommended installation option, you can also install the Az module within PowerShell 5.1 environment on Windows. If you're on Windows 10 version 1607 or higher, you already have PowerShell 5.1 installed. You should also make sure that you have .NET Framework 4.7.2 or newer installed and the latest version of PowerShellGet. To install the latest version of the PowerShellGet module within PowerShell 5.1, run the following command: Install-Module -Name PowerShellGet -Force You can then install the Az module by using the same command you use in PowerShell 7.1.","title":"The Install-Module cmdlet"},{"location":"Net/az-mod/#azure-powershell-msi","text":"In some environments, it isn't possible to connect to the PowerShell Gallery. In such situations, you can install the Az PowerShell module offline, by downloading the Azure PowerShell MSI package. Keep in mind that the MSI installer only works for PowerShell 5.1 on Windows. To update any PowerShell module, you should use the same method used to install the module. For example, if you originally used Install-Module, then you should use Update-Module to get the latest version. If you originally used the MSI package, then you should download and install the new MSI package.","title":"Azure PowerShell MSI"},{"location":"Net/az-mod/#az-powershell-docker-container","text":"It's also possible to run Azure PowerShell inside a Docker image. Microsoft provides Docker images with Azure PowerShell preinstalled. The released images require Docker 17.05 or newer. The latest container image contains the latest version of PowerShell and the latest Azure PowerShell modules supported with the Az module. To download the image and start an interactive PowerShell session, you should run the following commands: docker pull mcr . microsoft . com / azure-powershell docker run -it mcr . microsoft . com / azure-powershell pwsh","title":"Az PowerShell Docker container"},{"location":"Net/az-mod/#start","text":"To start working in the Azure PowerShell environment, you should first sign in with your Azure credentials. This step is different from working in pure PowerShell. Your Azure credentials are the same credentials you use to sign in to the Azure portal or other Azure-based resources. To sign in to Azure from Azure PowerShell, run the following command: Connect-AzAccount After running this command, you'll be prompted to sign in with your Azure credentials. After you successfully authenticate to Azure, you can start using commands from the Az module to manage your Azure resources.","title":"Start"},{"location":"Net/az-mod/#azure-ad","text":"The Azure Active Directory Module for Windows PowerShell provides cmdlets that you can use for Azure Active Directory (Azure AD) administrative tasks. These tasks include user management, domain management, and configuring single sign-on. This topic includes information about how to install these cmdlets for use with your directory. You mostly need the Azure Active Directory Module for Windows PowerShell when you manage users, groups, and services such as Microsoft 365. However, Microsoft is replacing the Azure Active Directory Module for Windows PowerShell with Azure Active Directory PowerShell for Graph. The Azure Active Directory Module for Windows PowerShell cmdlets include Msol in their names, while the Azure Active Directory PowerShell for Graph cmdlets use AzureAD in their names.","title":"Azure AD"},{"location":"Net/az-mod/#azure-active-directory-module-for-windows-powershell","text":"The following Windows operating systems support the Azure Active Directory Module for Windows PowerShell, with the default version of Microsoft .NET Framework and Windows PowerShell: Windows 8.1 Windows 8 Windows 7 Windows Server 2012 R2 Windows Server 2012 Windows Server 2008 R2 The easiest way to install the module is from the PowerShell Gallery. You can install the module with the Install-Module cmdlet by running the following command: Install-Module MSOnline","title":"Azure Active Directory Module for Windows PowerShell"},{"location":"Net/az-mod/#azure-active-directory-powershell-for-graph","text":"Currently, the Azure Active Directory PowerShell for Graph module doesn't completely replace the functionality of the Azure Active Directory Module for Windows PowerShell module for user, group, and license administration. In some cases, you need to use both versions. You can safely install both versions on the same computer. The Azure AD PowerShell for Graph module has two versions: a Public Preview version and a General Availability version. It isn't recommended to use the Public Preview version for production scenarios.","title":"Azure Active Directory PowerShell for Graph"},{"location":"Net/az-mod/#connecting-to-azure-ad","text":"If you want to connect to the Azure AD service with the Azure Active Directory Module for Windows PowerShell, run the following command: Connect-MsolService If you use the Azure AD PowerShell for Graph module, and want to connect to Azure AD, run the following command: Connect-AzureAD After running either of the previous commands, you'll be prompted for your Azure AD credentials. You should use the credentials that you use to sign in to Microsoft 365 or your Azure services. After you authenticate, you'll be able to use the cmdlets available for Azure AD management. Additional reading: For more information about the Azure Active Directory PowerShell for Graph cmdlets, refer to AzureAD . Additional reading: For more information about the Azure Active Directory Module for Windows PowerShell cmdlets, refer to MSOnline .","title":"Connecting to Azure AD"},{"location":"Net/az-res/","text":"Azure virtual machines (VMs) provide a fully configurable and flexible computing environment. You can create and manage these VMs by using the Azure portal, the Windows PowerShell with Az module, or the Cloud Shell environment. Besides managing Azure VMs, one of the most common usages of the PowerShell Az module is to manage Azure storage accounts and Azure subscriptions. Create an Azure VM To create a new Azure virtual machine (VM) with PowerShell commands, you can use the locally installed Windows PowerShell with Az module, or you can use the Cloud Shell environment that's available in Azure portal. If you choose to use your locally installed PowerShell, it's recommended that you use Windows PowerShell 7.1. You should also install the Az module, so you can have Azure-related commands available. Also, when using locally installed PowerShell, you first need to use the Connect-AzAccount command to authenticate and connect to your Azure tenant. When you run this command in your PowerShell environment, you'll be prompted to authenticate. You need to use credentials from your Azure tenant, with privileges that allow you to create the resources needed for Azure VMs. Create a resource group An Azure resource group is a logical container into which Azure resources are deployed and managed. You must create a resource group before you create a VM. In the following example, a resource group named myResourceGroup is created in the West Europe region: New-AzResourceGroup -ResourceGroupName \"myResourceGroup\" -Location \"westeurope\" The resource group is later used when creating or modifying a VM or the resources attached to a VM. Create an Azure VM The New-AzVM cmdlet creates a VM in Azure. This cmdlet uses a VM object as input. Use the New-AzVMConfig cmdlet to create a virtual machine object. When you're creating a VM, several options are available, such as operating system image, network configuration, and administrative credentials. You can use other cmdlets to configure the VM, such as Set-AzVMOperatingSystem, Set-AzVMSourceImage, Add-AzVMNetworkInterface, and Set-AzVMOSDisk. Additional reading: For more information about the parameters that you can use with the New-AzVM command, refer to New-AzVM . Before you run the New-AzVM command, you need to specify the credentials that you'll use to sign in to the newly created Azure VM. The credentials that you specify during this process will be assigned with local administrative privileges on the VM you're creating. It's easiest to store these credentials in a variable, before creating a new Azure VM. To do this, run this command: $cred = Get-Credential When you run this command, you'll be prompted to provide the username and password for the Azure VM. These credentials will be stored in the $cred variable. After you store administrative credentials, you need to define parameters for the new VM. You don't need to provide all the parameters that New-AzVM supports. Most of them are optional, and if you don't provide them, their default values will be selected. You can also change most of these parameters later. You can choose to provide VM parameters directly with the New-AzVM command, or you can define these parameters in a variable, and then use this variable with the New-AzVM command. The following code depicts an example of defining VM parameters: $vmParams = @{ ResourceGroupName = 'myResourceGroup' Name = 'TestVM' Location = 'westeurope' ImageName = 'Win2016Datacenter' PublicIpAddressName = 'TestPublicIp' Credential = $cred OpenPorts = 3389 } When you define VM parameters as the previous example depicts, you can then use the following command to create a new Azure VM, based on these parameters: New-AzVM @vmParams Alternatively, you can also choose to provide VM parameters directly with New-AzVM as in the following example: New-AzVm ` -ResourceGroupName \"myResourceGroup\" -Name \"myVM\" -Location \"EastUS\" -VirtualNetworkName \"myVnet\" -SubnetName \"mySubnet\" -SecurityGroupName \"myNetworkSecurityGroup\" -PublicIpAddressName \"myPublicIpAddress\" -Credential $cred Connect to the Azure VM After a new Azure VM is created, you need to connect to it to verify the deployment. After the deployment has completed, create a remote desktop connection with the VM. Run the following commands to return the public IP address of the VM. Take note of this IP address so you can connect to it with your browser to test web connectivity in a future step. Get-AzPublicIpAddress -ResourceGroupName \"myResourceGroup\" | Select IpAddress To create a remote desktop session with the VM, use the following command on your local machine. Replace the IP address with the publicIPAddress of your VM. When prompted, enter the credentials you used when creating the VM. mstsc / v :< publicIpAddress > When you run this command, you'll be prompted for credentials to connect to the VM. In the Windows Security window, select More choices, and then select Use a different account. Enter the username and password you created for the VM, and then select OK. After you connect to your Azure VM through Remote Desktop Protocol (RDP), you'll be able to manage it the same way as any other computer. Modifying VM sizes The VM size determines the amount of compute resources such as CPU, GPU, and memory that are made available to the VM. You should create VMs using a VM size that's appropriate for the workload. If a workload increases, you can also resize existing VMs. To review a list of VM sizes available in a particular region, use the Get-AzVMSize command. For example: Get-AzVMSize -Location \"EastUS\" After a VM has been deployed, you can resize it to increase or decrease resource allocation. Before resizing a VM, check if the size you want is available on the current VM cluster. The Get-AzVMSize command returns a list of sizes: Get-AzVMSize -ResourceGroupName \"myResourceGroup\" -VMName \"myVM\" If your preferred size is available, you can resize the VM from a powered-on state; however, it's rebooted during the operation. The following example depicts how to change VM size to the Standard_DS3_v2 size profile: $vm = Get-AzVM -ResourceGroupName \"myResourceGroupVM\" -VMName \"myVM\" $vm . HardwareProfile . VmSize = \"Standard_DS3_v2\" Update-AzVM -VM $vm -ResourceGroupName \"myResourceGroup\" Management tasks During the lifecycle of a VM, you might want to run management tasks such as starting, stopping, or deleting a VM. Additionally, you might want to create scripts to automate repetitive or complex tasks. You can use Azure PowerShell to perform many common management tasks by using the command line or scripts. To stop and deallocate a VM with Stop-AzVM, you can run the following command: Stop-AzVM -ResourceGroupName \"myResourceGroup\" -Name \"myVM\" -Force To start a VM, you can run the following command: Start-AzVM -ResourceGroupName \"myResourceGroup\" -Name \"myVM\" If you want to delete everything inside of a resource group, including VMs, you can run the following command: Remove-AzResourceGroup -Name \"myResourceGroupVM\" -Force Adding disks to Azure VMs When you create an Azure VM, two disks are automatically attached to the VM: Operating system disk. These disks can be sized up to 4 terabytes and host the VM's operating system. Temporary disk. These disks use a solid-state drive that's located on the same Azure host as the VM. Temporary disks are highly performant and might be used for operations such as temporary data processing. You can add additional data disks for installing applications and storing data. You should use data disks in any situation that requires durable and responsive data storage. The size of the VM determines how many data disks can be attached to it. To add a data disk to an Azure VM after you create it, you need to define disk configuration by using the New-AzDiskConfig command. You then need to use the New-AzDisk and Add-AzVMDataDisk commands to add a new disk to the VM, as the following example depicts: $diskConfig = New-AzDiskConfig -Location \"EastUS\" -CreateOption Empty -DiskSizeGB 128 $dataDisk = New-AzDisk -ResourceGroupName \"myResourceGroupDisk\" -DiskName \"myDataDisk\" -Disk $diskConfig $vm = Get-AzVM -ResourceGroupName \"myResourceGroupDisk\" -Name \"myVM\" $vm = Add-AzVMDataDisk -VM $vm -Name \"myDataDisk\" -CreateOption Attach -ManagedDiskId $dataDisk . Id -Lun 1 Update-AzVM -ResourceGroupName \"myResourceGroupDisk\" -VM $vm Storage You can use Azure PowerShell to manage Azure-related storage. Before you start managing your storage, you should first create a storage account, if you don't have one. Usually, storage accounts are created automatically when you create other Azure resources such as Azure virtual machines (VMs). You can create a standard, general-purpose storage account with locally redundant storage (LRS) replication by using New-AzStorageAccount. Next, get the storage account context that defines the storage account you want to use. When acting on a storage account, reference the context, instead of repeatedly passing in the credentials. Use the following example to create a storage account called mystorageaccount with LRS and blob encryption, which is enabled by default. $storageAccount = New-AzStorageAccount -ResourceGroupName $resourceGroup ` -Name \"mystorageaccount\" ` -SkuName Standard_LRS ` -Location $location ` $ctx = $storageAccount . Context Blobs are always uploaded into a container. You can organize groups of blobs the way you organize your files on your computer in folders. Set the container name, and then create the container by using New-AzStorageContainer. Set the blob permissions to allow public access of the files. The container name in the following example is quickstartblobs. $containerName = \"quickstartblobs\" New-AzStorageContainer -Name $containerName -Context $ctx -Permission blob You can use the Set-AzStorageAccount cmdlet to modify an Azure Storage account. You can use this cmdlet to modify the account type, update a customer domain, or set tags on a Storage account. For example, to set the storage account type you should use the following command: Set-AzStorageAccount -ResourceGroupName \"MyResourceGroup\" -AccountName \"mystorageaccount\" -Type \"Standard_RAGRS\" To set custom domain for existing storage account, you can use the following command: Set-AzStorageAccount -ResourceGroupName \"MyResourceGroup\" -AccountName \"mystorageaccount\" -CustomDomainName \"www.contoso.com\" -UseSubDomain $True Additional reading: To learn more about the available cmdlets for managing Azure storage, refer to Az.Storage . Azure Subscriptions Most Azure users will only ever have a single subscription. However, if you're part of more than one organization or your organization has divided up access to certain resources across groupings, you might have multiple subscriptions within Azure. In Azure PowerShell, accessing the resources for a subscription requires changing the subscription associated with your current Azure session. You can do this by modifying the active session context, which is the information about which tenant, subscription, and user the cmdlets should be run against. To change subscriptions, you need to first retrieve an Azure PowerShell Context object with Get-AzSubscription, and then change the current context with Set-AzContext. The Get-AzSubscription cmdlet gets the subscription ID, subscription name, and home tenant for subscriptions that the current account can access. To get all Azure subscriptions active on all tenants, run the following command: Get-AzSubscription Name Id TenantId State ---- -- -------- ----- Subscription1 yyyy-yyyy-yyyy-yyyy aaaa-aaaa-aaaa-aaaa Enabled Subscription2 xxxx-xxxx-xxxx-xxxx aaaa-aaaa-aaaa-aaaa Enabled Subscription3 zzzz-zzzz-zzzz-zzzz bbbb-bbbb-bbbb-bbbb Enabled To focus on subscriptions assigned to a specific tenant, run the following command: Get-AzSubscription -TenantId \"aaaa-aaaa-aaaa-aaaa\" Name Id TenantId State ---- -- -------- ----- Subscription1 yyyy-yyyy-yyyy-yyyy aaaa-aaaa-aaaa-aaaa Enabled Subscription2 xxxx-xxxx-xxxx-xxxx aaaa-aaaa-aaaa-aaaa Enabled The Set-AzContext cmdlet sets authentication information for cmdlets that you run in the current session. The context includes tenant, subscription, and environment information. To set the subscription context, run the following command: Set-AzContext -Subscription \"xxxx-xxxx-xxxx-xxxx\" Name Account SubscriptionName Environment TenantId ---- ------- ---------------- ----------- -------- Work test @outlook . com Subscription1 AzureCloud xxxxxxxx-x ... The next example depicts how to get a subscription in the currently active tenant and set it as the active session: $context = Get-AzSubscription -SubscriptionId ... Set-AzContext $context","title":"Azure Resources"},{"location":"Net/az-res/#create-an-azure-vm","text":"To create a new Azure virtual machine (VM) with PowerShell commands, you can use the locally installed Windows PowerShell with Az module, or you can use the Cloud Shell environment that's available in Azure portal. If you choose to use your locally installed PowerShell, it's recommended that you use Windows PowerShell 7.1. You should also install the Az module, so you can have Azure-related commands available. Also, when using locally installed PowerShell, you first need to use the Connect-AzAccount command to authenticate and connect to your Azure tenant. When you run this command in your PowerShell environment, you'll be prompted to authenticate. You need to use credentials from your Azure tenant, with privileges that allow you to create the resources needed for Azure VMs.","title":"Create an Azure VM"},{"location":"Net/az-res/#create-a-resource-group","text":"An Azure resource group is a logical container into which Azure resources are deployed and managed. You must create a resource group before you create a VM. In the following example, a resource group named myResourceGroup is created in the West Europe region: New-AzResourceGroup -ResourceGroupName \"myResourceGroup\" -Location \"westeurope\" The resource group is later used when creating or modifying a VM or the resources attached to a VM.","title":"Create a resource group"},{"location":"Net/az-res/#create-an-azure-vm_1","text":"The New-AzVM cmdlet creates a VM in Azure. This cmdlet uses a VM object as input. Use the New-AzVMConfig cmdlet to create a virtual machine object. When you're creating a VM, several options are available, such as operating system image, network configuration, and administrative credentials. You can use other cmdlets to configure the VM, such as Set-AzVMOperatingSystem, Set-AzVMSourceImage, Add-AzVMNetworkInterface, and Set-AzVMOSDisk. Additional reading: For more information about the parameters that you can use with the New-AzVM command, refer to New-AzVM . Before you run the New-AzVM command, you need to specify the credentials that you'll use to sign in to the newly created Azure VM. The credentials that you specify during this process will be assigned with local administrative privileges on the VM you're creating. It's easiest to store these credentials in a variable, before creating a new Azure VM. To do this, run this command: $cred = Get-Credential When you run this command, you'll be prompted to provide the username and password for the Azure VM. These credentials will be stored in the $cred variable. After you store administrative credentials, you need to define parameters for the new VM. You don't need to provide all the parameters that New-AzVM supports. Most of them are optional, and if you don't provide them, their default values will be selected. You can also change most of these parameters later. You can choose to provide VM parameters directly with the New-AzVM command, or you can define these parameters in a variable, and then use this variable with the New-AzVM command. The following code depicts an example of defining VM parameters: $vmParams = @{ ResourceGroupName = 'myResourceGroup' Name = 'TestVM' Location = 'westeurope' ImageName = 'Win2016Datacenter' PublicIpAddressName = 'TestPublicIp' Credential = $cred OpenPorts = 3389 } When you define VM parameters as the previous example depicts, you can then use the following command to create a new Azure VM, based on these parameters: New-AzVM @vmParams Alternatively, you can also choose to provide VM parameters directly with New-AzVM as in the following example: New-AzVm ` -ResourceGroupName \"myResourceGroup\" -Name \"myVM\" -Location \"EastUS\" -VirtualNetworkName \"myVnet\" -SubnetName \"mySubnet\" -SecurityGroupName \"myNetworkSecurityGroup\" -PublicIpAddressName \"myPublicIpAddress\" -Credential $cred","title":"Create an Azure VM"},{"location":"Net/az-res/#connect-to-the-azure-vm","text":"After a new Azure VM is created, you need to connect to it to verify the deployment. After the deployment has completed, create a remote desktop connection with the VM. Run the following commands to return the public IP address of the VM. Take note of this IP address so you can connect to it with your browser to test web connectivity in a future step. Get-AzPublicIpAddress -ResourceGroupName \"myResourceGroup\" | Select IpAddress To create a remote desktop session with the VM, use the following command on your local machine. Replace the IP address with the publicIPAddress of your VM. When prompted, enter the credentials you used when creating the VM. mstsc / v :< publicIpAddress > When you run this command, you'll be prompted for credentials to connect to the VM. In the Windows Security window, select More choices, and then select Use a different account. Enter the username and password you created for the VM, and then select OK. After you connect to your Azure VM through Remote Desktop Protocol (RDP), you'll be able to manage it the same way as any other computer.","title":"Connect to the Azure VM"},{"location":"Net/az-res/#modifying-vm-sizes","text":"The VM size determines the amount of compute resources such as CPU, GPU, and memory that are made available to the VM. You should create VMs using a VM size that's appropriate for the workload. If a workload increases, you can also resize existing VMs. To review a list of VM sizes available in a particular region, use the Get-AzVMSize command. For example: Get-AzVMSize -Location \"EastUS\" After a VM has been deployed, you can resize it to increase or decrease resource allocation. Before resizing a VM, check if the size you want is available on the current VM cluster. The Get-AzVMSize command returns a list of sizes: Get-AzVMSize -ResourceGroupName \"myResourceGroup\" -VMName \"myVM\" If your preferred size is available, you can resize the VM from a powered-on state; however, it's rebooted during the operation. The following example depicts how to change VM size to the Standard_DS3_v2 size profile: $vm = Get-AzVM -ResourceGroupName \"myResourceGroupVM\" -VMName \"myVM\" $vm . HardwareProfile . VmSize = \"Standard_DS3_v2\" Update-AzVM -VM $vm -ResourceGroupName \"myResourceGroup\"","title":"Modifying VM sizes"},{"location":"Net/az-res/#management-tasks","text":"During the lifecycle of a VM, you might want to run management tasks such as starting, stopping, or deleting a VM. Additionally, you might want to create scripts to automate repetitive or complex tasks. You can use Azure PowerShell to perform many common management tasks by using the command line or scripts. To stop and deallocate a VM with Stop-AzVM, you can run the following command: Stop-AzVM -ResourceGroupName \"myResourceGroup\" -Name \"myVM\" -Force To start a VM, you can run the following command: Start-AzVM -ResourceGroupName \"myResourceGroup\" -Name \"myVM\" If you want to delete everything inside of a resource group, including VMs, you can run the following command: Remove-AzResourceGroup -Name \"myResourceGroupVM\" -Force","title":"Management tasks"},{"location":"Net/az-res/#adding-disks-to-azure-vms","text":"When you create an Azure VM, two disks are automatically attached to the VM: Operating system disk. These disks can be sized up to 4 terabytes and host the VM's operating system. Temporary disk. These disks use a solid-state drive that's located on the same Azure host as the VM. Temporary disks are highly performant and might be used for operations such as temporary data processing. You can add additional data disks for installing applications and storing data. You should use data disks in any situation that requires durable and responsive data storage. The size of the VM determines how many data disks can be attached to it. To add a data disk to an Azure VM after you create it, you need to define disk configuration by using the New-AzDiskConfig command. You then need to use the New-AzDisk and Add-AzVMDataDisk commands to add a new disk to the VM, as the following example depicts: $diskConfig = New-AzDiskConfig -Location \"EastUS\" -CreateOption Empty -DiskSizeGB 128 $dataDisk = New-AzDisk -ResourceGroupName \"myResourceGroupDisk\" -DiskName \"myDataDisk\" -Disk $diskConfig $vm = Get-AzVM -ResourceGroupName \"myResourceGroupDisk\" -Name \"myVM\" $vm = Add-AzVMDataDisk -VM $vm -Name \"myDataDisk\" -CreateOption Attach -ManagedDiskId $dataDisk . Id -Lun 1 Update-AzVM -ResourceGroupName \"myResourceGroupDisk\" -VM $vm","title":"Adding disks to Azure VMs"},{"location":"Net/az-res/#storage","text":"You can use Azure PowerShell to manage Azure-related storage. Before you start managing your storage, you should first create a storage account, if you don't have one. Usually, storage accounts are created automatically when you create other Azure resources such as Azure virtual machines (VMs). You can create a standard, general-purpose storage account with locally redundant storage (LRS) replication by using New-AzStorageAccount. Next, get the storage account context that defines the storage account you want to use. When acting on a storage account, reference the context, instead of repeatedly passing in the credentials. Use the following example to create a storage account called mystorageaccount with LRS and blob encryption, which is enabled by default. $storageAccount = New-AzStorageAccount -ResourceGroupName $resourceGroup ` -Name \"mystorageaccount\" ` -SkuName Standard_LRS ` -Location $location ` $ctx = $storageAccount . Context Blobs are always uploaded into a container. You can organize groups of blobs the way you organize your files on your computer in folders. Set the container name, and then create the container by using New-AzStorageContainer. Set the blob permissions to allow public access of the files. The container name in the following example is quickstartblobs. $containerName = \"quickstartblobs\" New-AzStorageContainer -Name $containerName -Context $ctx -Permission blob You can use the Set-AzStorageAccount cmdlet to modify an Azure Storage account. You can use this cmdlet to modify the account type, update a customer domain, or set tags on a Storage account. For example, to set the storage account type you should use the following command: Set-AzStorageAccount -ResourceGroupName \"MyResourceGroup\" -AccountName \"mystorageaccount\" -Type \"Standard_RAGRS\" To set custom domain for existing storage account, you can use the following command: Set-AzStorageAccount -ResourceGroupName \"MyResourceGroup\" -AccountName \"mystorageaccount\" -CustomDomainName \"www.contoso.com\" -UseSubDomain $True Additional reading: To learn more about the available cmdlets for managing Azure storage, refer to Az.Storage .","title":"Storage"},{"location":"Net/az-res/#azure-subscriptions","text":"Most Azure users will only ever have a single subscription. However, if you're part of more than one organization or your organization has divided up access to certain resources across groupings, you might have multiple subscriptions within Azure. In Azure PowerShell, accessing the resources for a subscription requires changing the subscription associated with your current Azure session. You can do this by modifying the active session context, which is the information about which tenant, subscription, and user the cmdlets should be run against. To change subscriptions, you need to first retrieve an Azure PowerShell Context object with Get-AzSubscription, and then change the current context with Set-AzContext. The Get-AzSubscription cmdlet gets the subscription ID, subscription name, and home tenant for subscriptions that the current account can access. To get all Azure subscriptions active on all tenants, run the following command: Get-AzSubscription Name Id TenantId State ---- -- -------- ----- Subscription1 yyyy-yyyy-yyyy-yyyy aaaa-aaaa-aaaa-aaaa Enabled Subscription2 xxxx-xxxx-xxxx-xxxx aaaa-aaaa-aaaa-aaaa Enabled Subscription3 zzzz-zzzz-zzzz-zzzz bbbb-bbbb-bbbb-bbbb Enabled To focus on subscriptions assigned to a specific tenant, run the following command: Get-AzSubscription -TenantId \"aaaa-aaaa-aaaa-aaaa\" Name Id TenantId State ---- -- -------- ----- Subscription1 yyyy-yyyy-yyyy-yyyy aaaa-aaaa-aaaa-aaaa Enabled Subscription2 xxxx-xxxx-xxxx-xxxx aaaa-aaaa-aaaa-aaaa Enabled The Set-AzContext cmdlet sets authentication information for cmdlets that you run in the current session. The context includes tenant, subscription, and environment information. To set the subscription context, run the following command: Set-AzContext -Subscription \"xxxx-xxxx-xxxx-xxxx\" Name Account SubscriptionName Environment TenantId ---- ------- ---------------- ----------- -------- Work test @outlook . com Subscription1 AzureCloud xxxxxxxx-x ... The next example depicts how to get a subscription in the currently active tenant and set it as the active session: $context = Get-AzSubscription -SubscriptionId ... Set-AzContext $context","title":"Azure Subscriptions"},{"location":"Net/az-shell/","text":"Instead of using the locally installed PowerShell module for managing Azure resources, you could also use the Azure Cloud Shell environment. This option lets you use PowerShell or Bash environments and commands to manage Azure resources. Azure Cloud Shell is available in the Azure portal and also in the Microsoft 365 admin portal. Azure Cloud Shell is an interactive, browser-accessible shell for managing Azure resources. It provides the flexibility of choosing the shell experience that best suits the way you work. Linux users can opt for a Bash experience, while Windows users can opt for PowerShell. Cloud Shell enables access to a browser-based, command-line experience built with Azure management tasks in mind. You can use Cloud Shell to work untethered from a local machine in a way only the cloud can provide. The main characteristics of Azure Cloud Shell are that it: Is a temporary environment that requires a new or existing Azure file share to be mounted. Offers an integrated graphical text editor based on the open-source Monaco Editor. Authenticates automatically for instant access to your resources. Runs on a temporary host provided on a per-session, per-user basis. Times out after 20 minutes without interactive activity. Requires a resource group, storage account, and Azure file share. Uses the same Azure file share for both Bash and PowerShell. Is assigned to one machine per user account. Persists $HOME using a 5-GB image held in your file share. Has permissions that are set as a regular Linux user in Bash. You can access the Cloud Shell in three ways: Direct link. Open a browser and refer to https://shell.azure.com . Azure portal. Select the Cloud Shell icon on the Azure portal. Code snippets. On Microsoft Docs and Microsoft Learn , select the Try It option that displays with the Azure CLI and Azure PowerShell code snippets: az account show Get-AzSubscription The Try It option opens the Cloud Shell directly alongside the documentation using Bash (for Azure CLI snippets) or PowerShell (for Azure PowerShell snippets). To run the command: Use Copy in the code snippet. Use Ctrl+Shift+V (Windows/Linux) or Cmd+Shift+V (macOS) to paste the command. Select Enter. Cloud Shell provisions machines on a per-request basis, and as a result, machine state won't persist across sessions. Cloud Shell is built for interactive sessions, and therefore, shells automatically terminate after 20 minutes of shell inactivity. Secure automatic authentication Cloud Shell securely and automatically authenticates account access for the Azure CLI and Azure PowerShell. This helps you gain quick and more secure access to your resources. $HOME persistence across sessions To persist files across sessions, Cloud Shell moves through attaching an Azure file share on the first launch. When this completes, Cloud Shell will automatically attach your storage (mounted as $HOME\\clouddrive) for all future sessions. Additionally, your $HOME directory is persisted as an .img in your Azure file share. Files outside of $HOME and machine state aren't persisted across sessions. Depending on the scenario, you should use recommended best practices when storing secrets such as SSH keys. Services such as Azure Key Vault have tutorials for setup. Azure drive (Azure:) PowerShell in Cloud Shell provides the Azure drive (Azure:). You can switch to the Azure drive with cd Azure: and back to your home directory with cd ~. The Azure drive enables easier discovery and navigation of Azure resources such as compute, network, and storage, similar to file system navigation. You can continue to use familiar Azure PowerShell cmdlets to manage these resources, regardless of the drive you're in. Any changes to the Azure resources, whether they're made directly in the Azure portal or by using Azure PowerShell cmdlets, are reflected in the Azure drive. You can run dir -Force to refresh your resources. Manage Exchange Online PowerShell in Cloud Shell contains a private build of the Exchange Online module. Run Connect-EXOPSSession to get your Exchange cmdlets. By using these cmdlets, you can manage your Exchange Online instance running in the Microsoft 365 environment. Deep integration with open-source tooling Cloud Shell includes preconfigured authentication for various open-source tools. The following table lists the various tool categories and interfaces you can use. Category Names Linux tools bash, zsh, sh, tmux, and dig Azure tools Azure CLI and Azure classic CLI, AzCopy, Azure Functions CLI, Service Fabric CLI, Batch Shipyard, and blobxfer Text editors code (Cloud Shell editor), vim, nano, and emacs Source control git Build tools make, maven, npm, and pip Containers Docker Machine, Kubectl, Helm, and DC/OS CLI Databases MySQL client, PostgreSql client, sqlcmd Utility, and mssql-scripter Other iPython Client, Cloud Foundry CLI, Terraform, Ansible, Chef InSpec, Puppet Bolt, HashiCorp Packer, and Office 365 CLI Configure the Cloud Shell Access the Azure Portal. Select the Cloud Shell icon on the banner. On the Welcome to Azure Cloud Shell page, notice your selections for Bash or PowerShell. Select PowerShell. The Azure Cloud Shell requires an Azure file share to persist files. If you have time, select Learn more to obtain information about the Cloud Shell storage and the associated pricing. Select your Subscription, and then select Create Storage. Experiment with Azure PowerShell Wait for your storage to be created and your account to be initialized. At the PowerShell prompt, enter Get-AzSubscription to review your subscriptions. Enter Get-AzResourceGroup to review resource group information. Experiment with the Bash shell Use the drop-down list to switch to the Bash shell and confirm your choice. At the Bash shell prompt, enter az account list to review your subscriptions. Also, try tab completion. Enter az resource list to review resource information. Experiment with the Cloud Editor To use the Cloud Editor, enter code .. You can also select the curly braces icon. Select a file from the navigation pane; for example, .profile. On the editor banner, notice the selections for Settings, such as Text Size, Font, and Upload/Download files. Notice the ellipses (...) for Save, Close Editor, and Open File. After experimenting, you can close the Cloud Editor. Close Azure Cloud Shell.","title":"Azure Cloud Shell"},{"location":"Net/az-shell/#secure-automatic-authentication","text":"Cloud Shell securely and automatically authenticates account access for the Azure CLI and Azure PowerShell. This helps you gain quick and more secure access to your resources.","title":"Secure automatic authentication"},{"location":"Net/az-shell/#home-persistence-across-sessions","text":"To persist files across sessions, Cloud Shell moves through attaching an Azure file share on the first launch. When this completes, Cloud Shell will automatically attach your storage (mounted as $HOME\\clouddrive) for all future sessions. Additionally, your $HOME directory is persisted as an .img in your Azure file share. Files outside of $HOME and machine state aren't persisted across sessions. Depending on the scenario, you should use recommended best practices when storing secrets such as SSH keys. Services such as Azure Key Vault have tutorials for setup.","title":"$HOME persistence across sessions"},{"location":"Net/az-shell/#azure-drive-azure","text":"PowerShell in Cloud Shell provides the Azure drive (Azure:). You can switch to the Azure drive with cd Azure: and back to your home directory with cd ~. The Azure drive enables easier discovery and navigation of Azure resources such as compute, network, and storage, similar to file system navigation. You can continue to use familiar Azure PowerShell cmdlets to manage these resources, regardless of the drive you're in. Any changes to the Azure resources, whether they're made directly in the Azure portal or by using Azure PowerShell cmdlets, are reflected in the Azure drive. You can run dir -Force to refresh your resources.","title":"Azure drive (Azure:)"},{"location":"Net/az-shell/#manage-exchange-online","text":"PowerShell in Cloud Shell contains a private build of the Exchange Online module. Run Connect-EXOPSSession to get your Exchange cmdlets. By using these cmdlets, you can manage your Exchange Online instance running in the Microsoft 365 environment.","title":"Manage Exchange Online"},{"location":"Net/az-shell/#deep-integration-with-open-source-tooling","text":"Cloud Shell includes preconfigured authentication for various open-source tools. The following table lists the various tool categories and interfaces you can use. Category Names Linux tools bash, zsh, sh, tmux, and dig Azure tools Azure CLI and Azure classic CLI, AzCopy, Azure Functions CLI, Service Fabric CLI, Batch Shipyard, and blobxfer Text editors code (Cloud Shell editor), vim, nano, and emacs Source control git Build tools make, maven, npm, and pip Containers Docker Machine, Kubectl, Helm, and DC/OS CLI Databases MySQL client, PostgreSql client, sqlcmd Utility, and mssql-scripter Other iPython Client, Cloud Foundry CLI, Terraform, Ansible, Chef InSpec, Puppet Bolt, HashiCorp Packer, and Office 365 CLI","title":"Deep integration with open-source tooling"},{"location":"Net/az-shell/#configure-the-cloud-shell","text":"Access the Azure Portal. Select the Cloud Shell icon on the banner. On the Welcome to Azure Cloud Shell page, notice your selections for Bash or PowerShell. Select PowerShell. The Azure Cloud Shell requires an Azure file share to persist files. If you have time, select Learn more to obtain information about the Cloud Shell storage and the associated pricing. Select your Subscription, and then select Create Storage.","title":"Configure the Cloud Shell"},{"location":"Net/az-shell/#experiment-with-azure-powershell","text":"Wait for your storage to be created and your account to be initialized. At the PowerShell prompt, enter Get-AzSubscription to review your subscriptions. Enter Get-AzResourceGroup to review resource group information.","title":"Experiment with Azure PowerShell"},{"location":"Net/az-shell/#experiment-with-the-bash-shell","text":"Use the drop-down list to switch to the Bash shell and confirm your choice. At the Bash shell prompt, enter az account list to review your subscriptions. Also, try tab completion. Enter az resource list to review resource information.","title":"Experiment with the Bash shell"},{"location":"Net/az-shell/#experiment-with-the-cloud-editor","text":"To use the Cloud Editor, enter code .. You can also select the curly braces icon. Select a file from the navigation pane; for example, .profile. On the editor banner, notice the selections for Settings, such as Text Size, Font, and Upload/Download files. Notice the ellipses (...) for Save, Close Editor, and Open File. After experimenting, you can close the Cloud Editor. Close Azure Cloud Shell.","title":"Experiment with the Cloud Editor"},{"location":"Net/net-dns/","text":"PowerShell offers cmdlets for managing DNS client settings, DNS name query resolution, and for securing DNS clients. DNS client management cmdlets are part of the DNSClient PowerShell module and have the text \u201cDnsClient\u201d in the noun part of the name. Cmdlet Description Get-DnsClient Gets details about a network interface Set-DnsClient Sets DNS client configuration settings for a network interface Get-DnsClientServerAddress Gets the DNS server address settings for a network interface Set-DnsClientServerAddress Sets the DNS server address for a network interface Set-DnsClient requires an interface that an alias or index references. The following command sets the connection-specific suffix for an interface: Set-DnsClient -InterfaceAlias Ethernet -ConnectionSpecificSuffix \"adatum.com\" The DNSClient PowerShell module offers cmdlets for managing DNS client settings, DNS name query resolution, and for securing DNS clients. They have the text \u201cDnsClient\u201d in the noun part of the name.","title":"DNS"},{"location":"Net/net-fire/","text":"PowerShell supports the NetSecurity module that contains cmdlets to manage local Network Security configurations such as Windows firewall rules and IP security settings. To manage firewall settings, use cmdlets that have the text \u201cNetFirewall\u201d in their names. For firewall rule management, use cmdlets that contain the noun \u201cNetFirewallRule.\u201d Cmdlet Description New-NetFirewallRule Creates a new firewall rule Set-NetFirewallRule Sets properties for a firewall rule Get-NetFirewallRule Gets properties for a firewall rule Remove-NetFirewallRule Deletes a firewall rule Rename-NetFirewallRule Renames a firewall rule Copy-NetFirewallRule Makes a copy of a firewall rule Enable-NetFirewallRule Enables a firewall rule Disable-NetFirewallRule Disables a firewall rule Get-NetFirewallProfile Gets properties for a firewall profile Set-NetFirewallProfile Sets properties for a firewall profile You can use the Get-NetFirewallRule cmdlet to retrieve settings for firewall rules. You can enable and disable rules by using one of the following cmdlets: The Set-NetFirewallRule cmdlet with the -Enabled parameter The Enable-NetFirewallRule or Disable-NetFirewallRule cmdlets. The following commands both enable firewall rules in the group Remote Access: Enable-NetFirewallRule -DisplayGroup \"Remote Access\" ## and Set-NetFirewallRule -DisplayGroup \"Remote Access\" -Enabled True PowerShell supports the NetSecurity module that contains cmdlets to manage local Network Security configurations such as Windows firewall rules and IP security settings.","title":"Firewall"},{"location":"Net/net-ipadd/","text":"Both Windows PowerShell and PowerShell Core support cmdlets that you can use to manage all aspects related to network settings on Windows devices. Settings that you can configure with PowerShell include TCP/IP, Domain Name System (DNS), firewall, and routing table configurations. In addition to the cmdlets for managing network features and components, the Test-NetConnection cmdlet is also available. This cmdlet offers the same functionality as traditional command-line interface tools such as ping.exe and tracert.exe , which are used to identify and diagnose network connectivity and configuration settings. Manage IP Addresses PowerShell includes the NETTCPIP module, which consists of TCP/IP-specific cmdlets used to manage network settings for Windows servers and devices. You can use the NETTCPIP cmdlets to add, remove, change, and validate IP address settings. IP address management cmdlets use the noun \"NetIPAddress\" in their names. You can also find them by using the Get-Command command with the -Module NetTCPIP parameter. Cmdlet Description New-NetIPAddress Creates a new IP address Get-NetIPAddress Displays properties of an IP address Set-NetIPAddress Modifies properties of an IP address Remove-NetIPAddress Deletes an IP address Creating new IP address settings The New-NetIPAddress cmdlet requires an IPv4 or IPv6 address and either the alias or index of a network interface. As a best practice, you should also set the default gateway and subnet mask at the same time. Parameter Description -IPAddress Defines the IPv4 or IPv6 address to create -InterfaceIndex Defines the network interface, by index, for the IP address -InterfaceAlias Defines the network interface, by name, for the IP address -DefaultGateway Defines the IPv4 or IPv6 address of the default gateway host -PrefixLength Defines the subnet mask for the IP address The following command creates a new IP address on the Ethernet interface: New-NetIPAddress -IPAddress 192 . 168 . 1 . 10 -InterfaceAlias \"Ethernet\" -PrefixLength 24 -DefaultGateway 192 . 168 . 1 . 1 The New-NetIPAddress cmdlet also accepts the \u2013AddressFamily parameter, which defines either the IPv4 or IPv6 IP address family. If you don't use this parameter, the address family property is detected automatically. PowerShell includes the NetTCPIP module, which consists of TCP/IP-specific cmdlets used to manage network settings for Windows servers and devices. You can use these cmdlets to add, remove, change, and validate IP address settings.","title":"IP addresses"},{"location":"Net/net-ipadd/#manage-ip-addresses","text":"PowerShell includes the NETTCPIP module, which consists of TCP/IP-specific cmdlets used to manage network settings for Windows servers and devices. You can use the NETTCPIP cmdlets to add, remove, change, and validate IP address settings. IP address management cmdlets use the noun \"NetIPAddress\" in their names. You can also find them by using the Get-Command command with the -Module NetTCPIP parameter. Cmdlet Description New-NetIPAddress Creates a new IP address Get-NetIPAddress Displays properties of an IP address Set-NetIPAddress Modifies properties of an IP address Remove-NetIPAddress Deletes an IP address","title":"Manage IP Addresses"},{"location":"Net/net-ipadd/#creating-new-ip-address-settings","text":"The New-NetIPAddress cmdlet requires an IPv4 or IPv6 address and either the alias or index of a network interface. As a best practice, you should also set the default gateway and subnet mask at the same time. Parameter Description -IPAddress Defines the IPv4 or IPv6 address to create -InterfaceIndex Defines the network interface, by index, for the IP address -InterfaceAlias Defines the network interface, by name, for the IP address -DefaultGateway Defines the IPv4 or IPv6 address of the default gateway host -PrefixLength Defines the subnet mask for the IP address The following command creates a new IP address on the Ethernet interface: New-NetIPAddress -IPAddress 192 . 168 . 1 . 10 -InterfaceAlias \"Ethernet\" -PrefixLength 24 -DefaultGateway 192 . 168 . 1 . 1 The New-NetIPAddress cmdlet also accepts the \u2013AddressFamily parameter, which defines either the IPv4 or IPv6 IP address family. If you don't use this parameter, the address family property is detected automatically. PowerShell includes the NetTCPIP module, which consists of TCP/IP-specific cmdlets used to manage network settings for Windows servers and devices. You can use these cmdlets to add, remove, change, and validate IP address settings.","title":"Creating new IP address settings"},{"location":"Net/net-iproute/","text":"IP routing forwards data packets based on the destination IP address. This routing is based on routing tables, and while entries are made automatically, you might need to add, remove, or modify routing table entries manually. The NETTCPIP PowerShell module also includes cmdlets used to manage the routing table for Windows servers and devices. The cmdlets for managing routing table entries have the noun \u201cNetRoute\u201d in the names. Cmdlet Description New-NetRoute Creates an entry in the IP routing table Get-NetRoute Retrieves an entry from the IP routing table Set-NetRoute Modifies properties of an entry in the IP routing table Remove-NetRoute Deletes an entry from the IP routing table Find-NetRoute Identifies the best local IP address and route to reach a remote address Creating an IP routing table entry You can use the New-NetRoute cmdlet to create routing table entries on a Windows computer. The New-NetRoute cmdlet requires you to identify the network interface and destination prefix. Parameter Description \u2011DestinationPrefix Defines the destination prefix of an IP route \u2011InterfaceAlias Defines the network interface, by alias, for an IP route \u2011InterfaceIndex Defines the network interface, by index, for an IP route \u2011NextHop Defines the next hop for an IP route \u2011RouteMetric Defines the route metric for an IP route The following command creates an IP routing table entry: New-NetRoute -DestinationPrefix 0 . 0 . 0 . 0 / 24 -InterfaceAlias \"Ethernet\" -DefaultGateway 192 . 168 . 1 . 1 The NetTCPIP PowerShell module also includes cmdlets used to manage the routing table for Windows servers and devices. They have the noun \u201cNetRoute\u201d in their names.","title":"IP Routing"},{"location":"Net/net-iproute/#creating-an-ip-routing-table-entry","text":"You can use the New-NetRoute cmdlet to create routing table entries on a Windows computer. The New-NetRoute cmdlet requires you to identify the network interface and destination prefix. Parameter Description \u2011DestinationPrefix Defines the destination prefix of an IP route \u2011InterfaceAlias Defines the network interface, by alias, for an IP route \u2011InterfaceIndex Defines the network interface, by index, for an IP route \u2011NextHop Defines the next hop for an IP route \u2011RouteMetric Defines the route metric for an IP route The following command creates an IP routing table entry: New-NetRoute -DestinationPrefix 0 . 0 . 0 . 0 / 24 -InterfaceAlias \"Ethernet\" -DefaultGateway 192 . 168 . 1 . 1 The NetTCPIP PowerShell module also includes cmdlets used to manage the routing table for Windows servers and devices. They have the noun \u201cNetRoute\u201d in their names.","title":"Creating an IP routing table entry"},{"location":"Net/ws-gp/","text":"You can use Windows PowerShell to automate the management of most tasks involving Group Policy Objects (GPOs), including creating, deleting, backing up, reporting, and importing GPOs. You can also associate GPOs with Active Directory Domain Services (AD DS) OUs, including setting GPO inheritance and permissions. Group Policy management cmdlets require Remote Server Administration Tools (RSAT) installed. Group Policy management cmdlets are part of the GroupPolicy module for Windows PowerShell. Cmdlet names include the prefix \u201cGP\u201d in the names, and most have \u201cGPO\u201d as the noun. Cmdlet Description New-GPO Creates a new GPO Get-GPO Retrieves a GPO Set-GPO Modifies properties of a GPO Remove-GPO Deletes a GPO Rename-GPO Renames a GPO Backup-GPO Backs up one or more GPOs in a domain Copy-GPO Copies a GPO from one domain to another domain Restore-GPO Restores a GPO from backup files New-GPLink Links a GPO to an AD DS container Import-GPO Imports GPO settings from a backed-up GPO Set-GPRegistryValue Configures one or more registry-based policy settings in a GPO Creating a new GPO New-GPO requires only the -Name parameter, which must be unique in the domain in which you create the GPO. By default, the GPO is created in the domain of the user who is running the command. New-GPO also doesn't link the created GPO to an AD DS container. To link a GPO to a container, use the New-GPLink cmdlet. The following command creates a new GPO from a starter GPO: New-GPO -Name \"IT Team GPO\" -StarterGPOName \"IT Starter GPO\" # links the new GPO to an AD DS organizational unit New-GPLink -Name \"IT Team GPO\" -Target \"OU=IT,DC=adatum,DC=com\" The Group Policy management cmdlets that are part of the GroupPolicy module can automate the management of most tasks involving Group Policy Objects (GPOs), including creating, deleting, backing up, reporting, and importing GPOs. Their names include the prefix \u201cGP\u201d while most have \u201cGPO\u201d as the noun.","title":"Group Policy"},{"location":"Net/ws-gp/#creating-a-new-gpo","text":"New-GPO requires only the -Name parameter, which must be unique in the domain in which you create the GPO. By default, the GPO is created in the domain of the user who is running the command. New-GPO also doesn't link the created GPO to an AD DS container. To link a GPO to a container, use the New-GPLink cmdlet. The following command creates a new GPO from a starter GPO: New-GPO -Name \"IT Team GPO\" -StarterGPOName \"IT Starter GPO\" # links the new GPO to an AD DS organizational unit New-GPLink -Name \"IT Team GPO\" -Target \"OU=IT,DC=adatum,DC=com\" The Group Policy management cmdlets that are part of the GroupPolicy module can automate the management of most tasks involving Group Policy Objects (GPOs), including creating, deleting, backing up, reporting, and importing GPOs. Their names include the prefix \u201cGP\u201d while most have \u201cGPO\u201d as the noun.","title":"Creating a new GPO"},{"location":"Net/ws-hv/","text":"PowerShell offers more than 200 cmdlets for managing Hyper-V Virtual machines (VMs), virtual hard disks, and other components of a Hyper-V environment. Hyper-V cmdlets are available in the Hyper-V module for PowerShell. The Hyper-V cmdlets are available when you install the Hyper-V Management tools feature on a Windows client operating system, or the Hyper-V Module for Windows PowerShell feature on Windows Server. Hyper-V cmdlets use one of three prefixes: \u201cVM\u201d for virtual machine cmdlets \u201cVHD\u201d for virtual hard disk cmdlets \u201cVFD\u201d for virtual floppy disk cmdlets Cmdlet Description Get-VM Gets properties of a VM Set-VM Sets properties of a VM New-VM Creates a new VM Start-VM Starts a VM Stop-VM Stops a VM Restart-VM Restarts a VM Suspend-VM Pauses a VM Resume-VM Resumes a paused VM Import-VM Imports a VM from a file Export-VM Exports a VM to a file Checkpoint-VM Creates a checkpoint of a VM The Hyper-V module for PowerShell offers more than 200 cmdlets for managing Hyper-V Virtual machines (VMs), virtual hard disks, and other components of a Hyper-V environment.","title":"Hyper-V"},{"location":"Net/ws-iis/","text":"The Web server role includes Internet Information Services (IIS), which is commonly used to manage websites and web-based applications. IIS supports PowerShell cmdlets to allow you to configure and manage application pools, websites, web applications, and virtual directories. IIS management cmdlets are available in the IISAdministration module for PowerShell and have the prefix \u201cIIS\u201d in the noun part of their names. Sites use the noun \u201cIISSite\u201d. To manage web-based applications, you can use the WebAdministration module for PowerShell, which includes cmdlets for managing web applications. These cmdlets use the noun \"WebApplication\". Cmdlets for managing application pools use the noun \u201cWebAppPool\u201d. The WebAdministration module has mostly been replaced by updated features included in the IISAdministration module. For any IIS-related management tasks, it's recommended to use the IISAdministration module. Cmdlet Description New-IISSite Creates a new IIS website Get-IISSite Gets properties and configuration information about an IIS website Start-IISSite Starts an existing IIS website on the IIS server Stop-IISSite Stops an IIS website New-WebApplication Creates a new web application Remove-WebApplication Deletes a web application New-WebAppPool Creates a new web application pool Restart-WebAppPool Restarts a web application pool The IISAdministration module for PowerShell includes IIS management cmdlets, while the WebAdministration module for PowerShell includes cmdlets for managing web applications.","title":"Internet Information Services"},{"location":"Net/ws-wf/","text":"The ServerManager module for PowerShell contains cmdlets for managing server features, roles, and services. These cmdlets are the equivalent of the Server Manager user interface. The Server Manager cmdlet names include the noun \u201cWindowsFeature.\u201d The ServerManager module cmdlets can only be targeted against and run on Windows Server operating systems. If you try to use these cmdlets on a Windows client-based operating system, you'll receive an error message. Cmdlet Description Get-WindowsFeature Obtains and displays information about Windows Server roles, services, and features that are installed or are available for installation Install-WindowsFeature Installs one or more roles, services, or features Uninstall-WindowsFeature Uninstalls one or more roles, services, or features The following command installs network load balancing on the local server: Install-WindowsFeature \"nlb\" The ServerManager module for PowerShell contains cmdlets for managing server features, roles, and services. These cmdlet names include the noun \u201cWindowsFeature\u201d. These cmdlets can only be targeted against and run on Windows Server operating systems and not on a Windows client-based operating system.","title":"Windows Feature"},{"location":"Scripting/ConsoleIO/","text":"To enhance the usability of your scripts, you must learn how to accept user input. This skill allows you to create scripts that can be used for multiple purposes. In addition, accepting user input allows you to create scripts that are easier for others to use. Requesting Info The Read-Host cmdlet displays a request message, and then reads a response from the user. For example: Read-Host \"Enter a computer name\" Enter a computer name: SERVER SERVER The cmdlet adds a colon (:) after the request message, and places the user's response in the pipeline. In most cases, the user's response is captured in a variable, as in the following example: $computer = Read-Host \"Enter a computer name\" Enter a computer name : SERVER You can combine a Write-Host command with Read-Host to display text and avoid a colon being appended, as the following example depicts: Write-Host \"How many days? \" -NoNewline $answer = Read-Host Input from Read-Host is limited to 1022 characters. You can mask the input users enter at the prompt by using the -MaskInput or -AsSecureString parameters. Both parameters cause the characters entered by the user to display as asterisks (*). When -MaskInput is used, the response is collected as a String object. When -AsSecureString is used, the response is collected as a SecureString object. A SecureString object is required for scenarios such as setting passwords, where data shouldn't be stored as clear text in memory. Writing Info To write data to the console: Write-Host: Allows you to write data directly to the console, skipping the pipeline. For this reason, its output cannot be captured or redirected to logs. It is recommended not to use it. Write-Output: Allows data to be written to the pipeline. If there is no redirection to another command, the data will be output to the screen. This is the recommended way to print data to the console. Other ways: Powershell has other cmdlets to produce console output. None of them use the pipeline (they function as Write-Host), but their output can be suppressed at will, through the use of environment variables. The commands are the following: Command Description Write-Warning Prints the message in orange, preceded by the word WARNING. Its printing depends on the value of the $WarningPerference variable, which defaults to Continue. Write-Verbose Prints the message in blue, preceded by the word VERBOSE. Its printing depends on the value of the $VerbosePreference variable, which is set to SilentlyContinue by default. Write-Debug Prints the message in blue, preceded by the word DEBUG. Its printing depends on the value of the $DebugPreference variable, which defaults to SilentlyContinue. Write-error Generates an error message. Its printing depends on the value of the $ErrorActionPreference variable, which defaults to Continue. If the variable corresponding to the command has the value Continue, the message is printed. If the value is SilentlyContinue, the printing of the message is suppressed. Out-GridView Out-GridView is primarily used to review data. However, you can also use Out-GridView to create a simple menu selection interface. When the user makes one or more selections in the window presented by Out-GridView, the data for those objects is either passed further through the pipeline or placed into a variable. $selection = $users | Out-GridView -PassThru In the previous example, an array of user accounts is piped to Out-GridView. Out-GridView displays the user accounts on screen, and the user can select one or more rows in the Out-GridView window. When the user selects OK, the selected rows are stored in the $selection variable. You can then perform further processing on the users\u2019 accounts. To retain more control over the amount of data that users can select, you can use the -OutputMode parameter instead of the -PassThru parameter. The following table depicts the values that can be defined for the -OutputMode parameter. -OutputMode parameter Value Description None This is the default value that doesn't pass any objects further down the pipeline. Single This value allows users to select zero rows or one row in the Out-GridView window. Multiple This value allows users to select zero rows, one row, or multiple rows in the Out-GridView window. This value is equivalent to using the -PassThru parameter. Because users aren't forced to select a row in the Out-GridView window, you must ensure that your script properly handles the scenario where a row isn't selected.","title":"Console IO"},{"location":"Scripting/ConsoleIO/#requesting-info","text":"The Read-Host cmdlet displays a request message, and then reads a response from the user. For example: Read-Host \"Enter a computer name\" Enter a computer name: SERVER SERVER The cmdlet adds a colon (:) after the request message, and places the user's response in the pipeline. In most cases, the user's response is captured in a variable, as in the following example: $computer = Read-Host \"Enter a computer name\" Enter a computer name : SERVER You can combine a Write-Host command with Read-Host to display text and avoid a colon being appended, as the following example depicts: Write-Host \"How many days? \" -NoNewline $answer = Read-Host Input from Read-Host is limited to 1022 characters. You can mask the input users enter at the prompt by using the -MaskInput or -AsSecureString parameters. Both parameters cause the characters entered by the user to display as asterisks (*). When -MaskInput is used, the response is collected as a String object. When -AsSecureString is used, the response is collected as a SecureString object. A SecureString object is required for scenarios such as setting passwords, where data shouldn't be stored as clear text in memory.","title":"Requesting Info"},{"location":"Scripting/ConsoleIO/#writing-info","text":"To write data to the console: Write-Host: Allows you to write data directly to the console, skipping the pipeline. For this reason, its output cannot be captured or redirected to logs. It is recommended not to use it. Write-Output: Allows data to be written to the pipeline. If there is no redirection to another command, the data will be output to the screen. This is the recommended way to print data to the console. Other ways: Powershell has other cmdlets to produce console output. None of them use the pipeline (they function as Write-Host), but their output can be suppressed at will, through the use of environment variables. The commands are the following: Command Description Write-Warning Prints the message in orange, preceded by the word WARNING. Its printing depends on the value of the $WarningPerference variable, which defaults to Continue. Write-Verbose Prints the message in blue, preceded by the word VERBOSE. Its printing depends on the value of the $VerbosePreference variable, which is set to SilentlyContinue by default. Write-Debug Prints the message in blue, preceded by the word DEBUG. Its printing depends on the value of the $DebugPreference variable, which defaults to SilentlyContinue. Write-error Generates an error message. Its printing depends on the value of the $ErrorActionPreference variable, which defaults to Continue. If the variable corresponding to the command has the value Continue, the message is printed. If the value is SilentlyContinue, the printing of the message is suppressed.","title":"Writing Info"},{"location":"Scripting/ConsoleIO/#out-gridview","text":"Out-GridView is primarily used to review data. However, you can also use Out-GridView to create a simple menu selection interface. When the user makes one or more selections in the window presented by Out-GridView, the data for those objects is either passed further through the pipeline or placed into a variable. $selection = $users | Out-GridView -PassThru In the previous example, an array of user accounts is piped to Out-GridView. Out-GridView displays the user accounts on screen, and the user can select one or more rows in the Out-GridView window. When the user selects OK, the selected rows are stored in the $selection variable. You can then perform further processing on the users\u2019 accounts. To retain more control over the amount of data that users can select, you can use the -OutputMode parameter instead of the -PassThru parameter. The following table depicts the values that can be defined for the -OutputMode parameter.","title":"Out-GridView"},{"location":"Scripting/ConsoleIO/#-outputmode-parameter","text":"Value Description None This is the default value that doesn't pass any objects further down the pipeline. Single This value allows users to select zero rows or one row in the Out-GridView window. Multiple This value allows users to select zero rows, one row, or multiple rows in the Out-GridView window. This value is equivalent to using the -PassThru parameter. Because users aren't forced to select a row in the Out-GridView window, you must ensure that your script properly handles the scenario where a row isn't selected.","title":"-OutputMode parameter"},{"location":"Scripting/advanced/","text":"Adding the line [CmdletBinding()] after the help comments makes the script advanced, which allows you to return required parameters, set their data type, add aliases for parameters, etc. The final version of the example script is as follows: <# .SYNOPSIS Get-DiskInventory gets logical disk information for one or more computers. .DESCRIPTION Get-DiskInventory uses CIM to query the instances Win32_LogicalDisk from one or more computers. Display for each disk the drive letter, free space, total space, and percentage of free space. .PARAMETER DriveType The type of unit to query. View the Win32_LogicalDisk documentation for more information. 3 indicates a fixed disk, and is the default. .EXAMPLE Get-DiskInventory -DriveType 3 #> [ CmdletBinding ()] param ( [ Parameter ( Mandatory = $True )] [ Alias ( 'Type' )] [ ValidateSet ( 2 , 3 )] [int] $DriveType = 3 ) Get-CimInstance Win32_logicaldisk ` -filter \"drivetype=$DriveType\" | Sort-Object -Property DeviceID | Select-Object -Property DeviceID , @{ n = 'FreeSpace(MB)' ; e ={ $_ . FreeSpace / 1MB -as [int] }}, @{ n = 'Size(GB)' ; e ={ $_ . Size / 1GB -as [int] }}, @{ n = '%Free' ; e ={ $_ . FreeSpace / $_ . Size * 100 -as [int] }} The changes from the previous example are as follows: The directive to return the script advanced is included The parameter is now required, and the alias Type is created for it. The parameter is declared as an integer, and the only valid values \u200b\u200bit receives are 2 and 3. If you've configured your script as an advanced script by using CmdletBinding() in the Param() block, you can also use the cmdlets in the following table as part of your script for troubleshooting. Cmdlets for troubleshooting Cmdlet Description Write-Verbose Text specified by Write-Verbose is displayed only when you use the -Verbose parameter when running the script. The value of $VerbosePreference specifies the action to take after the Write-Verbose command. The default action is SilentlyContinue. Write-Debug Text specified by Write-Debug is displayed only when you use the -Debug parameter when running the script. The value of $DebugPreference specifies the action to take after the Write-Debug command. The default action is SilentlyContinue, which displays no information to screen. You need to change this action to Continue so that debug messages are displayed.","title":"Advanced Script"},{"location":"Scripting/advanced/#cmdlets-for-troubleshooting","text":"Cmdlet Description Write-Verbose Text specified by Write-Verbose is displayed only when you use the -Verbose parameter when running the script. The value of $VerbosePreference specifies the action to take after the Write-Verbose command. The default action is SilentlyContinue. Write-Debug Text specified by Write-Debug is displayed only when you use the -Debug parameter when running the script. The value of $DebugPreference specifies the action to take after the Write-Debug command. The default action is SilentlyContinue, which displays no information to screen. You need to change this action to Continue so that debug messages are displayed.","title":"Cmdlets for troubleshooting"},{"location":"Scripting/basic/","text":"Powershell scripts allow you to store a command or series of commands, for easier execution later. To produce a script, it is enough to record the required commands in a text file with the extension .ps1 . You can also use scripts to accomplish more complex tasks than are practical by using a single command. While it's technically possible to make a single Windows PowerShell command that's long and complex, it's impractical to manage. Placing complex tasks in a script makes editing simpler and easier to understand. Reporting is one complex and repetitive task that you can do with Windows PowerShell. You can use Windows PowerShell to create text or HTML-based reports. For example, you can create a script that reports available disk space on your servers, or you can create a script for Exchange that scans the message tracking logs to report on mail flow statistics. Scripts can also use constructs such as ForEach, If, and Switch, which are seldom used in a single command. You can use these constructs to process objects and make decisions in your scripts. For example, consider the following command, which prints a list of fixed disks attached to the system, along with their free space, total size, and free space percentage: Get-CimInstance Win32_logicaldisk ` -filter \"drivetype=3\" | Sort-Object -Property DeviceID | format-table -Property DeviceID , @{ n = 'FreeSpace(MB)' ; e ={ $_ . FreeSpace / 1MB -as [int] }}, @{ n = 'Size(GB)' ; e ={ $_ . Size / 1GB -as [int] }}, @{ n = '%Free' ; e ={ $_ . FreeSpace / $_ . Size * 100 -as [int] }} At the end of the first line the backtick ` is used to indicate that the command has not finished yet. In the rest of the lines, this job is done by vertical bars and commas. This way it is easier to read. By copying these lines of code and saving them to a text file called Get-DiskInventory.ps1, a script will be created. Parameterization Scripts can be parameterized, that is, parameters can be created that can be specified at the time the script is executed. For example, in the script of the previous example it is possible to return parameters the name of the computer and the type of unit. The parameterized script would look like this: param ( $DriveType = 3 ) Get-CimInstance Win32_logicaldisk ` -filter \"drivetype=$DriveType\" | Sort-Object -Property DeviceID | format-table -Property DeviceID , @{ n = 'FreeSpace(MB)' ; e ={ $_ . FreeSpace / 1MB -as [int] }}, @{ n = 'Size(GB)' ; e ={ $_ . Size / 1GB -as [int] }}, @{ n = '%Free' ; e ={ $_ . FreeSpace / $_ . Size * 100 -as [int] }} Optionally, each parameter can be specified with a default value, as seen in the example above. Parameters are positional by default. If the parameter names aren't specified, then the parameter values are passed to the parameters in order. If you don't put a Param() block in your script, you can still pass data into the script by using unnamed parameters. The values that are provided after the script name are available inside the script in the $args array. Run the script The script can be executed by typing its name in the console. If the script is saved in a different directory than the current one, the full path to the file must be written to execute it. In case the script does not execute, it is necessary to change the script execution policy to a more permissive value, using the Set-ExecutionPolicy cmdlet as administrator. See the cmdlet help for more details. An execution policy is a safety feature. Like requiring the path of a script, a policy can stop you from doing unintentional things. You can set the policy on various levels, like the local computer, current user, or particular session. You can also use a Group Policy setting to set execution policies for computers and users. . ./ Get-DiskInventory . ps1 To run a Windows PowerShell script at the Windows PowerShell prompt, you can use the following methods: Enter the full path to the script; for example, C:\\Scripts\\MyScript.ps1. Enter a relative path to the script; for example, \\Scripts\\MyScript.ps1. Reference the current directory; for example, .\\MyScript.ps1. Execution Policy You can control whether Windows PowerShell scripts can be run on Windows computers. You do this task by setting the execution policy on the computer. The default execution policy on a computer varies depending on the operating system version. To be sure of the current configuration, you can use the Get-ExecutionPolicy cmdlet. The options for the execution policy are: Restricted. No scripts are allowed to be run. AllSigned. Scripts can be run only if they're digitally signed. RemoteSigned. Scripts that are downloaded can only be run if they're digitally signed. Unrestricted. All scripts can be run, but a confirmation prompt displays when running unsigned scripts that are downloaded. Bypass. All scripts are run without prompts. Setting the script execution policy provides a safety net that can prevent untrusted scripts from being run accidentally. However, the execution policy can always be overridden. You can set the execution policy on a computer by using the Set-ExecutionPolicy cmdlet. However, this setting is difficult to manage across many computers. When you configure the execution policy for many computers, you can use the Computer Configuration\\Policies\\Administrative Templates\\Windows Components\\Windows PowerShell\\Turn on Script Execution Group Policy setting to override the local setting. You can override the execution policy for an individual Windows PowerShell instance. This setting is useful if company policy requires the execution policy to be set as Restricted, but you still must run scripts occasionally. To override the execution policy, run PowerShell.exe with the -ExecutionPolicy parameter. Powershell . exe -ExecutionPolicy ByPass If you've modified a script downloaded from the internet, the script still has the attributes that identify it as a downloaded file. To remove that status from a script, use the Unblock-File cmdlet. AppLocker While the Windows PowerShell script execution policy provides a safety net for inexperienced users, it's not very flexible. When you set an execution policy, you can only check that the script was downloaded and that it's signed. Another alternative for controlling the use of Windows PowerShell scripts is AppLocker. With AppLocker, you can set various restrictions that limit the running of specific scripts or scripts in specific locations. Also, unlike the AllSigned execution policy, AppLocker can allow scripts that are signed only by specific publishers.","title":"Basic Scripting"},{"location":"Scripting/basic/#parameterization","text":"Scripts can be parameterized, that is, parameters can be created that can be specified at the time the script is executed. For example, in the script of the previous example it is possible to return parameters the name of the computer and the type of unit. The parameterized script would look like this: param ( $DriveType = 3 ) Get-CimInstance Win32_logicaldisk ` -filter \"drivetype=$DriveType\" | Sort-Object -Property DeviceID | format-table -Property DeviceID , @{ n = 'FreeSpace(MB)' ; e ={ $_ . FreeSpace / 1MB -as [int] }}, @{ n = 'Size(GB)' ; e ={ $_ . Size / 1GB -as [int] }}, @{ n = '%Free' ; e ={ $_ . FreeSpace / $_ . Size * 100 -as [int] }} Optionally, each parameter can be specified with a default value, as seen in the example above. Parameters are positional by default. If the parameter names aren't specified, then the parameter values are passed to the parameters in order. If you don't put a Param() block in your script, you can still pass data into the script by using unnamed parameters. The values that are provided after the script name are available inside the script in the $args array.","title":"Parameterization"},{"location":"Scripting/basic/#run-the-script","text":"The script can be executed by typing its name in the console. If the script is saved in a different directory than the current one, the full path to the file must be written to execute it. In case the script does not execute, it is necessary to change the script execution policy to a more permissive value, using the Set-ExecutionPolicy cmdlet as administrator. See the cmdlet help for more details. An execution policy is a safety feature. Like requiring the path of a script, a policy can stop you from doing unintentional things. You can set the policy on various levels, like the local computer, current user, or particular session. You can also use a Group Policy setting to set execution policies for computers and users. . ./ Get-DiskInventory . ps1 To run a Windows PowerShell script at the Windows PowerShell prompt, you can use the following methods: Enter the full path to the script; for example, C:\\Scripts\\MyScript.ps1. Enter a relative path to the script; for example, \\Scripts\\MyScript.ps1. Reference the current directory; for example, .\\MyScript.ps1.","title":"Run the script"},{"location":"Scripting/basic/#execution-policy","text":"You can control whether Windows PowerShell scripts can be run on Windows computers. You do this task by setting the execution policy on the computer. The default execution policy on a computer varies depending on the operating system version. To be sure of the current configuration, you can use the Get-ExecutionPolicy cmdlet. The options for the execution policy are: Restricted. No scripts are allowed to be run. AllSigned. Scripts can be run only if they're digitally signed. RemoteSigned. Scripts that are downloaded can only be run if they're digitally signed. Unrestricted. All scripts can be run, but a confirmation prompt displays when running unsigned scripts that are downloaded. Bypass. All scripts are run without prompts. Setting the script execution policy provides a safety net that can prevent untrusted scripts from being run accidentally. However, the execution policy can always be overridden. You can set the execution policy on a computer by using the Set-ExecutionPolicy cmdlet. However, this setting is difficult to manage across many computers. When you configure the execution policy for many computers, you can use the Computer Configuration\\Policies\\Administrative Templates\\Windows Components\\Windows PowerShell\\Turn on Script Execution Group Policy setting to override the local setting. You can override the execution policy for an individual Windows PowerShell instance. This setting is useful if company policy requires the execution policy to be set as Restricted, but you still must run scripts occasionally. To override the execution policy, run PowerShell.exe with the -ExecutionPolicy parameter. Powershell . exe -ExecutionPolicy ByPass If you've modified a script downloaded from the internet, the script still has the attributes that identify it as a downloaded file. To remove that status from a script, use the Unblock-File cmdlet.","title":"Execution Policy"},{"location":"Scripting/basic/#applocker","text":"While the Windows PowerShell script execution policy provides a safety net for inexperienced users, it's not very flexible. When you set an execution policy, you can only check that the script was downloaded and that it's signed. Another alternative for controlling the use of Windows PowerShell scripts is AppLocker. With AppLocker, you can set various restrictions that limit the running of specific scripts or scripts in specific locations. Also, unlike the AllSigned execution policy, AppLocker can allow scripts that are signed only by specific publishers.","title":"AppLocker"},{"location":"Scripting/break_cont/","text":"Break and Continue are two commands that you can use to modify the default behavior of a loop. Continue ends the processing for the current iteration of the loop. Break completely stops the loop processing. You typically use these commands when the data you're processing has an invalid value. In this example, the use of Continue prevents modification of the Administrator user account in the list of users to be modified: ForEach ( $user in $users ) { If ( $user . Name -eq \"Administrator\" ) { Continue } Write-Host \"Modify user object\" } In this example, Break is used to end the loop when a maximum number of accounts has been modified: ForEach ( $user in $users ) { $number ++ Write-Host \"Modify User object $number\" If ( $number -ge $max ) { Break } }","title":"Break & Continue"},{"location":"Scripting/comments/","text":"Scripts can be documented in such a way that they provide help similar to that provided by Powershell. The documented script would look like this: <# .SYNOPSIS Get-DiskInventory gets logical disk information for one or more computers. .DESCRIPTION Get-DiskInventory uses CIM to query the instances Win32_LogicalDisk from one or more computers. Display for each disk the drive letter, free space, total space, and percentage of free space. .PARAMETER DriveType The type of unit to query. View the Win32_LogicalDisk documentation for more information. 3 indicates a fixed disk, and is the default. .EXAMPLE Get-DiskInventory -DriveType 3 #> param ( $DriveType = 3 ) Get-CimInstance -Class Win32_logicaldisk ` -filter \"drivetype=$DriveType\" | Sort-Object -Property DeviceID | Select-Object -Property DeviceID , @{ n = 'FreeSpace(MB)' ; e ={ $_ . FreeSpace / 1MB -as [int] }}, @{ n = 'Size(GB)' ; e ={ $_ . Size / 1GB -as [int] }}, @{ n = '%Free' ; e ={ $_ . FreeSpace / $_ . Size * 100 -as [int] }} Comments can be specified with a # symbol before each comment line, or with the notation <# #> if there are several consecutive lines of comments. A slight change was also made to the script: instead of using the Format-Table cmdlet, Select-Object is used, so as not to produce a formatted table as output. Using Select-Object the final output of the script is an object, so the end user can chain the script with other commands using the pipeline.","title":"Script Documentation"},{"location":"Scripting/cond/","text":"Flow control refers to how your code runs in your console or script. If, ElseIf, and Else You can use an If construct to determine if an expression is True or False. $True indicates that an expression is True. $False indicates that an expression is False. # _FullyTax.ps1_ # Possible values: 'Minor', 'Adult', 'Senior Citizen' $Status = 'Minor' If ( $Status -eq 'Minor' ) { Write-Host $False } ElseIf ( $Status -eq 'Adult' ) { Write-Host $True } Else { Write-Host $False } You can use the If construct in Windows PowerShell to make decisions. You also can use it to evaluate data you've queried or user input. For example, you could have an If statement that displays a warning if available disk space is low. The If construct uses the following syntax: If ( $freeSpace -le 5GB ) { Write-Host \"Free disk space is less than 5 GB\" } ElseIf ( $freeSpace -le 10GB ) { Write-Host \"Free disk space is less than 10 GB\" } Else { Write-Host \"Free disk space is more than 10 GB\" } Switch The Switch construct is similar to an If construct that has multiple ElseIf sections. The Switch construct evaluates a single variable or item against multiple values and has a script block for each value. The script block for each value is run if that value matches the variable. There's also a Default section that runs only if there are no matches. The Switch construct uses the following syntax: Switch ( $choice ) { 1 { Write-Host \"You selected menu item 1\" } 2 { Write-Host \"You selected menu item 2\" } 3 { Write-Host \"You selected menu item 3\" } Default { Write-Host \"You did not select a valid option\" } } In addition to matching values, the Switch construct can also be used to match patterns. You can use the -wildcard parameter to perform pattern matching by using the same syntax as the -like operator. Alternatively, you can use the -regex parameter to perform matching by using regular expressions. It's important to be aware that when you use pattern matching, multiple matches are possible. When there are multiple matches, the script blocks for all matching patterns are run. This is different from an If construct in which only one script block is run. The following example uses pattern matching: Switch -WildCard ( $ip ) { \"10.*\" { Write-Host \"This computer is on the internal network\" } \"10.1.*\" { Write-Host \"This computer is in London\" } \"10.2.*\" { Write-Host \"This computer is in Vancouver\" } Default { Write-Host \"This computer is not on the internal network\" } } For values of $ip on the London or Vancouver networks, two messages will be displayed. If $ip includes an IP address on the 10.x.x.x network, the messages will indicate that the computer is on the internal network and that the computer is in either London or Vancouver. If $ip is not an IP address on the 10.x.x.x network, the message indicates that it's not on the internal network. If you provide multiple values in an array to a Switch construct, each item in the array is evaluated. In the previous example, if the variable $ip was an array with two IP addresses, then both IP addresses would be processed. The actions appropriate for each item in the array would be performed.","title":"Conditionals"},{"location":"Scripting/cond/#if-elseif-and-else","text":"You can use an If construct to determine if an expression is True or False. $True indicates that an expression is True. $False indicates that an expression is False. # _FullyTax.ps1_ # Possible values: 'Minor', 'Adult', 'Senior Citizen' $Status = 'Minor' If ( $Status -eq 'Minor' ) { Write-Host $False } ElseIf ( $Status -eq 'Adult' ) { Write-Host $True } Else { Write-Host $False } You can use the If construct in Windows PowerShell to make decisions. You also can use it to evaluate data you've queried or user input. For example, you could have an If statement that displays a warning if available disk space is low. The If construct uses the following syntax: If ( $freeSpace -le 5GB ) { Write-Host \"Free disk space is less than 5 GB\" } ElseIf ( $freeSpace -le 10GB ) { Write-Host \"Free disk space is less than 10 GB\" } Else { Write-Host \"Free disk space is more than 10 GB\" }","title":"If, ElseIf, and Else"},{"location":"Scripting/cond/#switch","text":"The Switch construct is similar to an If construct that has multiple ElseIf sections. The Switch construct evaluates a single variable or item against multiple values and has a script block for each value. The script block for each value is run if that value matches the variable. There's also a Default section that runs only if there are no matches. The Switch construct uses the following syntax: Switch ( $choice ) { 1 { Write-Host \"You selected menu item 1\" } 2 { Write-Host \"You selected menu item 2\" } 3 { Write-Host \"You selected menu item 3\" } Default { Write-Host \"You did not select a valid option\" } } In addition to matching values, the Switch construct can also be used to match patterns. You can use the -wildcard parameter to perform pattern matching by using the same syntax as the -like operator. Alternatively, you can use the -regex parameter to perform matching by using regular expressions. It's important to be aware that when you use pattern matching, multiple matches are possible. When there are multiple matches, the script blocks for all matching patterns are run. This is different from an If construct in which only one script block is run. The following example uses pattern matching: Switch -WildCard ( $ip ) { \"10.*\" { Write-Host \"This computer is on the internal network\" } \"10.1.*\" { Write-Host \"This computer is in London\" } \"10.2.*\" { Write-Host \"This computer is in Vancouver\" } Default { Write-Host \"This computer is not on the internal network\" } } For values of $ip on the London or Vancouver networks, two messages will be displayed. If $ip includes an IP address on the 10.x.x.x network, the messages will indicate that the computer is on the internal network and that the computer is in either London or Vancouver. If $ip is not an IP address on the 10.x.x.x network, the message indicates that it's not on the internal network. If you provide multiple values in an array to a Switch construct, each item in the array is evaluated. In the previous example, if the variable $ip was an array with two IP addresses, then both IP addresses would be processed. The actions appropriate for each item in the array would be performed.","title":"Switch"},{"location":"Scripting/ds/","text":"Array An array is a data structure that's designed to store a collection of items of the same type. You can think of an array as a variable containing multiple values or objects. Variables that contain a single value are useful, but for complex tasks you often need to work with groups of items. For example, you might need to update the Voice over IP (VoIP) attribute on multiple domain user accounts. Or you might need to check the status of a group of services and restart all of them that are stopped. When you put multiple objects or values into a variable, it becomes an array. Creating Arrays You can create an array by providing multiple values in a comma-separated list. For example: $computers = \"LON-DC1\" , \"LON-SRV1\" , \"LON-SRV2\" $numbers = 228 , 43 , 102 To create an array of strings, you put quotes around each item. If you put one set of quotes around all the items, it's treated as a single string. You also can create an array by using the output from a command. For example: $users = Get-ADUser -Filter * $files = Get-ChildItem C :\\ ou can verify whether a variable is an array by using the GetType() method on the variable. The BaseType listed will be System.Array. You can create an empty array before you're ready to put content in it. This can be useful when you have a loop later on in a script that adds items to the array. For example: $newUsers = @() You also can force an array to be created when adding a single value to a variable. This creates an array with a single value into which you can add items later. For example: [array] $computers = \"LON-DC1\" Working With Arrays Display Item $users [ 0 ] Add Item $users = $users + $user1 # or $users += $user1 To Identify To identify what you can do with the content in an array, use the Get-Member cmdlet. Pipe the contents of the array to Get-Member, and the results returned identify the properties and methods that you can use for the items in the array. For example: $files | Get-Member When you pipe an array containing mixed data types to Get-Member, results are returned for each data type. This is also a helpful way of determining which data types are in the array. To review the properties and methods available for an array rather than the items within the array, use the following syntax: Get-Member -InputObject $files ArrayLists The default type of array that Windows PowerShell creates is a fixed-size array. This means that when you add an item to the array, the array is actually recreated with the additional item. When you work with relatively small arrays, this is not a concern. However, if you add thousands of items to an array one by one, recreating an array each time has a negative performance impact. The other concern when using fixed-size arrays is removing items. There's no simple method to remove an item from a fixed-size array. To address the shortcomings of arrays, you can use an array list. An array list functions similar to an array, except that it doesn't have a fixed size. This means that you can use methods to add and remove items. Creating ArrayLists [System.Collections.ArrayList] $computers = \"LON-DC1\" , \"LON-SVR1\" , \"LON-CL1\" To create an array list that's empty and ready to add items, use the following syntax: $computers = New-Object System . Collections . ArrayList ArrayList Methods $computers . Add ( \"LON-SRV2\" ) $computers . Remove ( \"LON-CL1\" ) When you remove an item from an array list, if there are multiple matching items then only the first instance is removed. If you want to remove an item from an array list based on the index number, you use the RemoveAt() method. For example: $computers . RemoveAt ( 1 ) Hash Tables A hash table represents a similar concept to an array since it stores multiple items. However, unlike an array which uses an index number to identify each item, a hash table uses for this purpose a unique key. The key is a string that's a unique identifier for the item. Each key in a hash table is associated with a value. You can use a hash table to store both IP addresses and the computer names as the following table depicts. Key Value LON-DC1 192.168.0.10 LON-SRV1 192.168.0.11 LON-SRV2 192.168.0.12 If the hash table is named $servers, then you access the first item in the hash table by using either of the following options: $servers . 'LON-DC1' $servers [ 'LON-DC1' ] You only need to use single quote marks to enclose keys that contain special characters. In the previous example, the hyphen in the computer names is a special character, which requires the key name to be enclosed in single quote marks. Working with Hash Tables Working with hash tables is similar to working with an array, except that to add items to a hash table you need to provide both the key for the item and the value. $servers = @{ \"LON-DC1\" = \"172.16.0.10\" ; \"LON-SRV1\" = \"172.16.0.11\" } Notice the following syntax in the previous example: It begins with the at (@) symbol. The keys and associated values are enclosed in braces. The items are separated by a semicolon. The semicolon between hash table items is required in the previous example because they're all on the same line. If you place each item on a separate line, it's not necessary to use semicolons as separators. $servers . Add ( \"LON-SRV2\" , \"172.16.0.12\" ) $servers . Remove ( \"LON-DC1\" ) # Update the value for a key $servers . \"LON-SRV2\" = \"172.16.0.100\"","title":"Data Structures"},{"location":"Scripting/ds/#array","text":"An array is a data structure that's designed to store a collection of items of the same type. You can think of an array as a variable containing multiple values or objects. Variables that contain a single value are useful, but for complex tasks you often need to work with groups of items. For example, you might need to update the Voice over IP (VoIP) attribute on multiple domain user accounts. Or you might need to check the status of a group of services and restart all of them that are stopped. When you put multiple objects or values into a variable, it becomes an array.","title":"Array"},{"location":"Scripting/ds/#creating-arrays","text":"You can create an array by providing multiple values in a comma-separated list. For example: $computers = \"LON-DC1\" , \"LON-SRV1\" , \"LON-SRV2\" $numbers = 228 , 43 , 102 To create an array of strings, you put quotes around each item. If you put one set of quotes around all the items, it's treated as a single string. You also can create an array by using the output from a command. For example: $users = Get-ADUser -Filter * $files = Get-ChildItem C :\\ ou can verify whether a variable is an array by using the GetType() method on the variable. The BaseType listed will be System.Array. You can create an empty array before you're ready to put content in it. This can be useful when you have a loop later on in a script that adds items to the array. For example: $newUsers = @() You also can force an array to be created when adding a single value to a variable. This creates an array with a single value into which you can add items later. For example: [array] $computers = \"LON-DC1\"","title":"Creating Arrays"},{"location":"Scripting/ds/#working-with-arrays","text":"","title":"Working With Arrays"},{"location":"Scripting/ds/#display-item","text":"$users [ 0 ]","title":"Display Item"},{"location":"Scripting/ds/#add-item","text":"$users = $users + $user1 # or $users += $user1","title":"Add Item"},{"location":"Scripting/ds/#to-identify","text":"To identify what you can do with the content in an array, use the Get-Member cmdlet. Pipe the contents of the array to Get-Member, and the results returned identify the properties and methods that you can use for the items in the array. For example: $files | Get-Member When you pipe an array containing mixed data types to Get-Member, results are returned for each data type. This is also a helpful way of determining which data types are in the array. To review the properties and methods available for an array rather than the items within the array, use the following syntax: Get-Member -InputObject $files","title":"To Identify"},{"location":"Scripting/ds/#arraylists","text":"The default type of array that Windows PowerShell creates is a fixed-size array. This means that when you add an item to the array, the array is actually recreated with the additional item. When you work with relatively small arrays, this is not a concern. However, if you add thousands of items to an array one by one, recreating an array each time has a negative performance impact. The other concern when using fixed-size arrays is removing items. There's no simple method to remove an item from a fixed-size array. To address the shortcomings of arrays, you can use an array list. An array list functions similar to an array, except that it doesn't have a fixed size. This means that you can use methods to add and remove items.","title":"ArrayLists"},{"location":"Scripting/ds/#creating-arraylists","text":"[System.Collections.ArrayList] $computers = \"LON-DC1\" , \"LON-SVR1\" , \"LON-CL1\" To create an array list that's empty and ready to add items, use the following syntax: $computers = New-Object System . Collections . ArrayList","title":"Creating ArrayLists"},{"location":"Scripting/ds/#arraylist-methods","text":"$computers . Add ( \"LON-SRV2\" ) $computers . Remove ( \"LON-CL1\" ) When you remove an item from an array list, if there are multiple matching items then only the first instance is removed. If you want to remove an item from an array list based on the index number, you use the RemoveAt() method. For example: $computers . RemoveAt ( 1 )","title":"ArrayList Methods"},{"location":"Scripting/ds/#hash-tables","text":"A hash table represents a similar concept to an array since it stores multiple items. However, unlike an array which uses an index number to identify each item, a hash table uses for this purpose a unique key. The key is a string that's a unique identifier for the item. Each key in a hash table is associated with a value. You can use a hash table to store both IP addresses and the computer names as the following table depicts. Key Value LON-DC1 192.168.0.10 LON-SRV1 192.168.0.11 LON-SRV2 192.168.0.12 If the hash table is named $servers, then you access the first item in the hash table by using either of the following options: $servers . 'LON-DC1' $servers [ 'LON-DC1' ] You only need to use single quote marks to enclose keys that contain special characters. In the previous example, the hyphen in the computer names is a special character, which requires the key name to be enclosed in single quote marks.","title":"Hash Tables"},{"location":"Scripting/ds/#working-with-hash-tables","text":"Working with hash tables is similar to working with an array, except that to add items to a hash table you need to provide both the key for the item and the value. $servers = @{ \"LON-DC1\" = \"172.16.0.10\" ; \"LON-SRV1\" = \"172.16.0.11\" } Notice the following syntax in the previous example: It begins with the at (@) symbol. The keys and associated values are enclosed in braces. The items are separated by a semicolon. The semicolon between hash table items is required in the previous example because they're all on the same line. If you place each item on a separate line, it's not necessary to use semicolons as separators. $servers . Add ( \"LON-SRV2\" , \"172.16.0.12\" ) $servers . Remove ( \"LON-DC1\" ) # Update the value for a key $servers . \"LON-SRV2\" = \"172.16.0.100\"","title":"Working with Hash Tables"},{"location":"Scripting/functions/","text":"When you create many scripts, you'll have snippets of code that you want to reuse. You'll also have snippets of code that you want to reuse within the same script. Rather than having the same code display multiple times in a script, you can create a function that displays once in the script, but is called multiple times. If you need to use the same code across multiple scripts, then you can put the function into a module that can be shared by multiple scripts. When you call a function, you can pass data to it. You use the Param() block for a function in the same way as you do for a script. After the declaration for the function, insert the Param() block and the definitions for any variables that are expected to be passed to the function. Function Get-SecurityEvent { Param ( [string] $ComputerName ) #end Param Get-EventLog -LogName Security -ComputerName - $ComputerName -Newest 10 } To call the function within a script, use the following syntax: Get-SecurityEvent -ComputerName LON-DC1 Variable Scopes Scope Description Global The global scope is for the Windows PowerShell prompt. Variables set at the Windows PowerShell prompt can be reviewed in all the scripts started at that Windows PowerShell prompt. Variables created at a Windows PowerShell prompt don't exist in other Windows PowerShell prompts or in instances of the Windows PowerShell Integrated Scripting Environment (ISE). Script The script scope is for a single script. Variables set within a script can be reviewed by all the functions within that script. If you set a variable value in the script scope that already exists in the global scope, a new variable is created in the script scope. There are then two variables of the same name in two separate scopes. At this point, when you review the value of the variable in the script, the value of the variable in the script scope is returned. Function The function scope is for a single function. Variables set within a function aren't shared with other functions or the script. If you set a variable value in the function scope that already exists in the global or script scope, a new variable is created in the function scope. Then, there are two variables of the same name in two separate scopes. In addition to reviewing a variable in a higher-level scope, you can also modify that variable by specifically referencing the scope of the variable when you modify it. To modify a script scope variable from a function, use the following syntax: $script:var = \"Modified from function\" It's a best practice to avoid modifying variables between scopes, because doing so can cause confusion. Instead, set the script scope variable equal to the output of the function. If the data in the function is in a variable, you can use Return() to pass it back to the script. The following is an example of using Return() at the end of a function to pass a variable value back to the script scope: Return ( $users ) Using Return() in a function adds the specified data to the pipeline of data being returned, but doesn't replace existing data in the pipeline. As part of script development, you need to verify exactly which data is being returned by a function.","title":"Functions"},{"location":"Scripting/functions/#variable-scopes","text":"Scope Description Global The global scope is for the Windows PowerShell prompt. Variables set at the Windows PowerShell prompt can be reviewed in all the scripts started at that Windows PowerShell prompt. Variables created at a Windows PowerShell prompt don't exist in other Windows PowerShell prompts or in instances of the Windows PowerShell Integrated Scripting Environment (ISE). Script The script scope is for a single script. Variables set within a script can be reviewed by all the functions within that script. If you set a variable value in the script scope that already exists in the global scope, a new variable is created in the script scope. There are then two variables of the same name in two separate scopes. At this point, when you review the value of the variable in the script, the value of the variable in the script scope is returned. Function The function scope is for a single function. Variables set within a function aren't shared with other functions or the script. If you set a variable value in the function scope that already exists in the global or script scope, a new variable is created in the function scope. Then, there are two variables of the same name in two separate scopes. In addition to reviewing a variable in a higher-level scope, you can also modify that variable by specifically referencing the scope of the variable when you modify it. To modify a script scope variable from a function, use the following syntax: $script:var = \"Modified from function\" It's a best practice to avoid modifying variables between scopes, because doing so can cause confusion. Instead, set the script scope variable equal to the output of the function. If the data in the function is in a variable, you can use Return() to pass it back to the script. The following is an example of using Return() at the end of a function to pass a variable value back to the script scope: Return ( $users ) Using Return() in a function adds the specified data to the pipeline of data being returned, but doesn't replace existing data in the pipeline. As part of script development, you need to verify exactly which data is being returned by a function.","title":"Variable Scopes"},{"location":"Scripting/loops/","text":"While there are some simple scripts that use only simple Windows PowerShell commands, most scripts use scripting constructs to perform more complex actions. You can use the ForEach construct to process all of the objects in an array. You can use If..Else and Switch constructs to make decisions in your scripts. Finally, there are less common looping constructs such as For, While, and Do..While loops that can be used when appropriate. ForEach When you perform piping, the commands in the pipeline are applied to each object. In some cases, you might need to use the ForEach-Object cmdlet to process the data in the pipeline. When you store data in an array, the ForEach construct allows you to process each item in the array. The ForEach construct uses the following syntax: ForEach ( $user in $users ) { Set-ADUser $user -Department \"Marketing\" } In a script, the ForEach construct is the most common way to process items that you've placed into an array. It's easy to use because you don't need to know the number of items to process them. Parallel performance In PowerShell 7, the -Parallel parameter was added to the ForEach-Object cmdlet. This allows the pipeline to process multiple objects simultaneously. Processing multiple objects simultaneously can provide better performance than a standard ForEach loop. $users | ForEach -Object -Parallel { Set-ADUser $user -Department \"Marketing\" } By default, the -Parallel parameter allows five items to be processed at a time. You can modify this to be larger or smaller by using the -ThrottleLimit parameter. For The For construct performs a series of loops similar to a ForEach construct. However, when using the For construct, you must define how many loops occur, which is useful when you want an action to be performed a specific number of times. For example, you could create a specific number of user accounts in a test environment. The For construct uses the following syntax: For ( $i = 1 ; $i -le 10 ; $i ++) { Write-Host \"Creating User $i\" } The For construct uses an initial state, a condition, and an action. In the previous example, the initial state is $i=1. The condition is $i -le 10. When the condition specified is true, another loop is processed. After each loop is processed, the action is performed. In this example, the action is $i++, which increments $i by 1. The script block inside the braces is run each time the loop is processed. In the previous example, this loop is processed 10 times. When you're processing an array of objects, using the ForEach construct is preferred because you don't need to calculate the number of items in the array before processing. Other Loops There are other less common looping constructs that you can use. These looping constructs are Do..While, Do..Until, and While. All these looping constructs process a script block until a condition is met, but they vary in how they do it. Do..While The Do..While construct runs a script block until a specified condition isn't true. This construct guarantees that the script block is run at least once. The Do..While construct uses the following syntax: Do { Write-Host \"Script block to process\" } While ( $answer -eq \"go\" ) Do..Until The Do..Until construct runs a script block until a specified condition is true. This construct guarantees that the script block is run at least once. The Do..Until construct uses the following syntax: Do { Write-Host \"Script block to process\" } Until ( $answer -eq \"stop\" ) While The While construct runs a script block until a specified condition is false. While it's similar to the Do..While construct, it doesn't guarantee that the script block is run. The While construct uses the following syntax: While ( $answer -eq \"go\" ) { Write-Host \"Script block to process\" }","title":"Loops"},{"location":"Scripting/loops/#foreach","text":"When you perform piping, the commands in the pipeline are applied to each object. In some cases, you might need to use the ForEach-Object cmdlet to process the data in the pipeline. When you store data in an array, the ForEach construct allows you to process each item in the array. The ForEach construct uses the following syntax: ForEach ( $user in $users ) { Set-ADUser $user -Department \"Marketing\" } In a script, the ForEach construct is the most common way to process items that you've placed into an array. It's easy to use because you don't need to know the number of items to process them.","title":"ForEach"},{"location":"Scripting/loops/#parallel-performance","text":"In PowerShell 7, the -Parallel parameter was added to the ForEach-Object cmdlet. This allows the pipeline to process multiple objects simultaneously. Processing multiple objects simultaneously can provide better performance than a standard ForEach loop. $users | ForEach -Object -Parallel { Set-ADUser $user -Department \"Marketing\" } By default, the -Parallel parameter allows five items to be processed at a time. You can modify this to be larger or smaller by using the -ThrottleLimit parameter.","title":"Parallel performance"},{"location":"Scripting/loops/#for","text":"The For construct performs a series of loops similar to a ForEach construct. However, when using the For construct, you must define how many loops occur, which is useful when you want an action to be performed a specific number of times. For example, you could create a specific number of user accounts in a test environment. The For construct uses the following syntax: For ( $i = 1 ; $i -le 10 ; $i ++) { Write-Host \"Creating User $i\" } The For construct uses an initial state, a condition, and an action. In the previous example, the initial state is $i=1. The condition is $i -le 10. When the condition specified is true, another loop is processed. After each loop is processed, the action is performed. In this example, the action is $i++, which increments $i by 1. The script block inside the braces is run each time the loop is processed. In the previous example, this loop is processed 10 times. When you're processing an array of objects, using the ForEach construct is preferred because you don't need to calculate the number of items in the array before processing.","title":"For"},{"location":"Scripting/loops/#other-loops","text":"There are other less common looping constructs that you can use. These looping constructs are Do..While, Do..Until, and While. All these looping constructs process a script block until a condition is met, but they vary in how they do it.","title":"Other Loops"},{"location":"Scripting/loops/#dowhile","text":"The Do..While construct runs a script block until a specified condition isn't true. This construct guarantees that the script block is run at least once. The Do..While construct uses the following syntax: Do { Write-Host \"Script block to process\" } While ( $answer -eq \"go\" )","title":"Do..While"},{"location":"Scripting/loops/#dountil","text":"The Do..Until construct runs a script block until a specified condition is true. This construct guarantees that the script block is run at least once. The Do..Until construct uses the following syntax: Do { Write-Host \"Script block to process\" } Until ( $answer -eq \"stop\" )","title":"Do..Until"},{"location":"Scripting/loops/#while","text":"The While construct runs a script block until a specified condition is false. While it's similar to the Do..While construct, it doesn't guarantee that the script block is run. The While construct uses the following syntax: While ( $answer -eq \"go\" ) { Write-Host \"Script block to process\" }","title":"While"},{"location":"Scripting/variables/","text":"Powershell allows you to store values \u200b\u200bin variables. All variable names begin with the $ sign, and are made up of letters, numbers, and the underscore (_). The assignment operator is the equal sign (=). Some examples: Command Description $server = \"localhost\" The variable will contain a text string $number = 5 The variable will contain an integer $services = Get-Service The variable will contain a list of services If you want to query the type of data a variable contains, you can do so with the Get-Member cmdlet. Get-Member also displays the variable's properties and methods. For example, variables of the System.String type have the ToUpper() method, which converts the content of the variable to uppercase. $server . ToUpper () LOCALHOST Variables can be used to replace any parameter in a cmdlet call. You can store all types of values in PowerShell variables. For example, store the results of commands, and store elements that are used in commands and expressions, such as names, paths, settings, and values. To get a list of all the variables in your PowerShell session, type Get-Variable. The variable names are displayed without the preceding dollar ($) sign that is used to reference variables. Variables in Powershell There are several different types of variables in PowerShell. User-created variables : User-created variables are created and maintained by the user. By default, the variables that you create at the PowerShell command line exist only while the PowerShell window is open. When the PowerShell windows is closed, the variables are deleted. To save a variable, add it to your PowerShell profile. You can also create variables in scripts with global, script, or local scope. Automatic variables : Automatic variables store the state of PowerShell. These variables are created by PowerShell, and PowerShell changes their values as required to maintain their accuracy. Users can't change the value of these variables. For example, the $PSHOME variable stores the path to the PowerShell installation directory.For more information, a list, and a description of the automatic variables, see about_Automatic_Variables . Preference variables : Preference variables store user preferences for PowerShell. These variables are created by PowerShell and are populated with default values. Users can change the values of these variables. For example, the $MaximumHistoryCount variable determines the maximum number of entries in the session history. For more information, a list, and a description of the preference variables, see about_Preference_Variables . Working With Variables To create a new variable, use an assignment statement to assign a value to the variable. You don't have to declare the variable before using it. The default value of all variables is $null $MyVariable = 1 , 2 , 3 $Path = \"C:\\Windows\\System32\" Variables are useful for storing the results of commands. For example: $Processes = Get-Process $Today = ( Get-Date ). DateTime To change the value of a variable, assign a new value to the variable. The Variable Cmdlets Cmdlet Name Description Clear-Variable Deletes the value of a variable. Get-Variable Gets the variables in the current console. New-Variable Creates a new variable. Remove-Variable Deletes a variable and its value. Set-Variable Changes the value of a variable. Variable Types You can store any type of object in a variable, including integers, strings, arrays, and hash tables. And, objects that represent processes, services, event logs, and computers. PowerShell variables are loosely typed, which means that they aren't limited to a particular type of object. A single variable can even contain a collection, or array, of different types of objects at the same time. The data type of a variable is determined by the .NET types of the values of the variable. To view a variable's object type, use Get-Member. $a = 12 # System.Int32 $a = \"Word\" # System.String $a = 12 , \"Word\" # array of System.Int32, System.String $a = Get-ChildItem C :\\ Windows # FileInfo and DirectoryInfo types Casting To use cast notation, enter a type name, enclosed in brackets, before the variable name (on the left side of the assignment statement). The following example creates a $number variable that can contain only integers, a $words variable that can contain only strings, and a $dates variable that can contain only DateTime objects. [int] $number = 8 $number = \"12345\" # The string is converted to an integer. $number = \"Hello\" #Casting Error Casting is useful when asking user input: # If no casting the number will be concatenated instead of multiplied PS > [int] $num = read-host \"Enter any number:\" Enter any number : 1024 PS > $num = $num * 10 PS > $num 10240 Using Variables in Commands and Expressions To use a variable in a command or expression, type the variable name, preceded by the dollar ($) sign. If the variable name and dollar sign aren't enclosed in quotation marks, or if they're enclosed in double quotation (\") marks, the value of the variable is used in the command or expression. If the variable name and dollar sign are enclosed in single quotation (') marks, the variable name is used in the expression. For more information about using quotation marks in PowerShell, see about_Quoting_Rules . Single quotes are used to assign to a variable the exact text that is placed between them, for example: PS > $var = 'Hello' PS > $var = 'The content of the variable is $var' PS > $var The content of the variable is $var The single quotes prevent the $ sign from being interpreted as the start of a variable name. To get Powershell to interpret the $ sign as the start of a variable name, the assignment is done with double quotes: PS > $var = 'Hello' PS > $var = \"Variable contains $var\" PS > $var Variable contains Hello The backtick ` causes Powershell to ignore the meaning of the following special character, for example: PS > $var = 'Hello' PS > $var = \"Variable `$ var contains $var\" PS > $var The variable $var contains Hello It can also be used to give special meaning to certain characters (equivalent to \\ in C and Java, for example \\n, \\t...). An example of use is the following: PS > $computername = 'localhost' PS > $phrase = \" `$ computername `n contains `n $computername\" PS > $phrase $computername contains localhost As you can see, `n stands for the carriage return character. To create or display a variable name that includes spaces or special characters, enclose the variable name with the curly braces ({}) characters. The curly braces direct PowerShell to interpret the variable name's characters as literals. ${ save-items } = \"a\" , \"b\" , \"c\" ${ save-items } To reference a variable name that includes braces, enclose the variable name in braces, and use the backtick character to escape the braces. For example, to create a variable named this{value}is type: ${ this `{ value `} is } = \"This variable name uses braces and backticks.\" ${ this `{ value `} is } List Variables It is possible to create a list type variable, separating the values \u200b\u200bof the list with commas: PS > $computers = 'server' , 'localhost' , 'server_2' PS > $computers server localhost server_2 List elements can be accessed by index number. Lists are numbered from zero: PS > $computers [ 0 ] server PS > $computers . count 3 Starting with Powershell version 3, if you pass a list as a parameter to a cmdlet, Powershell iterates over the items in the list. It is also possible to iterate over a list using the Foreach-Object cmdlet. These two commands do the same thing: $computers = $computers . tolower () $computers = $computers | ForEach -Object { $_ . tolower ()}","title":"Variables"},{"location":"Scripting/variables/#variables-in-powershell","text":"There are several different types of variables in PowerShell. User-created variables : User-created variables are created and maintained by the user. By default, the variables that you create at the PowerShell command line exist only while the PowerShell window is open. When the PowerShell windows is closed, the variables are deleted. To save a variable, add it to your PowerShell profile. You can also create variables in scripts with global, script, or local scope. Automatic variables : Automatic variables store the state of PowerShell. These variables are created by PowerShell, and PowerShell changes their values as required to maintain their accuracy. Users can't change the value of these variables. For example, the $PSHOME variable stores the path to the PowerShell installation directory.For more information, a list, and a description of the automatic variables, see about_Automatic_Variables . Preference variables : Preference variables store user preferences for PowerShell. These variables are created by PowerShell and are populated with default values. Users can change the values of these variables. For example, the $MaximumHistoryCount variable determines the maximum number of entries in the session history. For more information, a list, and a description of the preference variables, see about_Preference_Variables .","title":"Variables in Powershell"},{"location":"Scripting/variables/#working-with-variables","text":"To create a new variable, use an assignment statement to assign a value to the variable. You don't have to declare the variable before using it. The default value of all variables is $null $MyVariable = 1 , 2 , 3 $Path = \"C:\\Windows\\System32\" Variables are useful for storing the results of commands. For example: $Processes = Get-Process $Today = ( Get-Date ). DateTime To change the value of a variable, assign a new value to the variable.","title":"Working With Variables"},{"location":"Scripting/variables/#the-variable-cmdlets","text":"Cmdlet Name Description Clear-Variable Deletes the value of a variable. Get-Variable Gets the variables in the current console. New-Variable Creates a new variable. Remove-Variable Deletes a variable and its value. Set-Variable Changes the value of a variable.","title":"The Variable Cmdlets"},{"location":"Scripting/variables/#variable-types","text":"You can store any type of object in a variable, including integers, strings, arrays, and hash tables. And, objects that represent processes, services, event logs, and computers. PowerShell variables are loosely typed, which means that they aren't limited to a particular type of object. A single variable can even contain a collection, or array, of different types of objects at the same time. The data type of a variable is determined by the .NET types of the values of the variable. To view a variable's object type, use Get-Member. $a = 12 # System.Int32 $a = \"Word\" # System.String $a = 12 , \"Word\" # array of System.Int32, System.String $a = Get-ChildItem C :\\ Windows # FileInfo and DirectoryInfo types","title":"Variable Types"},{"location":"Scripting/variables/#casting","text":"To use cast notation, enter a type name, enclosed in brackets, before the variable name (on the left side of the assignment statement). The following example creates a $number variable that can contain only integers, a $words variable that can contain only strings, and a $dates variable that can contain only DateTime objects. [int] $number = 8 $number = \"12345\" # The string is converted to an integer. $number = \"Hello\" #Casting Error Casting is useful when asking user input: # If no casting the number will be concatenated instead of multiplied PS > [int] $num = read-host \"Enter any number:\" Enter any number : 1024 PS > $num = $num * 10 PS > $num 10240","title":"Casting"},{"location":"Scripting/variables/#using-variables-in-commands-and-expressions","text":"To use a variable in a command or expression, type the variable name, preceded by the dollar ($) sign. If the variable name and dollar sign aren't enclosed in quotation marks, or if they're enclosed in double quotation (\") marks, the value of the variable is used in the command or expression. If the variable name and dollar sign are enclosed in single quotation (') marks, the variable name is used in the expression. For more information about using quotation marks in PowerShell, see about_Quoting_Rules . Single quotes are used to assign to a variable the exact text that is placed between them, for example: PS > $var = 'Hello' PS > $var = 'The content of the variable is $var' PS > $var The content of the variable is $var The single quotes prevent the $ sign from being interpreted as the start of a variable name. To get Powershell to interpret the $ sign as the start of a variable name, the assignment is done with double quotes: PS > $var = 'Hello' PS > $var = \"Variable contains $var\" PS > $var Variable contains Hello The backtick ` causes Powershell to ignore the meaning of the following special character, for example: PS > $var = 'Hello' PS > $var = \"Variable `$ var contains $var\" PS > $var The variable $var contains Hello It can also be used to give special meaning to certain characters (equivalent to \\ in C and Java, for example \\n, \\t...). An example of use is the following: PS > $computername = 'localhost' PS > $phrase = \" `$ computername `n contains `n $computername\" PS > $phrase $computername contains localhost As you can see, `n stands for the carriage return character. To create or display a variable name that includes spaces or special characters, enclose the variable name with the curly braces ({}) characters. The curly braces direct PowerShell to interpret the variable name's characters as literals. ${ save-items } = \"a\" , \"b\" , \"c\" ${ save-items } To reference a variable name that includes braces, enclose the variable name in braces, and use the backtick character to escape the braces. For example, to create a variable named this{value}is type: ${ this `{ value `} is } = \"This variable name uses braces and backticks.\" ${ this `{ value `} is }","title":"Using Variables in Commands and Expressions"},{"location":"Scripting/variables/#list-variables","text":"It is possible to create a list type variable, separating the values \u200b\u200bof the list with commas: PS > $computers = 'server' , 'localhost' , 'server_2' PS > $computers server localhost server_2 List elements can be accessed by index number. Lists are numbered from zero: PS > $computers [ 0 ] server PS > $computers . count 3 Starting with Powershell version 3, if you pass a list as a parameter to a cmdlet, Powershell iterates over the items in the list. It is also possible to iterate over a list using the Foreach-Object cmdlet. These two commands do the same thing: $computers = $computers . tolower () $computers = $computers | ForEach -Object { $_ . tolower ()}","title":"List Variables"}]}